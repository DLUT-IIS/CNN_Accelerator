Script started on 2024-04-11 22:24:39+08:00 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="186" LINES="12"]
]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model resnet ...
 learning rate =  0.0001
SGD
2024-04-11 22:30:22.942476------------------------------------------------------ Precision@1: 75.40%  Precision@1: 92.59%

top1: [75.396]
top5: [92.592]
=> creating model alexnet ...
 learning rate =  0.0001
SGD
2024-04-11 22:34:04.665899------------------------------------------------------ Precision@1: 55.83%  Precision@1: 78.71%

top1: [55.83]
top5: [78.708]
=> creating model resnet ...
 learning rate =  0.0001
SGD
2024-04-11 22:34:09.680598 epoch: 1 step: 0 cls_loss= 1.37145 (6371 samples/sec)
2024-04-11 22:39:53.810482 epoch: 1 step: 500 cls_loss= 1.36252 (46 samples/sec)
2024-04-11 22:45:44.499233 epoch: 1 step: 1000 cls_loss= 1.43176 (45 samples/sec)
2024-04-11 22:51:39.868037 epoch: 1 step: 1500 cls_loss= 1.23400 (45 samples/sec)
2024-04-11 22:57:31.861275 epoch: 1 step: 2000 cls_loss= 0.84183 (45 samples/sec)
2024-04-11 23:03:35.037288 epoch: 1 step: 2500 cls_loss= 1.02280 (44 samples/sec)
2024-04-11 23:09:56.768291 epoch: 1 step: 3000 cls_loss= 1.00547 (41 samples/sec)
2024-04-11 23:16:16.053084------------------------------------------------------ Precision@1: 75.74%  Precision@1: 92.67%

top1: [75.738]
top5: [92.668]
2024-04-11 23:16:16.650414 epoch: 2 step: 0 cls_loss= 1.14952 (26901 samples/sec)
2024-04-11 23:19:39.508884 epoch: 2 step: 500 cls_loss= 0.97630 (78 samples/sec)
2024-04-11 23:23:18.626923 epoch: 2 step: 1000 cls_loss= 1.28648 (73 samples/sec)
2024-04-11 23:27:25.344775 epoch: 2 step: 1500 cls_loss= 1.03749 (64 samples/sec)
2024-04-11 23:32:15.546054 epoch: 2 step: 2000 cls_loss= 0.74792 (55 samples/sec)
2024-04-11 23:37:49.438993 epoch: 2 step: 2500 cls_loss= 0.98384 (47 samples/sec)
2024-04-11 23:43:27.076259 epoch: 2 step: 3000 cls_loss= 1.02521 (47 samples/sec)
2024-04-11 23:49:46.020326------------------------------------------------------ Precision@1: 75.71%  Precision@1: 92.69%

top1: [75.738, 75.712]
top5: [92.668, 92.686]
2024-04-11 23:49:46.499803 epoch: 3 step: 0 cls_loss= 1.57787 (33541 samples/sec)
2024-04-11 23:52:11.367042 epoch: 3 step: 500 cls_loss= 1.10224 (110 samples/sec)
2024-04-11 23:54:51.000548 epoch: 3 step: 1000 cls_loss= 0.98931 (100 samples/sec)
2024-04-11 23:57:45.842617 epoch: 3 step: 1500 cls_loss= 0.70082 (91 samples/sec)
2024-04-12 00:01:04.270533 epoch: 3 step: 2000 cls_loss= 1.19895 (80 samples/sec)
2024-04-12 00:05:08.443506 epoch: 3 step: 2500 cls_loss= 1.03184 (65 samples/sec)
2024-04-12 00:09:33.418079 epoch: 3 step: 3000 cls_loss= 1.17592 (60 samples/sec)
2024-04-12 00:16:01.768597------------------------------------------------------ Precision@1: 75.75%  Precision@1: 92.66%

top1: [75.738, 75.712, 75.748]
top5: [92.668, 92.686, 92.664]
2024-04-12 00:16:02.237808 epoch: 4 step: 0 cls_loss= 0.58070 (34219 samples/sec)
2024-04-12 00:17:56.859749 epoch: 4 step: 500 cls_loss= 1.02645 (139 samples/sec)
2024-04-12 00:20:33.946177 epoch: 4 step: 1000 cls_loss= 1.24109 (101 samples/sec)
2024-04-12 00:23:11.835983 epoch: 4 step: 1500 cls_loss= 0.80242 (101 samples/sec)
2024-04-12 00:25:49.510611 epoch: 4 step: 2000 cls_loss= 0.88007 (101 samples/sec)
2024-04-12 00:28:26.633575 epoch: 4 step: 2500 cls_loss= 1.24344 (101 samples/sec)
2024-04-12 00:31:04.380474 epoch: 4 step: 3000 cls_loss= 0.74065 (101 samples/sec)
2024-04-12 00:35:20.652699------------------------------------------------------ Precision@1: 75.75%  Precision@1: 92.68%

top1: [75.738, 75.712, 75.748, 75.746]
top5: [92.668, 92.686, 92.664, 92.676]
2024-04-12 00:35:20.946364 epoch: 5 step: 0 cls_loss= 1.27890 (54729 samples/sec)
2024-04-12 00:36:50.662828 epoch: 5 step: 500 cls_loss= 1.54975 (178 samples/sec)
2024-04-12 00:38:20.034841 epoch: 5 step: 1000 cls_loss= 1.24389 (179 samples/sec)
2024-04-12 00:39:49.729992 epoch: 5 step: 1500 cls_loss= 1.12851 (178 samples/sec)
2024-04-12 00:41:19.427674 epoch: 5 step: 2000 cls_loss= 0.88648 (178 samples/sec)
2024-04-12 00:42:49.117481 epoch: 5 step: 2500 cls_loss= 1.07529 (178 samples/sec)
2024-04-12 00:44:18.591517 epoch: 5 step: 3000 cls_loss= 1.24704 (178 samples/sec)
2024-04-12 00:48:17.416058------------------------------------------------------ Precision@1: 75.58%  Precision@1: 92.60%

top1: [75.738, 75.712, 75.748, 75.746, 75.57600000000001]
top5: [92.668, 92.686, 92.664, 92.676, 92.596]
2024-04-12 00:48:17.735925 epoch: 6 step: 0 cls_loss= 1.20237 (50240 samples/sec)
2024-04-12 00:49:47.422563 epoch: 6 step: 500 cls_loss= 0.91302 (178 samples/sec)
2024-04-12 00:51:16.892431 epoch: 6 step: 1000 cls_loss= 0.52561 (178 samples/sec)
2024-04-12 00:52:46.406919 epoch: 6 step: 1500 cls_loss= 0.90796 (178 samples/sec)
2024-04-12 00:54:16.083801 epoch: 6 step: 2000 cls_loss= 1.72236 (178 samples/sec)
2024-04-12 00:55:45.766923 epoch: 6 step: 2500 cls_loss= 1.12113 (178 samples/sec)
2024-04-12 00:57:15.370583 epoch: 6 step: 3000 cls_loss= 1.06513 (178 samples/sec)
2024-04-12 01:01:14.760116------------------------------------------------------ Precision@1: 75.39%  Precision@1: 92.59%

top1: [75.738, 75.712, 75.748, 75.746, 75.57600000000001, 75.388]
top5: [92.668, 92.686, 92.664, 92.676, 92.596, 92.592]
=> creating model resnet ...
 learning rate =  0.0001
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 01:01:20.661038 epoch: 1 step: 0 cls_loss= 1.31385 (8001 samples/sec)
2024-04-12 01:03:31.857468 epoch: 1 step: 500 cls_loss= 1.03764 (121 samples/sec)
2024-04-12 01:05:43.207608 epoch: 1 step: 1000 cls_loss= 0.82651 (121 samples/sec)
2024-04-12 01:07:54.454964 epoch: 1 step: 1500 cls_loss= 1.17760 (121 samples/sec)
2024-04-12 01:10:05.451848 epoch: 1 step: 2000 cls_loss= 0.46399 (122 samples/sec)
2024-04-12 01:12:16.390930 epoch: 1 step: 2500 cls_loss= 1.12104 (122 samples/sec)
2024-04-12 01:14:27.675583 epoch: 1 step: 3000 cls_loss= 1.15153 (121 samples/sec)
2024-04-12 01:18:37.457667------------------------------------------------------ Precision@1: 75.26%  Precision@1: 92.56%

top1: [75.258]
top5: [92.558]
2024-04-12 01:18:37.904446 epoch: 2 step: 0 cls_loss= 0.94897 (35938 samples/sec)
2024-04-12 01:20:49.607164 epoch: 2 step: 500 cls_loss= 0.72473 (121 samples/sec)
2024-04-12 01:23:00.988938 epoch: 2 step: 1000 cls_loss= 0.97493 (121 samples/sec)
2024-04-12 01:25:12.314004 epoch: 2 step: 1500 cls_loss= 1.64370 (121 samples/sec)
2024-04-12 01:27:23.569582 epoch: 2 step: 2000 cls_loss= 1.05194 (121 samples/sec)
2024-04-12 01:29:35.184925 epoch: 2 step: 2500 cls_loss= 1.18457 (121 samples/sec)
2024-04-12 01:31:46.616160 epoch: 2 step: 3000 cls_loss= 1.02946 (121 samples/sec)
2024-04-12 01:35:56.081370------------------------------------------------------ Precision@1: 75.01%  Precision@1: 92.33%

top1: [75.258, 75.01]
top5: [92.558, 92.328]
2024-04-12 01:35:56.505566 epoch: 3 step: 0 cls_loss= 0.87949 (37856 samples/sec)
2024-04-12 01:38:08.101029 epoch: 3 step: 500 cls_loss= 0.95917 (121 samples/sec)
2024-04-12 01:40:19.634942 epoch: 3 step: 1000 cls_loss= 0.53993 (121 samples/sec)
2024-04-12 01:42:31.010241 epoch: 3 step: 1500 cls_loss= 0.92957 (121 samples/sec)
2024-04-12 01:44:42.614605 epoch: 3 step: 2000 cls_loss= 1.50850 (121 samples/sec)
2024-04-12 01:46:54.035333 epoch: 3 step: 2500 cls_loss= 1.42172 (121 samples/sec)
2024-04-12 01:49:05.473573 epoch: 3 step: 3000 cls_loss= 1.39645 (121 samples/sec)
2024-04-12 01:53:15.114624------------------------------------------------------ Precision@1: 75.07%  Precision@1: 92.37%

top1: [75.258, 75.01, 75.072]
top5: [92.558, 92.328, 92.37]
2024-04-12 01:53:15.523895 epoch: 4 step: 0 cls_loss= 0.80020 (39232 samples/sec)
2024-04-12 01:55:27.193457 epoch: 4 step: 500 cls_loss= 0.78018 (121 samples/sec)
2024-04-12 01:57:38.636294 epoch: 4 step: 1000 cls_loss= 1.43276 (121 samples/sec)
2024-04-12 01:59:49.834969 epoch: 4 step: 1500 cls_loss= 1.43012 (121 samples/sec)
2024-04-12 02:02:01.335064 epoch: 4 step: 2000 cls_loss= 1.08260 (121 samples/sec)
2024-04-12 02:04:12.196312 epoch: 4 step: 2500 cls_loss= 1.29754 (122 samples/sec)
2024-04-12 02:06:22.662908 epoch: 4 step: 3000 cls_loss= 1.06358 (122 samples/sec)
2024-04-12 02:10:32.472986------------------------------------------------------ Precision@1: 74.85%  Precision@1: 92.21%

top1: [75.258, 75.01, 75.072, 74.852]
top5: [92.558, 92.328, 92.37, 92.214]
2024-04-12 02:10:32.880550 epoch: 5 step: 0 cls_loss= 0.96053 (39421 samples/sec)
2024-04-12 02:12:44.523812 epoch: 5 step: 500 cls_loss= 0.72784 (121 samples/sec)
2024-04-12 02:14:56.115992 epoch: 5 step: 1000 cls_loss= 1.21796 (121 samples/sec)
2024-04-12 02:17:07.891049 epoch: 5 step: 1500 cls_loss= 1.56049 (121 samples/sec)
2024-04-12 02:19:19.422591 epoch: 5 step: 2000 cls_loss= 1.08593 (121 samples/sec)
2024-04-12 02:21:30.954691 epoch: 5 step: 2500 cls_loss= 0.87094 (121 samples/sec)
2024-04-12 02:23:42.553376 epoch: 5 step: 3000 cls_loss= 0.84136 (121 samples/sec)
2024-04-12 02:27:52.039406------------------------------------------------------ Precision@1: 74.79%  Precision@1: 92.33%

top1: [75.258, 75.01, 75.072, 74.852, 74.794]
top5: [92.558, 92.328, 92.37, 92.214, 92.33]
2024-04-12 02:27:52.446429 epoch: 6 step: 0 cls_loss= 1.10638 (39454 samples/sec)
2024-04-12 02:30:03.906378 epoch: 6 step: 500 cls_loss= 1.00197 (121 samples/sec)
2024-04-12 02:32:15.439563 epoch: 6 step: 1000 cls_loss= 1.09426 (121 samples/sec)
2024-04-12 02:34:26.480092 epoch: 6 step: 1500 cls_loss= 0.64391 (122 samples/sec)
2024-04-12 02:36:36.957931 epoch: 6 step: 2000 cls_loss= 1.19801 (122 samples/sec)
2024-04-12 02:38:47.805550 epoch: 6 step: 2500 cls_loss= 1.27782 (122 samples/sec)
2024-04-12 02:40:58.670854 epoch: 6 step: 3000 cls_loss= 0.94678 (122 samples/sec)
2024-04-12 02:45:08.062183------------------------------------------------------ Precision@1: 74.74%  Precision@1: 92.14%

top1: [75.258, 75.01, 75.072, 74.852, 74.794, 74.738]
top5: [92.558, 92.328, 92.37, 92.214, 92.33, 92.142]
=> creating model resnet ...
 learning rate =  0.0001
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 02:45:11.623347 epoch: 1 step: 0 cls_loss= 1.14990 (9323 samples/sec)
2024-04-12 02:47:25.660016 epoch: 1 step: 500 cls_loss= 0.87902 (119 samples/sec)
2024-04-12 02:49:40.005344 epoch: 1 step: 1000 cls_loss= 1.65694 (119 samples/sec)
2024-04-12 02:51:54.188924 epoch: 1 step: 1500 cls_loss= 1.63229 (119 samples/sec)
2024-04-12 02:54:08.045263 epoch: 1 step: 2000 cls_loss= 1.13466 (119 samples/sec)
2024-04-12 02:56:22.369876 epoch: 1 step: 2500 cls_loss= 0.52058 (119 samples/sec)
2024-04-12 02:58:36.784955 epoch: 1 step: 3000 cls_loss= 1.47140 (119 samples/sec)
2024-04-12 03:02:47.031913------------------------------------------------------ Precision@1: 74.67%  Precision@1: 92.22%

top1: [74.666]
top5: [92.218]
2024-04-12 03:02:47.441223 epoch: 2 step: 0 cls_loss= 1.42129 (39229 samples/sec)
2024-04-12 03:05:02.380157 epoch: 2 step: 500 cls_loss= 0.89650 (118 samples/sec)
2024-04-12 03:07:17.549028 epoch: 2 step: 1000 cls_loss= 1.37819 (118 samples/sec)
2024-04-12 03:09:32.619501 epoch: 2 step: 1500 cls_loss= 1.41373 (118 samples/sec)
2024-04-12 03:11:47.483255 epoch: 2 step: 2000 cls_loss= 1.22343 (118 samples/sec)
2024-04-12 03:14:02.360753 epoch: 2 step: 2500 cls_loss= 1.23379 (118 samples/sec)
2024-04-12 03:16:17.468954 epoch: 2 step: 3000 cls_loss= 1.20594 (118 samples/sec)
2024-04-12 03:20:27.758118------------------------------------------------------ Precision@1: 74.57%  Precision@1: 92.21%

top1: [74.666, 74.568]
top5: [92.218, 92.206]
2024-04-12 03:20:28.174597 epoch: 3 step: 0 cls_loss= 1.82316 (38562 samples/sec)
2024-04-12 03:22:42.920286 epoch: 3 step: 500 cls_loss= 0.76486 (118 samples/sec)
2024-04-12 03:24:57.579254 epoch: 3 step: 1000 cls_loss= 0.94510 (118 samples/sec)
2024-04-12 03:27:12.225424 epoch: 3 step: 1500 cls_loss= 0.94326 (118 samples/sec)
2024-04-12 03:29:26.941855 epoch: 3 step: 2000 cls_loss= 1.55493 (118 samples/sec)
2024-04-12 03:31:41.513479 epoch: 3 step: 2500 cls_loss= 0.90825 (118 samples/sec)
2024-04-12 03:33:56.053538 epoch: 3 step: 3000 cls_loss= 0.48505 (118 samples/sec)
2024-04-12 03:38:05.836190------------------------------------------------------ Precision@1: 74.34%  Precision@1: 92.01%

top1: [74.666, 74.568, 74.336]
top5: [92.218, 92.206, 92.012]
2024-04-12 03:38:06.250853 epoch: 4 step: 0 cls_loss= 1.30527 (38728 samples/sec)
2024-04-12 03:40:20.849902 epoch: 4 step: 500 cls_loss= 1.18852 (118 samples/sec)
2024-04-12 03:42:34.974757 epoch: 4 step: 1000 cls_loss= 0.91693 (119 samples/sec)
2024-04-12 03:44:48.964943 epoch: 4 step: 1500 cls_loss= 1.56548 (119 samples/sec)
2024-04-12 03:47:02.866334 epoch: 4 step: 2000 cls_loss= 1.22983 (119 samples/sec)
2024-04-12 03:49:17.412589 epoch: 4 step: 2500 cls_loss= 1.32187 (118 samples/sec)
2024-04-12 03:51:31.927115 epoch: 4 step: 3000 cls_loss= 1.13726 (118 samples/sec)
2024-04-12 03:55:41.605307------------------------------------------------------ Precision@1: 74.10%  Precision@1: 91.97%

top1: [74.666, 74.568, 74.336, 74.096]
top5: [92.218, 92.206, 92.012, 91.968]
2024-04-12 03:55:42.023811 epoch: 5 step: 0 cls_loss= 1.10439 (38366 samples/sec)
2024-04-12 03:57:56.296238 epoch: 5 step: 500 cls_loss= 0.94701 (119 samples/sec)
2024-04-12 04:00:10.410538 epoch: 5 step: 1000 cls_loss= 1.31164 (119 samples/sec)
2024-04-12 04:02:24.799895 epoch: 5 step: 1500 cls_loss= 1.27423 (119 samples/sec)
2024-04-12 04:04:39.438978 epoch: 5 step: 2000 cls_loss= 0.96893 (118 samples/sec)
2024-04-12 04:06:53.357450 epoch: 5 step: 2500 cls_loss= 0.97699 (119 samples/sec)
2024-04-12 04:09:07.110092 epoch: 5 step: 3000 cls_loss= 1.20972 (119 samples/sec)
2024-04-12 04:13:17.113022------------------------------------------------------ Precision@1: 74.03%  Precision@1: 91.87%

top1: [74.666, 74.568, 74.336, 74.096, 74.028]
top5: [92.218, 92.206, 92.012, 91.968, 91.874]
2024-04-12 04:13:17.530072 epoch: 6 step: 0 cls_loss= 1.43160 (38525 samples/sec)
2024-04-12 04:15:32.150800 epoch: 6 step: 500 cls_loss= 1.15405 (118 samples/sec)
2024-04-12 04:17:46.912144 epoch: 6 step: 1000 cls_loss= 0.93826 (118 samples/sec)
2024-04-12 04:20:01.702511 epoch: 6 step: 1500 cls_loss= 0.93823 (118 samples/sec)
2024-04-12 04:22:16.108476 epoch: 6 step: 2000 cls_loss= 0.98138 (119 samples/sec)
2024-04-12 04:24:29.814085 epoch: 6 step: 2500 cls_loss= 0.88751 (119 samples/sec)
2024-04-12 04:26:44.248377 epoch: 6 step: 3000 cls_loss= 0.99126 (119 samples/sec)
2024-04-12 04:30:54.283906------------------------------------------------------ Precision@1: 74.10%  Precision@1: 91.93%

top1: [74.666, 74.568, 74.336, 74.096, 74.028, 74.104]
top5: [92.218, 92.206, 92.012, 91.968, 91.874, 91.93]
=> creating model resnet ...
 learning rate =  0.0001
SGD
2024-04-12 04:30:57.901446 epoch: 1 step: 0 cls_loss= 1.31393 (9125 samples/sec)
2024-04-12 04:32:35.690101 epoch: 1 step: 500 cls_loss= 1.40810 (163 samples/sec)
2024-04-12 04:34:13.093166 epoch: 1 step: 1000 cls_loss= 1.17559 (164 samples/sec)
2024-04-12 04:35:50.075843 epoch: 1 step: 1500 cls_loss= 1.01798 (165 samples/sec)
2024-04-12 04:37:26.549473 epoch: 1 step: 2000 cls_loss= 0.90443 (165 samples/sec)
2024-04-12 04:39:03.116024 epoch: 1 step: 2500 cls_loss= 1.50782 (165 samples/sec)
2024-04-12 04:40:39.628969 epoch: 1 step: 3000 cls_loss= 0.75268 (165 samples/sec)
2024-04-12 04:45:04.134119------------------------------------------------------ Precision@1: 76.01%  Precision@1: 92.76%

top1: [76.014]
top5: [92.764]
2024-04-12 04:45:04.472220 epoch: 2 step: 0 cls_loss= 0.60661 (47524 samples/sec)
2024-04-12 04:46:41.205352 epoch: 2 step: 500 cls_loss= 1.10656 (165 samples/sec)
2024-04-12 04:48:19.147021 epoch: 2 step: 1000 cls_loss= 0.72887 (163 samples/sec)
2024-04-12 04:49:57.062563 epoch: 2 step: 1500 cls_loss= 0.56533 (163 samples/sec)
2024-04-12 04:51:34.424106 epoch: 2 step: 2000 cls_loss= 1.17515 (164 samples/sec)
2024-04-12 04:53:11.021034 epoch: 2 step: 2500 cls_loss= 0.79600 (165 samples/sec)
2024-04-12 04:54:48.367659 epoch: 2 step: 3000 cls_loss= 0.71235 (164 samples/sec)
2024-04-12 04:59:12.321993------------------------------------------------------ Precision@1: 75.91%  Precision@1: 92.75%

top1: [76.014, 75.906]
top5: [92.764, 92.752]
2024-04-12 04:59:12.639579 epoch: 3 step: 0 cls_loss= 1.54090 (50599 samples/sec)
2024-04-12 05:00:49.644954 epoch: 3 step: 500 cls_loss= 0.66879 (165 samples/sec)
2024-04-12 05:02:26.489987 epoch: 3 step: 1000 cls_loss= 1.91586 (165 samples/sec)
2024-04-12 05:04:03.088724 epoch: 3 step: 1500 cls_loss= 1.00762 (165 samples/sec)
2024-04-12 05:05:39.505742 epoch: 3 step: 2000 cls_loss= 0.83885 (166 samples/sec)
2024-04-12 05:07:15.984196 epoch: 3 step: 2500 cls_loss= 0.86266 (165 samples/sec)
2024-04-12 05:08:52.497461 epoch: 3 step: 3000 cls_loss= 0.70256 (165 samples/sec)
2024-04-12 05:13:17.088789------------------------------------------------------ Precision@1: 75.86%  Precision@1: 92.71%

top1: [76.014, 75.906, 75.858]
top5: [92.764, 92.752, 92.71000000000001]
2024-04-12 05:13:17.391862 epoch: 4 step: 0 cls_loss= 1.11266 (53035 samples/sec)
2024-04-12 05:14:54.891608 epoch: 4 step: 500 cls_loss= 1.04401 (164 samples/sec)
2024-04-12 05:16:31.998740 epoch: 4 step: 1000 cls_loss= 1.01631 (164 samples/sec)
2024-04-12 05:18:09.163864 epoch: 4 step: 1500 cls_loss= 1.27548 (164 samples/sec)
2024-04-12 05:19:46.117148 epoch: 4 step: 2000 cls_loss= 0.83791 (165 samples/sec)
2024-04-12 05:21:22.879381 epoch: 4 step: 2500 cls_loss= 0.73320 (165 samples/sec)
2024-04-12 05:22:59.411519 epoch: 4 step: 3000 cls_loss= 1.21358 (165 samples/sec)
2024-04-12 05:27:23.604138------------------------------------------------------ Precision@1: 75.87%  Precision@1: 92.80%

top1: [76.014, 75.906, 75.858, 75.868]
top5: [92.764, 92.752, 92.71000000000001, 92.796]
2024-04-12 05:27:23.962221 epoch: 5 step: 0 cls_loss= 0.90700 (44833 samples/sec)
2024-04-12 05:29:00.701300 epoch: 5 step: 500 cls_loss= 0.99814 (165 samples/sec)
2024-04-12 05:30:37.129784 epoch: 5 step: 1000 cls_loss= 1.08046 (165 samples/sec)
2024-04-12 05:32:13.585228 epoch: 5 step: 1500 cls_loss= 0.56607 (165 samples/sec)
2024-04-12 05:33:50.094520 epoch: 5 step: 2000 cls_loss= 0.69619 (165 samples/sec)
2024-04-12 05:35:26.653702 epoch: 5 step: 2500 cls_loss= 1.06591 (165 samples/sec)
2024-04-12 05:37:03.359543 epoch: 5 step: 3000 cls_loss= 0.84251 (165 samples/sec)
2024-04-12 05:41:27.175635------------------------------------------------------ Precision@1: 75.73%  Precision@1: 92.73%

top1: [76.014, 75.906, 75.858, 75.868, 75.726]
top5: [92.764, 92.752, 92.71000000000001, 92.796, 92.726]
2024-04-12 05:41:27.486449 epoch: 6 step: 0 cls_loss= 0.79332 (51709 samples/sec)
2024-04-12 05:43:03.975228 epoch: 6 step: 500 cls_loss= 0.84539 (165 samples/sec)
2024-04-12 05:44:41.009173 epoch: 6 step: 1000 cls_loss= 1.69201 (164 samples/sec)
2024-04-12 05:46:18.297108 epoch: 6 step: 1500 cls_loss= 0.91359 (164 samples/sec)
2024-04-12 05:47:54.818592 epoch: 6 step: 2000 cls_loss= 1.37959 (165 samples/sec)
2024-04-12 05:49:31.413916 epoch: 6 step: 2500 cls_loss= 0.80406 (165 samples/sec)
2024-04-12 05:51:08.239023 epoch: 6 step: 3000 cls_loss= 0.97069 (165 samples/sec)
2024-04-12 05:55:32.555807------------------------------------------------------ Precision@1: 75.56%  Precision@1: 92.62%

top1: [76.014, 75.906, 75.858, 75.868, 75.726, 75.56400000000001]
top5: [92.764, 92.752, 92.71000000000001, 92.796, 92.726, 92.618]
=> creating model resnet ...
 learning rate =  0.0001
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 05:55:36.135867 epoch: 1 step: 0 cls_loss= 1.06486 (9046 samples/sec)
2024-04-12 05:57:56.610437 epoch: 1 step: 500 cls_loss= 1.08410 (113 samples/sec)
2024-04-12 06:00:16.744358 epoch: 1 step: 1000 cls_loss= 0.95317 (114 samples/sec)
2024-04-12 06:02:37.013718 epoch: 1 step: 1500 cls_loss= 1.38500 (114 samples/sec)
2024-04-12 06:04:57.370619 epoch: 1 step: 2000 cls_loss= 1.14385 (113 samples/sec)
2024-04-12 06:07:17.532936 epoch: 1 step: 2500 cls_loss= 1.08618 (114 samples/sec)
2024-04-12 06:09:37.722047 epoch: 1 step: 3000 cls_loss= 0.87148 (114 samples/sec)
2024-04-12 06:14:13.178519------------------------------------------------------ Precision@1: 75.39%  Precision@1: 92.47%

top1: [75.39]
top5: [92.46600000000001]
2024-04-12 06:14:13.608974 epoch: 2 step: 0 cls_loss= 0.90283 (37292 samples/sec)
2024-04-12 06:16:33.822828 epoch: 2 step: 500 cls_loss= 0.93179 (114 samples/sec)
2024-04-12 06:18:54.195079 epoch: 2 step: 1000 cls_loss= 1.18228 (113 samples/sec)
2024-04-12 06:21:14.390929 epoch: 2 step: 1500 cls_loss= 0.69172 (114 samples/sec)
2024-04-12 06:23:34.703607 epoch: 2 step: 2000 cls_loss= 0.92689 (114 samples/sec)
2024-04-12 06:25:54.952617 epoch: 2 step: 2500 cls_loss= 1.39394 (114 samples/sec)
2024-04-12 06:28:15.270323 epoch: 2 step: 3000 cls_loss= 1.51111 (114 samples/sec)
2024-04-12 06:32:50.009781------------------------------------------------------ Precision@1: 75.13%  Precision@1: 92.41%

top1: [75.39, 75.132]
top5: [92.46600000000001, 92.412]
2024-04-12 06:32:50.435862 epoch: 3 step: 0 cls_loss= 0.98381 (37656 samples/sec)
2024-04-12 06:35:10.736071 epoch: 3 step: 500 cls_loss= 0.99702 (114 samples/sec)
2024-04-12 06:37:31.131007 epoch: 3 step: 1000 cls_loss= 1.38482 (113 samples/sec)
2024-04-12 06:39:51.213424 epoch: 3 step: 1500 cls_loss= 0.81050 (114 samples/sec)
2024-04-12 06:42:11.547533 epoch: 3 step: 2000 cls_loss= 1.46426 (114 samples/sec)
2024-04-12 06:44:31.955059 epoch: 3 step: 2500 cls_loss= 1.21730 (113 samples/sec)
2024-04-12 06:46:52.175579 epoch: 3 step: 3000 cls_loss= 1.25676 (114 samples/sec)
2024-04-12 06:51:27.334779------------------------------------------------------ Precision@1: 75.03%  Precision@1: 92.41%

top1: [75.39, 75.132, 75.028]
top5: [92.46600000000001, 92.412, 92.406]
2024-04-12 06:51:27.767537 epoch: 4 step: 0 cls_loss= 1.19395 (37091 samples/sec)
2024-04-12 06:53:48.381978 epoch: 4 step: 500 cls_loss= 1.58450 (113 samples/sec)
2024-04-12 06:56:09.151949 epoch: 4 step: 1000 cls_loss= 0.68832 (113 samples/sec)
2024-04-12 06:58:29.559665 epoch: 4 step: 1500 cls_loss= 0.81820 (113 samples/sec)
2024-04-12 07:00:49.997599 epoch: 4 step: 2000 cls_loss= 1.00920 (113 samples/sec)
2024-04-12 07:03:10.606184 epoch: 4 step: 2500 cls_loss= 1.03254 (113 samples/sec)
2024-04-12 07:05:31.129823 epoch: 4 step: 3000 cls_loss= 0.87961 (113 samples/sec)
2024-04-12 07:10:06.505063------------------------------------------------------ Precision@1: 74.91%  Precision@1: 92.37%

top1: [75.39, 75.132, 75.028, 74.906]
top5: [92.46600000000001, 92.412, 92.406, 92.374]
2024-04-12 07:10:06.941295 epoch: 5 step: 0 cls_loss= 1.02013 (36818 samples/sec)
2024-04-12 07:12:27.105690 epoch: 5 step: 500 cls_loss= 1.00535 (114 samples/sec)
2024-04-12 07:14:46.984796 epoch: 5 step: 1000 cls_loss= 1.23195 (114 samples/sec)
2024-04-12 07:17:06.405222 epoch: 5 step: 1500 cls_loss= 1.20597 (114 samples/sec)
2024-04-12 07:19:26.331162 epoch: 5 step: 2000 cls_loss= 1.05115 (114 samples/sec)
2024-04-12 07:21:46.013693 epoch: 5 step: 2500 cls_loss= 1.08803 (114 samples/sec)
2024-04-12 07:24:06.495099 epoch: 5 step: 3000 cls_loss= 0.74258 (113 samples/sec)
2024-04-12 07:28:41.704888------------------------------------------------------ Precision@1: 74.85%  Precision@1: 92.23%

top1: [75.39, 75.132, 75.028, 74.906, 74.846]
top5: [92.46600000000001, 92.412, 92.406, 92.374, 92.226]
2024-04-12 07:28:42.140420 epoch: 6 step: 0 cls_loss= 1.09751 (36834 samples/sec)
2024-04-12 07:31:02.285732 epoch: 6 step: 500 cls_loss= 1.04621 (114 samples/sec)
2024-04-12 07:33:22.366690 epoch: 6 step: 1000 cls_loss= 0.84344 (114 samples/sec)
2024-04-12 07:35:42.449528 epoch: 6 step: 1500 cls_loss= 1.51209 (114 samples/sec)
2024-04-12 07:38:02.814864 epoch: 6 step: 2000 cls_loss= 1.23441 (113 samples/sec)
2024-04-12 07:40:23.074846 epoch: 6 step: 2500 cls_loss= 1.01639 (114 samples/sec)
2024-04-12 07:42:43.475164 epoch: 6 step: 3000 cls_loss= 1.17534 (113 samples/sec)
2024-04-12 07:47:18.812970------------------------------------------------------ Precision@1: 74.92%  Precision@1: 92.30%

top1: [75.39, 75.132, 75.028, 74.906, 74.846, 74.922]
top5: [92.46600000000001, 92.412, 92.406, 92.374, 92.226, 92.3]
=> creating model resnet ...
 learning rate =  0.0001
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 07:47:22.436837 epoch: 1 step: 0 cls_loss= 1.16216 (9005 samples/sec)
2024-04-12 07:49:44.902196 epoch: 1 step: 500 cls_loss= 1.22680 (112 samples/sec)
2024-04-12 07:52:06.922374 epoch: 1 step: 1000 cls_loss= 1.54463 (112 samples/sec)
2024-04-12 07:54:29.362003 epoch: 1 step: 1500 cls_loss= 1.05374 (112 samples/sec)
2024-04-12 07:56:51.935841 epoch: 1 step: 2000 cls_loss= 1.36221 (112 samples/sec)
2024-04-12 07:59:14.196291 epoch: 1 step: 2500 cls_loss= 1.01101 (112 samples/sec)
2024-04-12 08:01:36.843119 epoch: 1 step: 3000 cls_loss= 0.59297 (112 samples/sec)
2024-04-12 08:06:12.085041------------------------------------------------------ Precision@1: 74.86%  Precision@1: 92.26%

top1: [74.862]
top5: [92.26]
2024-04-12 08:06:12.565096 epoch: 2 step: 0 cls_loss= 1.04820 (33427 samples/sec)
2024-04-12 08:08:34.990241 epoch: 2 step: 500 cls_loss= 1.05446 (112 samples/sec)
2024-04-12 08:10:57.436292 epoch: 2 step: 1000 cls_loss= 1.04413 (112 samples/sec)
2024-04-12 08:13:19.871488 epoch: 2 step: 1500 cls_loss= 1.38286 (112 samples/sec)
2024-04-12 08:15:42.187282 epoch: 2 step: 2000 cls_loss= 1.09215 (112 samples/sec)
2024-04-12 08:18:04.351400 epoch: 2 step: 2500 cls_loss= 1.38645 (112 samples/sec)
2024-04-12 08:20:26.367355 epoch: 2 step: 3000 cls_loss= 1.51650 (112 samples/sec)
2024-04-12 08:25:01.130344------------------------------------------------------ Precision@1: 74.69%  Precision@1: 92.08%

top1: [74.862, 74.694]
top5: [92.26, 92.08]
2024-04-12 08:25:01.564065 epoch: 3 step: 0 cls_loss= 1.36353 (36989 samples/sec)
2024-04-12 08:27:24.047029 epoch: 3 step: 500 cls_loss= 1.31644 (112 samples/sec)
2024-04-12 08:29:46.360295 epoch: 3 step: 1000 cls_loss= 1.31831 (112 samples/sec)
2024-04-12 08:32:08.925487 epoch: 3 step: 1500 cls_loss= 0.71653 (112 samples/sec)
2024-04-12 08:34:31.984489 epoch: 3 step: 2000 cls_loss= 0.75493 (111 samples/sec)
2024-04-12 08:36:54.839707 epoch: 3 step: 2500 cls_loss= 1.22172 (112 samples/sec)
2024-04-12 08:39:17.816335 epoch: 3 step: 3000 cls_loss= 1.13462 (111 samples/sec)
2024-04-12 08:43:52.866352------------------------------------------------------ Precision@1: 74.28%  Precision@1: 92.20%

top1: [74.862, 74.694, 74.278]
top5: [92.26, 92.08, 92.2]
2024-04-12 08:43:53.324668 epoch: 4 step: 0 cls_loss= 0.99631 (35019 samples/sec)
2024-04-12 08:46:16.445638 epoch: 4 step: 500 cls_loss= 0.99734 (111 samples/sec)
2024-04-12 08:48:39.587027 epoch: 4 step: 1000 cls_loss= 1.12513 (111 samples/sec)
^CTraceback (most recent call last):
  File "./imgnet_train_eval.py", line 324, in <module>
    main()
  File "./imgnet_train_eval.py", line 317, in main
    train(epoch)
  File "./imgnet_train_eval.py", line 153, in train
    output = model(inputs.cuda())
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/nets_imgnet/resnet50.py", line 238, in forward
    x = self.layer1(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/nets_imgnet/resnet50.py", line 74, in forward
    out = self.conv1(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/utils/conv2d_func.py", line 22, in forward
    self.weight_q = self.quantize_weight(self.weight/self.Kw) 
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/utils/sfp_quant.py", line 146, in forward
    weight_q = self.quantize(x)  
  File "/workspaces/pytorch-dev/SLFP_CNNs/utils/sfp_quant.py", line 39, in forward
    mantissa = input_abs / pow(2, exponent)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py", line 40, in wrapped
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py", line 866, in __rpow__
    return torch.tensor(other, dtype=dtype, device=self.device) ** self
KeyboardInterrupt

]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model resnet ...
 learning rate =  1e-05
SGD
2024-04-12 08:51:11.596402 epoch: 1 step: 0 cls_loss= 0.99654 (9357 samples/sec)
2024-04-12 08:52:41.869694 epoch: 1 step: 500 cls_loss= 0.99789 (177 samples/sec)
2024-04-12 08:54:11.436893 epoch: 1 step: 1000 cls_loss= 1.10031 (178 samples/sec)
2024-04-12 08:55:41.036073 epoch: 1 step: 1500 cls_loss= 0.95048 (178 samples/sec)
2024-04-12 08:57:11.111038 epoch: 1 step: 2000 cls_loss= 1.23752 (177 samples/sec)
2024-04-12 08:58:41.109132 epoch: 1 step: 2500 cls_loss= 0.89875 (177 samples/sec)
2024-04-12 09:00:11.148549 epoch: 1 step: 3000 cls_loss= 1.14908 (177 samples/sec)
2024-04-12 09:04:11.092941------------------------------------------------------ Precision@1: 75.74%  Precision@1: 92.72%

top1: [75.736]
top5: [92.718]
2024-04-12 09:04:11.388712 epoch: 2 step: 0 cls_loss= 1.19253 (54359 samples/sec)
2024-04-12 09:05:41.793540 epoch: 2 step: 500 cls_loss= 1.51838 (177 samples/sec)
2024-04-12 09:07:12.271592 epoch: 2 step: 1000 cls_loss= 1.10723 (176 samples/sec)
2024-04-12 09:08:41.871726 epoch: 2 step: 1500 cls_loss= 0.85041 (178 samples/sec)
2024-04-12 09:10:11.758962 epoch: 2 step: 2000 cls_loss= 1.43807 (178 samples/sec)
2024-04-12 09:11:41.892929 epoch: 2 step: 2500 cls_loss= 2.05734 (177 samples/sec)
2024-04-12 09:13:12.234322 epoch: 2 step: 3000 cls_loss= 0.99974 (177 samples/sec)
2024-04-12 09:17:11.595425------------------------------------------------------ Precision@1: 75.88%  Precision@1: 92.72%

top1: [75.736, 75.876]
top5: [92.718, 92.718]
2024-04-12 09:17:11.889493 epoch: 3 step: 0 cls_loss= 1.39754 (54663 samples/sec)
2024-04-12 09:18:41.431497 epoch: 3 step: 500 cls_loss= 0.93348 (178 samples/sec)
2024-04-12 09:20:10.926056 epoch: 3 step: 1000 cls_loss= 0.70071 (178 samples/sec)
2024-04-12 09:21:40.570847 epoch: 3 step: 1500 cls_loss= 0.79264 (178 samples/sec)
2024-04-12 09:23:10.453750 epoch: 3 step: 2000 cls_loss= 1.18166 (178 samples/sec)
2024-04-12 09:24:41.285619 epoch: 3 step: 2500 cls_loss= 0.87519 (176 samples/sec)
2024-04-12 09:26:11.161940 epoch: 3 step: 3000 cls_loss= 0.91649 (178 samples/sec)
2024-04-12 09:30:10.285164------------------------------------------------------ Precision@1: 75.90%  Precision@1: 92.76%

top1: [75.736, 75.876, 75.898]
top5: [92.718, 92.718, 92.76]
2024-04-12 09:30:10.588678 epoch: 4 step: 0 cls_loss= 1.07582 (52919 samples/sec)
2024-04-12 09:31:41.177206 epoch: 4 step: 500 cls_loss= 1.05025 (176 samples/sec)
2024-04-12 09:33:11.628578 epoch: 4 step: 1000 cls_loss= 0.84303 (176 samples/sec)
2024-04-12 09:34:41.849555 epoch: 4 step: 1500 cls_loss= 0.97056 (177 samples/sec)
2024-04-12 09:36:11.921902 epoch: 4 step: 2000 cls_loss= 0.84606 (177 samples/sec)
2024-04-12 09:37:42.192163 epoch: 4 step: 2500 cls_loss= 1.14104 (177 samples/sec)
2024-04-12 09:39:12.234960 epoch: 4 step: 3000 cls_loss= 1.07744 (177 samples/sec)
2024-04-12 09:43:11.789685------------------------------------------------------ Precision@1: 76.06%  Precision@1: 92.85%

top1: [75.736, 75.876, 75.898, 76.062]
top5: [92.718, 92.718, 92.76, 92.854]
2024-04-12 09:43:12.082627 epoch: 5 step: 0 cls_loss= 1.56810 (54897 samples/sec)
2024-04-12 09:44:41.812295 epoch: 5 step: 500 cls_loss= 1.55633 (178 samples/sec)
2024-04-12 09:46:11.541070 epoch: 5 step: 1000 cls_loss= 1.18195 (178 samples/sec)
2024-04-12 09:47:41.002276 epoch: 5 step: 1500 cls_loss= 1.01600 (178 samples/sec)
2024-04-12 09:49:10.463506 epoch: 5 step: 2000 cls_loss= 0.85000 (178 samples/sec)
2024-04-12 09:50:40.123908 epoch: 5 step: 2500 cls_loss= 1.16752 (178 samples/sec)
2024-04-12 09:52:09.553454 epoch: 5 step: 3000 cls_loss= 1.25987 (178 samples/sec)
2024-04-12 09:56:09.087394------------------------------------------------------ Precision@1: 76.00%  Precision@1: 92.86%

top1: [75.736, 75.876, 75.898, 76.062, 76.0]
top5: [92.718, 92.718, 92.76, 92.854, 92.858]
2024-04-12 09:56:09.381763 epoch: 6 step: 0 cls_loss= 1.00050 (54627 samples/sec)
2024-04-12 09:57:39.860991 epoch: 6 step: 500 cls_loss= 1.64235 (176 samples/sec)
2024-04-12 09:59:10.383622 epoch: 6 step: 1000 cls_loss= 0.80658 (176 samples/sec)
2024-04-12 10:00:41.358265 epoch: 6 step: 1500 cls_loss= 1.13956 (175 samples/sec)
2024-04-12 10:02:11.885425 epoch: 6 step: 2000 cls_loss= 1.03597 (176 samples/sec)
2024-04-12 10:03:42.417515 epoch: 6 step: 2500 cls_loss= 1.11301 (176 samples/sec)
2024-04-12 10:05:12.193801 epoch: 6 step: 3000 cls_loss= 0.82512 (178 samples/sec)
2024-04-12 10:09:11.638980------------------------------------------------------ Precision@1: 75.98%  Precision@1: 92.81%

top1: [75.736, 75.876, 75.898, 76.062, 76.0, 75.976]
top5: [92.718, 92.718, 92.76, 92.854, 92.858, 92.81]
=> creating model resnet ...
 learning rate =  1e-05
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 10:09:15.322356 epoch: 1 step: 0 cls_loss= 1.60103 (8822 samples/sec)
2024-04-12 10:11:26.794630 epoch: 1 step: 500 cls_loss= 2.00839 (121 samples/sec)
2024-04-12 10:13:37.950263 epoch: 1 step: 1000 cls_loss= 2.18372 (121 samples/sec)
2024-04-12 10:15:49.136066 epoch: 1 step: 1500 cls_loss= 0.92520 (121 samples/sec)
2024-04-12 10:18:00.395936 epoch: 1 step: 2000 cls_loss= 0.96266 (121 samples/sec)
2024-04-12 10:20:11.773144 epoch: 1 step: 2500 cls_loss= 0.94539 (121 samples/sec)
2024-04-12 10:22:23.276785 epoch: 1 step: 3000 cls_loss= 1.22627 (121 samples/sec)
2024-04-12 10:26:33.624639------------------------------------------------------ Precision@1: 75.84%  Precision@1: 92.78%

top1: [75.83800000000001]
top5: [92.776]
2024-04-12 10:26:34.034037 epoch: 2 step: 0 cls_loss= 1.11201 (39195 samples/sec)
2024-04-12 10:28:45.964474 epoch: 2 step: 500 cls_loss= 1.17526 (121 samples/sec)
2024-04-12 10:30:57.723682 epoch: 2 step: 1000 cls_loss= 0.58337 (121 samples/sec)
2024-04-12 10:33:09.475339 epoch: 2 step: 1500 cls_loss= 1.56309 (121 samples/sec)
2024-04-12 10:35:20.498261 epoch: 2 step: 2000 cls_loss= 1.32251 (122 samples/sec)
2024-04-12 10:37:33.192611 epoch: 2 step: 2500 cls_loss= 1.28039 (120 samples/sec)
2024-04-12 10:39:46.009095 epoch: 2 step: 3000 cls_loss= 1.16582 (120 samples/sec)
2024-04-12 10:43:57.431589------------------------------------------------------ Precision@1: 75.99%  Precision@1: 92.87%

top1: [75.83800000000001, 75.992]
top5: [92.776, 92.872]
2024-04-12 10:43:57.897024 epoch: 3 step: 0 cls_loss= 1.12170 (34506 samples/sec)
2024-04-12 10:46:10.621874 epoch: 3 step: 500 cls_loss= 0.97174 (120 samples/sec)
2024-04-12 10:48:22.945002 epoch: 3 step: 1000 cls_loss= 1.44487 (120 samples/sec)
2024-04-12 10:50:35.869017 epoch: 3 step: 1500 cls_loss= 1.02882 (120 samples/sec)
2024-04-12 10:52:48.111748 epoch: 3 step: 2000 cls_loss= 1.23705 (120 samples/sec)
2024-04-12 10:55:00.754394 epoch: 3 step: 2500 cls_loss= 1.73990 (120 samples/sec)
2024-04-12 10:57:13.085001 epoch: 3 step: 3000 cls_loss= 1.51768 (120 samples/sec)
2024-04-12 11:01:25.412264------------------------------------------------------ Precision@1: 76.07%  Precision@1: 92.77%

top1: [75.83800000000001, 75.992, 76.07000000000001]
top5: [92.776, 92.872, 92.772]
2024-04-12 11:01:25.832832 epoch: 4 step: 0 cls_loss= 1.44698 (38194 samples/sec)
2024-04-12 11:03:37.934602 epoch: 4 step: 500 cls_loss= 1.20418 (121 samples/sec)
2024-04-12 11:05:49.997668 epoch: 4 step: 1000 cls_loss= 1.00100 (121 samples/sec)
2024-04-12 11:08:01.989307 epoch: 4 step: 1500 cls_loss= 1.07111 (121 samples/sec)
2024-04-12 11:10:13.952002 epoch: 4 step: 2000 cls_loss= 0.62386 (121 samples/sec)
2024-04-12 11:12:25.834230 epoch: 4 step: 2500 cls_loss= 1.29902 (121 samples/sec)
2024-04-12 11:14:37.803315 epoch: 4 step: 3000 cls_loss= 1.19688 (121 samples/sec)
2024-04-12 11:18:48.951990------------------------------------------------------ Precision@1: 76.03%  Precision@1: 92.77%

top1: [75.83800000000001, 75.992, 76.07000000000001, 76.026]
top5: [92.776, 92.872, 92.772, 92.768]
2024-04-12 11:18:49.405952 epoch: 5 step: 0 cls_loss= 0.58566 (35370 samples/sec)
2024-04-12 11:21:01.078300 epoch: 5 step: 500 cls_loss= 1.17879 (121 samples/sec)
2024-04-12 11:23:13.275812 epoch: 5 step: 1000 cls_loss= 1.29238 (121 samples/sec)
2024-04-12 11:25:24.822711 epoch: 5 step: 1500 cls_loss= 0.81847 (121 samples/sec)
2024-04-12 11:27:36.376010 epoch: 5 step: 2000 cls_loss= 0.87167 (121 samples/sec)
2024-04-12 11:29:47.940243 epoch: 5 step: 2500 cls_loss= 1.11891 (121 samples/sec)
2024-04-12 11:31:59.666241 epoch: 5 step: 3000 cls_loss= 0.90919 (121 samples/sec)
2024-04-12 11:36:11.568360------------------------------------------------------ Precision@1: 75.83%  Precision@1: 92.82%

top1: [75.83800000000001, 75.992, 76.07000000000001, 76.026, 75.82600000000001]
top5: [92.776, 92.872, 92.772, 92.768, 92.822]
2024-04-12 11:36:11.980319 epoch: 6 step: 0 cls_loss= 1.19435 (38989 samples/sec)
2024-04-12 11:38:23.850131 epoch: 6 step: 500 cls_loss= 1.12023 (121 samples/sec)
2024-04-12 11:40:35.680431 epoch: 6 step: 1000 cls_loss= 0.96627 (121 samples/sec)
2024-04-12 11:42:47.478307 epoch: 6 step: 1500 cls_loss= 1.05458 (121 samples/sec)
2024-04-12 11:44:59.349474 epoch: 6 step: 2000 cls_loss= 1.19435 (121 samples/sec)
2024-04-12 11:47:11.100438 epoch: 6 step: 2500 cls_loss= 1.32171 (121 samples/sec)
2024-04-12 11:49:22.821311 epoch: 6 step: 3000 cls_loss= 0.89844 (121 samples/sec)
2024-04-12 11:53:34.659611------------------------------------------------------ Precision@1: 75.98%  Precision@1: 92.77%

top1: [75.83800000000001, 75.992, 76.07000000000001, 76.026, 75.82600000000001, 75.98]
top5: [92.776, 92.872, 92.772, 92.768, 92.822, 92.772]
=> creating model resnet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 11:53:38.420412 epoch: 1 step: 0 cls_loss= 1.45094 (8553 samples/sec)
2024-04-12 11:55:54.440897 epoch: 1 step: 500 cls_loss= 0.76040 (117 samples/sec)
2024-04-12 11:58:10.569166 epoch: 1 step: 1000 cls_loss= 1.13143 (117 samples/sec)
2024-04-12 12:00:26.636051 epoch: 1 step: 1500 cls_loss= 1.17324 (117 samples/sec)
2024-04-12 12:02:42.704062 epoch: 1 step: 2000 cls_loss= 1.23079 (117 samples/sec)
2024-04-12 12:04:58.776917 epoch: 1 step: 2500 cls_loss= 1.17924 (117 samples/sec)
2024-04-12 12:07:14.684322 epoch: 1 step: 3000 cls_loss= 1.53363 (117 samples/sec)
2024-04-12 12:11:28.440797------------------------------------------------------ Precision@1: 75.88%  Precision@1: 92.73%

top1: [75.878]
top5: [92.732]
2024-04-12 12:11:28.859513 epoch: 2 step: 0 cls_loss= 1.08934 (38346 samples/sec)
2024-04-12 12:13:44.317200 epoch: 2 step: 500 cls_loss= 0.99254 (118 samples/sec)
2024-04-12 12:15:59.659307 epoch: 2 step: 1000 cls_loss= 1.12394 (118 samples/sec)
2024-04-12 12:18:15.152650 epoch: 2 step: 1500 cls_loss= 1.29720 (118 samples/sec)
2024-04-12 12:20:30.644351 epoch: 2 step: 2000 cls_loss= 1.03513 (118 samples/sec)
2024-04-12 12:22:45.949042 epoch: 2 step: 2500 cls_loss= 1.30350 (118 samples/sec)
2024-04-12 12:25:01.196968 epoch: 2 step: 3000 cls_loss= 1.12757 (118 samples/sec)
2024-04-12 12:29:14.385901------------------------------------------------------ Precision@1: 76.02%  Precision@1: 92.83%

top1: [75.878, 76.02]
top5: [92.732, 92.82600000000001]
2024-04-12 12:29:14.815227 epoch: 3 step: 0 cls_loss= 1.27100 (37403 samples/sec)
2024-04-12 12:31:30.039661 epoch: 3 step: 500 cls_loss= 0.96991 (118 samples/sec)
2024-04-12 12:33:45.515179 epoch: 3 step: 1000 cls_loss= 0.71092 (118 samples/sec)
2024-04-12 12:36:01.268173 epoch: 3 step: 1500 cls_loss= 1.34457 (117 samples/sec)
2024-04-12 12:38:16.921403 epoch: 3 step: 2000 cls_loss= 1.47337 (117 samples/sec)
2024-04-12 12:40:32.775952 epoch: 3 step: 2500 cls_loss= 0.91283 (117 samples/sec)
2024-04-12 12:42:49.375671 epoch: 3 step: 3000 cls_loss= 1.31540 (117 samples/sec)
2024-04-12 12:47:23.583239------------------------------------------------------ Precision@1: 76.05%  Precision@1: 92.75%

top1: [75.878, 76.02, 76.048]
top5: [92.732, 92.82600000000001, 92.748]
2024-04-12 12:47:24.268083 epoch: 4 step: 0 cls_loss= 1.09558 (23441 samples/sec)
2024-04-12 12:50:20.636641 epoch: 4 step: 500 cls_loss= 1.55115 (90 samples/sec)
2024-04-12 12:53:33.622373 epoch: 4 step: 1000 cls_loss= 1.33395 (82 samples/sec)
2024-04-12 12:57:01.894627 epoch: 4 step: 1500 cls_loss= 1.75088 (76 samples/sec)
2024-04-12 13:00:51.373167 epoch: 4 step: 2000 cls_loss= 0.51614 (69 samples/sec)
2024-04-12 13:05:11.646847 epoch: 4 step: 2500 cls_loss= 0.96152 (61 samples/sec)
2024-04-12 13:10:47.376135 epoch: 4 step: 3000 cls_loss= 1.14019 (47 samples/sec)
2024-04-12 13:17:49.870457------------------------------------------------------ Precision@1: 75.96%  Precision@1: 92.79%

top1: [75.878, 76.02, 76.048, 75.964]
top5: [92.732, 92.82600000000001, 92.748, 92.788]
2024-04-12 13:17:50.581947 epoch: 5 step: 0 cls_loss= 0.81212 (22566 samples/sec)
2024-04-12 13:21:09.664362 epoch: 5 step: 500 cls_loss= 0.89327 (80 samples/sec)
2024-04-12 13:24:52.456992 epoch: 5 step: 1000 cls_loss= 1.12186 (71 samples/sec)
2024-04-12 13:29:02.063938 epoch: 5 step: 1500 cls_loss= 1.22628 (64 samples/sec)
2024-04-12 13:33:14.677060 epoch: 5 step: 2000 cls_loss= 0.87079 (63 samples/sec)
2024-04-12 13:37:29.193780 epoch: 5 step: 2500 cls_loss= 0.87758 (62 samples/sec)
2024-04-12 13:41:45.288997 epoch: 5 step: 3000 cls_loss= 0.90547 (62 samples/sec)
2024-04-12 13:48:50.190124------------------------------------------------------ Precision@1: 76.02%  Precision@1: 92.84%

top1: [75.878, 76.02, 76.048, 75.964, 76.016]
top5: [92.732, 92.82600000000001, 92.748, 92.788, 92.84400000000001]
2024-04-12 13:48:50.932386 epoch: 6 step: 0 cls_loss= 0.87698 (21606 samples/sec)
2024-04-12 13:51:45.635222 epoch: 6 step: 500 cls_loss= 1.44298 (91 samples/sec)
2024-04-12 13:54:59.757152 epoch: 6 step: 1000 cls_loss= 1.18407 (82 samples/sec)
2024-04-12 13:58:41.562874 epoch: 6 step: 1500 cls_loss= 0.44175 (72 samples/sec)
2024-04-12 14:03:02.077904 epoch: 6 step: 2000 cls_loss= 1.10761 (61 samples/sec)
2024-04-12 14:07:23.523641 epoch: 6 step: 2500 cls_loss= 1.20366 (61 samples/sec)
2024-04-12 14:11:55.682332 epoch: 6 step: 3000 cls_loss= 0.86493 (58 samples/sec)
2024-04-12 14:18:52.324705------------------------------------------------------ Precision@1: 76.01%  Precision@1: 92.82%

top1: [75.878, 76.02, 76.048, 75.964, 76.016, 76.006]
top5: [92.732, 92.82600000000001, 92.748, 92.788, 92.84400000000001, 92.824]
=> creating model resnet ...
 learning rate =  1e-05
SGD
2024-04-12 14:18:59.288299 epoch: 1 step: 0 cls_loss= 1.09648 (6287 samples/sec)
2024-04-12 14:21:54.342422 epoch: 1 step: 500 cls_loss= 1.15413 (91 samples/sec)
2024-04-12 14:25:11.261852 epoch: 1 step: 1000 cls_loss= 1.34840 (81 samples/sec)
2024-04-12 14:28:55.374400 epoch: 1 step: 1500 cls_loss= 0.76230 (71 samples/sec)
2024-04-12 14:33:02.691174 epoch: 1 step: 2000 cls_loss= 1.05091 (64 samples/sec)
2024-04-12 14:37:13.657632 epoch: 1 step: 2500 cls_loss= 0.94870 (63 samples/sec)
2024-04-12 14:41:26.849866 epoch: 1 step: 3000 cls_loss= 0.86655 (63 samples/sec)
2024-04-12 14:48:27.296378------------------------------------------------------ Precision@1: 76.03%  Precision@1: 92.81%

top1: [76.03]
top5: [92.81400000000001]
2024-04-12 14:48:27.851735 epoch: 2 step: 0 cls_loss= 0.95242 (28950 samples/sec)
2024-04-12 14:51:11.040644 epoch: 2 step: 500 cls_loss= 1.07552 (98 samples/sec)
2024-04-12 14:54:08.045060 epoch: 2 step: 1000 cls_loss= 1.25248 (90 samples/sec)
2024-04-12 14:57:31.794441 epoch: 2 step: 1500 cls_loss= 1.08366 (78 samples/sec)
2024-04-12 15:01:36.951408 epoch: 2 step: 2000 cls_loss= 1.72944 (65 samples/sec)
2024-04-12 15:05:58.363529 epoch: 2 step: 2500 cls_loss= 1.32225 (61 samples/sec)
2024-04-12 15:10:26.197022 epoch: 2 step: 3000 cls_loss= 0.52030 (59 samples/sec)
2024-04-12 15:17:21.064676------------------------------------------------------ Precision@1: 76.05%  Precision@1: 92.87%

top1: [76.03, 76.052]
top5: [92.81400000000001, 92.866]
2024-04-12 15:17:21.566163 epoch: 3 step: 0 cls_loss= 0.74130 (32049 samples/sec)
2024-04-12 15:19:58.736201 epoch: 3 step: 500 cls_loss= 0.54187 (101 samples/sec)
2024-04-12 15:22:51.359804 epoch: 3 step: 1000 cls_loss= 1.48974 (92 samples/sec)
2024-04-12 15:26:06.101273 epoch: 3 step: 1500 cls_loss= 1.38096 (82 samples/sec)
2024-04-12 15:29:57.501053 epoch: 3 step: 2000 cls_loss= 1.69362 (69 samples/sec)
2024-04-12 15:33:58.566319 epoch: 3 step: 2500 cls_loss= 1.61492 (66 samples/sec)
2024-04-12 15:38:07.139318 epoch: 3 step: 3000 cls_loss= 0.90954 (64 samples/sec)
2024-04-12 15:44:57.263879------------------------------------------------------ Precision@1: 76.15%  Precision@1: 92.85%

top1: [76.03, 76.052, 76.15]
top5: [92.81400000000001, 92.866, 92.854]
2024-04-12 15:44:57.808494 epoch: 4 step: 0 cls_loss= 0.99232 (29535 samples/sec)
2024-04-12 15:47:24.970731 epoch: 4 step: 500 cls_loss= 1.29638 (108 samples/sec)
2024-04-12 15:50:09.090577 epoch: 4 step: 1000 cls_loss= 0.64013 (97 samples/sec)
2024-04-12 15:53:17.228740 epoch: 4 step: 1500 cls_loss= 0.87010 (85 samples/sec)
2024-04-12 15:57:02.442973 epoch: 4 step: 2000 cls_loss= 0.57750 (71 samples/sec)
2024-04-12 16:01:09.209943 epoch: 4 step: 2500 cls_loss= 0.77438 (64 samples/sec)
2024-04-12 16:05:22.268853 epoch: 4 step: 3000 cls_loss= 0.84331 (63 samples/sec)
2024-04-12 16:12:15.938734------------------------------------------------------ Precision@1: 76.25%  Precision@1: 92.87%

top1: [76.03, 76.052, 76.15, 76.246]
top5: [92.81400000000001, 92.866, 92.854, 92.868]
2024-04-12 16:12:16.400782 epoch: 5 step: 0 cls_loss= 1.16893 (34782 samples/sec)
2024-04-12 16:14:32.245919 epoch: 5 step: 500 cls_loss= 0.90845 (117 samples/sec)
2024-04-12 16:17:02.203401 epoch: 5 step: 1000 cls_loss= 0.96037 (106 samples/sec)
2024-04-12 16:19:52.377669 epoch: 5 step: 1500 cls_loss= 1.06465 (94 samples/sec)
2024-04-12 16:23:10.517008 epoch: 5 step: 2000 cls_loss= 1.34080 (80 samples/sec)
2024-04-12 16:26:58.030996 epoch: 5 step: 2500 cls_loss= 1.50377 (70 samples/sec)
2024-04-12 16:30:53.101189 epoch: 5 step: 3000 cls_loss= 1.15649 (68 samples/sec)
2024-04-12 16:37:08.332722------------------------------------------------------ Precision@1: 76.25%  Precision@1: 92.90%

top1: [76.03, 76.052, 76.15, 76.246, 76.25]
top5: [92.81400000000001, 92.866, 92.854, 92.868, 92.904]
2024-04-12 16:37:08.679583 epoch: 6 step: 0 cls_loss= 0.78458 (46358 samples/sec)
2024-04-12 16:38:45.960509 epoch: 6 step: 500 cls_loss= 0.61336 (164 samples/sec)
2024-04-12 16:40:23.084497 epoch: 6 step: 1000 cls_loss= 1.27418 (164 samples/sec)
2024-04-12 16:41:59.893785 epoch: 6 step: 1500 cls_loss= 0.62331 (165 samples/sec)
2024-04-12 16:43:36.650719 epoch: 6 step: 2000 cls_loss= 1.30197 (165 samples/sec)
2024-04-12 16:45:13.925016 epoch: 6 step: 2500 cls_loss= 0.85664 (164 samples/sec)
2024-04-12 16:46:51.014679 epoch: 6 step: 3000 cls_loss= 1.22479 (164 samples/sec)
2024-04-12 16:51:16.022759------------------------------------------------------ Precision@1: 76.27%  Precision@1: 92.90%

top1: [76.03, 76.052, 76.15, 76.246, 76.25, 76.274]
top5: [92.81400000000001, 92.866, 92.854, 92.868, 92.904, 92.898]
=> creating model resnet ...
 learning rate =  1e-05
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 16:51:22.124410 epoch: 1 step: 0 cls_loss= 0.72529 (7899 samples/sec)
2024-04-12 16:53:41.693015 epoch: 1 step: 500 cls_loss= 1.23741 (114 samples/sec)
2024-04-12 16:56:00.920989 epoch: 1 step: 1000 cls_loss= 0.94175 (114 samples/sec)
2024-04-12 16:58:20.153171 epoch: 1 step: 1500 cls_loss= 1.47199 (114 samples/sec)
2024-04-12 17:00:39.706760 epoch: 1 step: 2000 cls_loss= 0.71965 (114 samples/sec)
2024-04-12 17:02:59.160682 epoch: 1 step: 2500 cls_loss= 1.18589 (114 samples/sec)
2024-04-12 17:05:18.237636 epoch: 1 step: 3000 cls_loss= 0.56662 (115 samples/sec)
2024-04-12 17:09:53.636792------------------------------------------------------ Precision@1: 76.10%  Precision@1: 92.87%

top1: [76.098]
top5: [92.874]
2024-04-12 17:09:54.060114 epoch: 2 step: 0 cls_loss= 1.19978 (37938 samples/sec)
2024-04-12 17:12:13.670257 epoch: 2 step: 500 cls_loss= 1.42807 (114 samples/sec)
2024-04-12 17:14:33.032176 epoch: 2 step: 1000 cls_loss= 0.89009 (114 samples/sec)
2024-04-12 17:16:52.698633 epoch: 2 step: 1500 cls_loss= 1.53147 (114 samples/sec)
2024-04-12 17:19:12.241095 epoch: 2 step: 2000 cls_loss= 1.03685 (114 samples/sec)
2024-04-12 17:21:31.857594 epoch: 2 step: 2500 cls_loss= 2.05574 (114 samples/sec)
2024-04-12 17:23:51.271744 epoch: 2 step: 3000 cls_loss= 1.65865 (114 samples/sec)
2024-04-12 17:28:26.044320------------------------------------------------------ Precision@1: 76.17%  Precision@1: 92.92%

top1: [76.098, 76.172]
top5: [92.874, 92.916]
2024-04-12 17:28:26.472666 epoch: 3 step: 0 cls_loss= 1.46145 (37477 samples/sec)
2024-04-12 17:30:46.306867 epoch: 3 step: 500 cls_loss= 1.76954 (114 samples/sec)
2024-04-12 17:33:05.963077 epoch: 3 step: 1000 cls_loss= 1.34994 (114 samples/sec)
2024-04-12 17:35:25.675576 epoch: 3 step: 1500 cls_loss= 1.40684 (114 samples/sec)
2024-04-12 17:37:45.066350 epoch: 3 step: 2000 cls_loss= 0.88015 (114 samples/sec)
2024-04-12 17:40:04.843442 epoch: 3 step: 2500 cls_loss= 0.68770 (114 samples/sec)
2024-04-12 17:42:24.511027 epoch: 3 step: 3000 cls_loss= 1.48616 (114 samples/sec)
2024-04-12 17:46:59.854521------------------------------------------------------ Precision@1: 76.21%  Precision@1: 92.98%

top1: [76.098, 76.172, 76.214]
top5: [92.874, 92.916, 92.98]
2024-04-12 17:47:00.290362 epoch: 4 step: 0 cls_loss= 1.31919 (36832 samples/sec)
2024-04-12 17:49:18.781260 epoch: 4 step: 500 cls_loss= 1.35367 (115 samples/sec)
2024-04-12 17:51:37.317390 epoch: 4 step: 1000 cls_loss= 1.14385 (115 samples/sec)
2024-04-12 17:53:55.641201 epoch: 4 step: 1500 cls_loss= 1.52814 (115 samples/sec)
2024-04-12 17:56:14.256886 epoch: 4 step: 2000 cls_loss= 0.62143 (115 samples/sec)
2024-04-12 17:58:32.863210 epoch: 4 step: 2500 cls_loss= 1.11743 (115 samples/sec)
2024-04-12 18:00:51.858100 epoch: 4 step: 3000 cls_loss= 0.94230 (115 samples/sec)
2024-04-12 18:05:26.539464------------------------------------------------------ Precision@1: 76.16%  Precision@1: 92.87%

top1: [76.098, 76.172, 76.214, 76.158]
top5: [92.874, 92.916, 92.98, 92.874]
2024-04-12 18:05:26.970744 epoch: 5 step: 0 cls_loss= 0.96510 (37243 samples/sec)
2024-04-12 18:07:46.547707 epoch: 5 step: 500 cls_loss= 0.97535 (114 samples/sec)
2024-04-12 18:10:07.078172 epoch: 5 step: 1000 cls_loss= 0.89273 (113 samples/sec)
2024-04-12 18:12:27.220809 epoch: 5 step: 1500 cls_loss= 1.61962 (114 samples/sec)
2024-04-12 18:14:47.251353 epoch: 5 step: 2000 cls_loss= 0.87455 (114 samples/sec)
2024-04-12 18:17:07.145947 epoch: 5 step: 2500 cls_loss= 1.26436 (114 samples/sec)
2024-04-12 18:19:26.976275 epoch: 5 step: 3000 cls_loss= 1.64060 (114 samples/sec)
2024-04-12 18:24:03.687409------------------------------------------------------ Precision@1: 76.27%  Precision@1: 92.89%

top1: [76.098, 76.172, 76.214, 76.158, 76.274]
top5: [92.874, 92.916, 92.98, 92.874, 92.888]
2024-04-12 18:24:04.113336 epoch: 6 step: 0 cls_loss= 1.11862 (37704 samples/sec)
2024-04-12 18:26:23.929007 epoch: 6 step: 500 cls_loss= 0.85574 (114 samples/sec)
2024-04-12 18:28:43.759945 epoch: 6 step: 1000 cls_loss= 1.43617 (114 samples/sec)
2024-04-12 18:31:03.632919 epoch: 6 step: 1500 cls_loss= 0.61430 (114 samples/sec)
2024-04-12 18:33:23.447674 epoch: 6 step: 2000 cls_loss= 1.13529 (114 samples/sec)
2024-04-12 18:35:43.128056 epoch: 6 step: 2500 cls_loss= 1.54887 (114 samples/sec)
2024-04-12 18:38:03.336370 epoch: 6 step: 3000 cls_loss= 1.36839 (114 samples/sec)
2024-04-12 18:42:39.060255------------------------------------------------------ Precision@1: 76.13%  Precision@1: 92.95%

top1: [76.098, 76.172, 76.214, 76.158, 76.274, 76.134]
top5: [92.874, 92.916, 92.98, 92.874, 92.888, 92.94800000000001]
=> creating model resnet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 18:42:42.857332 epoch: 1 step: 0 cls_loss= 1.42764 (8322 samples/sec)
^CTraceback (most recent call last):
  File "./imgnet_train_eval.py", line 346, in <module>
    main()
  File "./imgnet_train_eval.py", line 339, in main
    train(epoch)
  File "./imgnet_train_eval.py", line 175, in train
    output = model(inputs.cuda())
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/nets_imgnet/resnet50.py", line 240, in forward
    x = self.layer3(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/nets_imgnet/resnet50.py", line 78, in forward
    out = self.conv2(out)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/utils/conv2d_func.py", line 21, in forward
    self.input_q = self.quantize_act(input/self.Ka)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/utils/sfp_quant.py", line 160, in forward
    act_q = self.quantize(x)  
  File "/workspaces/pytorch-dev/SLFP_CNNs/utils/sfp_quant.py", line 87, in forward
    mantissa = input_abs / pow(2, exponent)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py", line 40, in wrapped
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/_tensor.py", line 866, in __rpow__
    return torch.tensor(other, dtype=dtype, device=self.device) ** self
KeyboardInterrupt

]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ 
[K]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model resnet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 18:44:42.672668 epoch: 1 step: 0 cls_loss= 1.31056 (8620 samples/sec)
2024-04-12 18:47:06.467008 epoch: 1 step: 500 cls_loss= 1.19957 (111 samples/sec)
2024-04-12 18:49:29.993539 epoch: 1 step: 1000 cls_loss= 1.03965 (111 samples/sec)
2024-04-12 18:51:53.205698 epoch: 1 step: 1500 cls_loss= 1.10352 (111 samples/sec)
2024-04-12 18:54:16.469257 epoch: 1 step: 2000 cls_loss= 1.17147 (111 samples/sec)
2024-04-12 18:56:40.323230 epoch: 1 step: 2500 cls_loss= 0.86333 (111 samples/sec)
2024-04-12 18:59:04.135261 epoch: 1 step: 3000 cls_loss= 1.17540 (111 samples/sec)
2024-04-12 19:03:42.240680------------------------------------------------------ Precision@1: 76.11%  Precision@1: 92.89%

top1: [76.106]
top5: [92.89]
2024-04-12 19:03:42.679672 epoch: 2 step: 0 cls_loss= 1.09099 (36592 samples/sec)
2024-04-12 19:06:06.830633 epoch: 2 step: 500 cls_loss= 1.00157 (110 samples/sec)
2024-04-12 19:08:31.017911 epoch: 2 step: 1000 cls_loss= 0.82254 (110 samples/sec)
2024-04-12 19:10:54.751037 epoch: 2 step: 1500 cls_loss= 0.84610 (111 samples/sec)
2024-04-12 19:13:18.504529 epoch: 2 step: 2000 cls_loss= 1.34112 (111 samples/sec)
2024-04-12 19:15:42.509243 epoch: 2 step: 2500 cls_loss= 0.79651 (111 samples/sec)
2024-04-12 19:18:06.699643 epoch: 2 step: 3000 cls_loss= 1.27779 (110 samples/sec)
2024-04-12 19:22:44.175434------------------------------------------------------ Precision@1: 76.19%  Precision@1: 92.92%

top1: [76.106, 76.186]
top5: [92.89, 92.92]
2024-04-12 19:22:44.623184 epoch: 3 step: 0 cls_loss= 0.98739 (35877 samples/sec)
2024-04-12 19:25:08.873909 epoch: 3 step: 500 cls_loss= 1.53976 (110 samples/sec)
2024-04-12 19:27:51.844648 epoch: 3 step: 1000 cls_loss= 0.70581 (98 samples/sec)
2024-04-12 19:30:59.406552 epoch: 3 step: 1500 cls_loss= 1.26632 (85 samples/sec)
2024-04-12 19:34:06.885751 epoch: 3 step: 2000 cls_loss= 0.64584 (85 samples/sec)
2024-04-12 19:37:13.296541 epoch: 3 step: 2500 cls_loss= 0.84709 (85 samples/sec)
2024-04-12 19:40:31.360038 epoch: 3 step: 3000 cls_loss= 0.87164 (80 samples/sec)
2024-04-12 19:46:42.838872------------------------------------------------------ Precision@1: 76.22%  Precision@1: 92.94%

top1: [76.106, 76.186, 76.21600000000001]
top5: [92.89, 92.92, 92.936]
=> creating model mobilenet ...
 learning rate =  1e-05
SGD
2024-04-12 19:46:46.640784 epoch: 1 step: 0 cls_loss= 1.80717 (11606 samples/sec)
2024-04-12 19:49:47.172772 epoch: 1 step: 500 cls_loss= 2.08577 (88 samples/sec)
2024-04-12 19:53:07.274612 epoch: 1 step: 1000 cls_loss= 1.76705 (79 samples/sec)
2024-04-12 19:56:35.723791 epoch: 1 step: 1500 cls_loss= 2.01078 (76 samples/sec)
2024-04-12 20:00:05.455649 epoch: 1 step: 2000 cls_loss= 1.95757 (76 samples/sec)
2024-04-12 20:03:35.945252 epoch: 1 step: 2500 cls_loss= 2.66707 (76 samples/sec)
2024-04-12 20:07:02.985946 epoch: 1 step: 3000 cls_loss= 2.58552 (77 samples/sec)
2024-04-12 20:13:35.513092------------------------------------------------------ Precision@1: 66.93%  Precision@1: 87.39%

top1: [66.93]
top5: [87.39]
2024-04-12 20:13:36.041995 epoch: 2 step: 0 cls_loss= 1.96319 (30353 samples/sec)
2024-04-12 20:16:20.364406 epoch: 2 step: 500 cls_loss= 1.50043 (97 samples/sec)
2024-04-12 20:19:19.098936 epoch: 2 step: 1000 cls_loss= 2.14639 (89 samples/sec)
2024-04-12 20:22:40.438227 epoch: 2 step: 1500 cls_loss= 1.58743 (79 samples/sec)
2024-04-12 20:26:10.028833 epoch: 2 step: 2000 cls_loss= 2.53773 (76 samples/sec)
2024-04-12 20:29:41.536120 epoch: 2 step: 2500 cls_loss= 2.46439 (75 samples/sec)
2024-04-12 20:33:28.866817 epoch: 2 step: 3000 cls_loss= 1.77582 (70 samples/sec)
2024-04-12 20:40:03.308791------------------------------------------------------ Precision@1: 66.92%  Precision@1: 87.59%

top1: [66.93, 66.922]
top5: [87.39, 87.59400000000001]
2024-04-12 20:40:03.759112 epoch: 3 step: 0 cls_loss= 1.75473 (35665 samples/sec)
2024-04-12 20:42:42.252978 epoch: 3 step: 500 cls_loss= 2.40227 (100 samples/sec)
2024-04-12 20:45:40.076056 epoch: 3 step: 1000 cls_loss= 1.88667 (89 samples/sec)
2024-04-12 20:49:01.574655 epoch: 3 step: 1500 cls_loss= 1.78123 (79 samples/sec)
2024-04-12 20:52:34.945766 epoch: 3 step: 2000 cls_loss= 2.09119 (74 samples/sec)
2024-04-12 20:56:14.546935 epoch: 3 step: 2500 cls_loss= 1.30085 (72 samples/sec)
2024-04-12 21:00:00.906847 epoch: 3 step: 3000 cls_loss= 2.69810 (70 samples/sec)
2024-04-12 21:06:26.460030------------------------------------------------------ Precision@1: 67.32%  Precision@1: 87.72%

top1: [66.93, 66.922, 67.322]
top5: [87.39, 87.59400000000001, 87.72]
=> creating model mobilenet ...
 learning rate =  1e-05
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 21:06:32.185089 epoch: 1 step: 0 cls_loss= 2.13623 (10221 samples/sec)
2024-04-12 21:09:11.967105 epoch: 1 step: 500 cls_loss= 2.11093 (100 samples/sec)
2024-04-12 21:12:10.622721 epoch: 1 step: 1000 cls_loss= 1.61617 (89 samples/sec)
2024-04-12 21:15:36.850046 epoch: 1 step: 1500 cls_loss= 1.42664 (77 samples/sec)
2024-04-12 21:19:29.598212 epoch: 1 step: 2000 cls_loss= 2.30391 (68 samples/sec)
2024-04-12 21:23:25.663788 epoch: 1 step: 2500 cls_loss= 1.50688 (67 samples/sec)
2024-04-12 21:27:32.108968 epoch: 1 step: 3000 cls_loss= 1.72147 (64 samples/sec)
2024-04-12 21:34:14.490476------------------------------------------------------ Precision@1: 67.20%  Precision@1: 87.68%

top1: [67.2]
top5: [87.682]
2024-04-12 21:34:14.989292 epoch: 2 step: 0 cls_loss= 1.34406 (32158 samples/sec)
2024-04-12 21:36:44.990973 epoch: 2 step: 500 cls_loss= 2.20372 (106 samples/sec)
2024-04-12 21:39:30.559028 epoch: 2 step: 1000 cls_loss= 1.97337 (96 samples/sec)
2024-04-12 21:42:41.352357 epoch: 2 step: 1500 cls_loss= 1.99692 (83 samples/sec)
2024-04-12 21:46:26.949309 epoch: 2 step: 2000 cls_loss= 2.40958 (70 samples/sec)
2024-04-12 21:50:26.351386 epoch: 2 step: 2500 cls_loss= 2.10073 (66 samples/sec)
2024-04-12 21:54:25.859630 epoch: 2 step: 3000 cls_loss= 2.57598 (66 samples/sec)
2024-04-12 22:00:56.656039------------------------------------------------------ Precision@1: 67.10%  Precision@1: 87.61%

top1: [67.2, 67.102]
top5: [87.682, 87.61]
2024-04-12 22:00:57.079197 epoch: 3 step: 0 cls_loss= 0.70481 (37969 samples/sec)
2024-04-12 22:03:26.859145 epoch: 3 step: 500 cls_loss= 1.65407 (106 samples/sec)
2024-04-12 22:06:16.528529 epoch: 3 step: 1000 cls_loss= 1.96960 (94 samples/sec)
2024-04-12 22:09:30.897278 epoch: 3 step: 1500 cls_loss= 2.11790 (82 samples/sec)
2024-04-12 22:13:22.079606 epoch: 3 step: 2000 cls_loss= 1.64290 (69 samples/sec)
2024-04-12 22:17:37.059658 epoch: 3 step: 2500 cls_loss= 1.55653 (62 samples/sec)
2024-04-12 22:22:00.053989 epoch: 3 step: 3000 cls_loss= 1.07837 (60 samples/sec)
2024-04-12 22:28:44.334952------------------------------------------------------ Precision@1: 67.14%  Precision@1: 87.75%

top1: [67.2, 67.102, 67.136]
top5: [87.682, 87.61, 87.754]
=> creating model mobilenet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-12 22:28:49.057507 epoch: 1 step: 0 cls_loss= 2.15308 (11443 samples/sec)
2024-04-12 22:31:26.568867 epoch: 1 step: 500 cls_loss= 2.23499 (101 samples/sec)
2024-04-12 22:34:28.807268 epoch: 1 step: 1000 cls_loss= 1.87302 (87 samples/sec)
2024-04-12 22:37:57.465210 epoch: 1 step: 1500 cls_loss= 1.58290 (76 samples/sec)
2024-04-12 22:41:56.448749 epoch: 1 step: 2000 cls_loss= 1.85042 (66 samples/sec)
2024-04-12 22:46:13.568629 epoch: 1 step: 2500 cls_loss= 1.47049 (62 samples/sec)
2024-04-12 22:50:40.154951 epoch: 1 step: 3000 cls_loss= 2.19229 (60 samples/sec)
2024-04-12 22:57:30.409900------------------------------------------------------ Precision@1: 67.20%  Precision@1: 87.62%

top1: [67.196]
top5: [87.62]
2024-04-12 22:57:31.044884 epoch: 2 step: 0 cls_loss= 2.24418 (25276 samples/sec)
2024-04-12 23:00:17.244203 epoch: 2 step: 500 cls_loss= 1.74698 (96 samples/sec)
2024-04-12 23:03:20.059331 epoch: 2 step: 1000 cls_loss= 1.23099 (87 samples/sec)
2024-04-12 23:06:53.266815 epoch: 2 step: 1500 cls_loss= 1.83754 (75 samples/sec)
2024-04-12 23:11:17.078537 epoch: 2 step: 2000 cls_loss= 2.40062 (60 samples/sec)
2024-04-12 23:16:13.865231 epoch: 2 step: 2500 cls_loss= 1.97004 (53 samples/sec)
2024-04-12 23:21:19.822257 epoch: 2 step: 3000 cls_loss= 1.32364 (52 samples/sec)
2024-04-12 23:28:26.256579------------------------------------------------------ Precision@1: 67.30%  Precision@1: 87.69%

top1: [67.196, 67.296]
top5: [87.62, 87.686]
2024-04-12 23:28:26.714763 epoch: 3 step: 0 cls_loss= 1.61727 (35058 samples/sec)
2024-04-12 23:31:31.156991 epoch: 3 step: 500 cls_loss= 2.33779 (86 samples/sec)
2024-04-12 23:34:57.348707 epoch: 3 step: 1000 cls_loss= 1.89834 (77 samples/sec)
2024-04-12 23:38:17.199275 epoch: 3 step: 1500 cls_loss= 1.39133 (80 samples/sec)
2024-04-12 23:41:40.349834 epoch: 3 step: 2000 cls_loss= 1.98928 (78 samples/sec)
2024-04-12 23:44:59.805914 epoch: 3 step: 2500 cls_loss= 1.60354 (80 samples/sec)
2024-04-12 23:48:22.320170 epoch: 3 step: 3000 cls_loss= 1.55544 (79 samples/sec)
2024-04-12 23:52:00.039877------------------------------------------------------ Precision@1: 67.26%  Precision@1: 87.71%

top1: [67.196, 67.296, 67.256]
top5: [87.62, 87.686, 87.712]
=> creating model mobilenet ...
 learning rate =  1e-05
SGD
2024-04-12 23:52:04.732286 epoch: 1 step: 0 cls_loss= 1.69936 (11578 samples/sec)
2024-04-12 23:53:01.073104 epoch: 1 step: 500 cls_loss= 2.07879 (283 samples/sec)
2024-04-12 23:53:57.924765 epoch: 1 step: 1000 cls_loss= 1.72790 (281 samples/sec)
2024-04-12 23:54:54.012217 epoch: 1 step: 1500 cls_loss= 1.91899 (285 samples/sec)
2024-04-12 23:55:50.741213 epoch: 1 step: 2000 cls_loss= 2.08225 (282 samples/sec)
2024-04-12 23:56:47.894472 epoch: 1 step: 2500 cls_loss= 1.92299 (280 samples/sec)
2024-04-12 23:57:44.412855 epoch: 1 step: 3000 cls_loss= 1.07166 (283 samples/sec)
2024-04-13 00:00:40.617999------------------------------------------------------ Precision@1: 67.68%  Precision@1: 88.06%

top1: [67.684]
top5: [88.06400000000001]
2024-04-13 00:00:40.841982 epoch: 2 step: 0 cls_loss= 2.18938 (71797 samples/sec)
2024-04-13 00:01:37.784183 epoch: 2 step: 500 cls_loss= 1.62375 (281 samples/sec)
2024-04-13 00:02:34.179334 epoch: 2 step: 1000 cls_loss= 1.56107 (283 samples/sec)
2024-04-13 00:03:31.545989 epoch: 2 step: 1500 cls_loss= 2.19128 (278 samples/sec)
2024-04-13 00:04:28.607814 epoch: 2 step: 2000 cls_loss= 1.28276 (280 samples/sec)
2024-04-13 00:05:26.177154 epoch: 2 step: 2500 cls_loss= 1.75425 (278 samples/sec)
2024-04-13 00:06:23.488001 epoch: 2 step: 3000 cls_loss= 1.39921 (279 samples/sec)
2024-04-13 00:09:27.495013------------------------------------------------------ Precision@1: 67.93%  Precision@1: 88.14%

top1: [67.684, 67.926]
top5: [88.06400000000001, 88.142]
2024-04-13 00:09:27.708842 epoch: 3 step: 0 cls_loss= 1.77895 (75216 samples/sec)
2024-04-13 00:10:24.452607 epoch: 3 step: 500 cls_loss= 2.47634 (282 samples/sec)
2024-04-13 00:11:21.422672 epoch: 3 step: 1000 cls_loss= 2.15196 (280 samples/sec)
2024-04-13 00:12:18.960252 epoch: 3 step: 1500 cls_loss= 2.26800 (278 samples/sec)
2024-04-13 00:13:16.754959 epoch: 3 step: 2000 cls_loss= 1.83657 (276 samples/sec)
2024-04-13 00:14:13.524901 epoch: 3 step: 2500 cls_loss= 2.39189 (281 samples/sec)
2024-04-13 00:15:10.883895 epoch: 3 step: 3000 cls_loss= 1.72853 (279 samples/sec)
2024-04-13 00:18:13.844921------------------------------------------------------ Precision@1: 68.02%  Precision@1: 87.97%

top1: [67.684, 67.926, 68.022]
top5: [88.06400000000001, 88.142, 87.96600000000001]
=> creating model mobilenet ...
 learning rate =  1e-05
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 00:18:16.193411 epoch: 1 step: 0 cls_loss= 1.54422 (17444 samples/sec)
2024-04-13 00:19:19.445854 epoch: 1 step: 500 cls_loss= 2.02471 (252 samples/sec)
2024-04-13 00:20:22.723410 epoch: 1 step: 1000 cls_loss= 2.02423 (252 samples/sec)
2024-04-13 00:21:25.842584 epoch: 1 step: 1500 cls_loss= 1.71449 (253 samples/sec)
2024-04-13 00:22:29.200237 epoch: 1 step: 2000 cls_loss= 1.38902 (252 samples/sec)
2024-04-13 00:23:32.577725 epoch: 1 step: 2500 cls_loss= 1.70423 (252 samples/sec)
2024-04-13 00:24:36.116408 epoch: 1 step: 3000 cls_loss= 2.20823 (251 samples/sec)
2024-04-13 00:27:38.231271------------------------------------------------------ Precision@1: 67.67%  Precision@1: 88.11%

top1: [67.668]
top5: [88.114]
2024-04-13 00:27:38.502051 epoch: 2 step: 0 cls_loss= 1.32271 (59348 samples/sec)
2024-04-13 00:28:41.605143 epoch: 2 step: 500 cls_loss= 1.99499 (253 samples/sec)
2024-04-13 00:29:44.767030 epoch: 2 step: 1000 cls_loss= 2.14772 (253 samples/sec)
2024-04-13 00:30:47.938009 epoch: 2 step: 1500 cls_loss= 0.90047 (253 samples/sec)
2024-04-13 00:31:51.188409 epoch: 2 step: 2000 cls_loss= 2.04931 (252 samples/sec)
2024-04-13 00:32:54.378314 epoch: 2 step: 2500 cls_loss= 1.78591 (253 samples/sec)
2024-04-13 00:33:57.596354 epoch: 2 step: 3000 cls_loss= 1.48648 (253 samples/sec)
2024-04-13 00:36:58.289757------------------------------------------------------ Precision@1: 67.82%  Precision@1: 88.02%

top1: [67.668, 67.82000000000001]
top5: [88.114, 88.016]
2024-04-13 00:36:58.565223 epoch: 3 step: 0 cls_loss= 1.52164 (58352 samples/sec)
2024-04-13 00:38:01.811736 epoch: 3 step: 500 cls_loss= 1.29246 (252 samples/sec)
2024-04-13 00:39:05.004939 epoch: 3 step: 1000 cls_loss= 2.06070 (253 samples/sec)
2024-04-13 00:40:08.203942 epoch: 3 step: 1500 cls_loss= 1.69885 (253 samples/sec)
2024-04-13 00:41:11.433841 epoch: 3 step: 2000 cls_loss= 2.47773 (253 samples/sec)
2024-04-13 00:42:14.767775 epoch: 3 step: 2500 cls_loss= 1.44903 (252 samples/sec)
2024-04-13 00:43:18.212161 epoch: 3 step: 3000 cls_loss= 1.73124 (252 samples/sec)
2024-04-13 00:46:21.323384------------------------------------------------------ Precision@1: 67.89%  Precision@1: 88.10%

top1: [67.668, 67.82000000000001, 67.892]
top5: [88.114, 88.016, 88.096]
=> creating model mobilenet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 00:46:23.693153 epoch: 1 step: 0 cls_loss= 1.83854 (17359 samples/sec)
2024-04-13 00:47:28.371687 epoch: 1 step: 500 cls_loss= 2.57363 (247 samples/sec)
2024-04-13 00:48:32.999990 epoch: 1 step: 1000 cls_loss= 2.27944 (247 samples/sec)
2024-04-13 00:49:39.166812 epoch: 1 step: 1500 cls_loss= 1.58182 (241 samples/sec)
2024-04-13 00:50:45.382583 epoch: 1 step: 2000 cls_loss= 1.88448 (241 samples/sec)
2024-04-13 00:51:51.621133 epoch: 1 step: 2500 cls_loss= 1.94865 (241 samples/sec)
2024-04-13 00:52:58.023319 epoch: 1 step: 3000 cls_loss= 1.45382 (240 samples/sec)
2024-04-13 00:56:00.600290------------------------------------------------------ Precision@1: 67.73%  Precision@1: 88.10%

top1: [67.734]
top5: [88.104]
2024-04-13 00:56:00.879111 epoch: 2 step: 0 cls_loss= 1.88177 (57624 samples/sec)
2024-04-13 00:57:05.529197 epoch: 2 step: 500 cls_loss= 1.35634 (247 samples/sec)
2024-04-13 00:58:10.125405 epoch: 2 step: 1000 cls_loss= 1.61326 (247 samples/sec)
2024-04-13 00:59:14.795240 epoch: 2 step: 1500 cls_loss= 0.88886 (247 samples/sec)
2024-04-13 01:00:19.707126 epoch: 2 step: 2000 cls_loss= 1.98070 (246 samples/sec)
2024-04-13 01:01:24.282981 epoch: 2 step: 2500 cls_loss= 2.05828 (247 samples/sec)
2024-04-13 01:02:28.881448 epoch: 2 step: 3000 cls_loss= 1.47770 (247 samples/sec)
2024-04-13 01:05:32.181308------------------------------------------------------ Precision@1: 67.87%  Precision@1: 87.99%

top1: [67.734, 67.866]
top5: [88.104, 87.992]
2024-04-13 01:05:32.465609 epoch: 3 step: 0 cls_loss= 1.75154 (56499 samples/sec)
2024-04-13 01:06:37.027216 epoch: 3 step: 500 cls_loss= 2.14786 (247 samples/sec)
2024-04-13 01:07:41.550830 epoch: 3 step: 1000 cls_loss= 1.38949 (247 samples/sec)
2024-04-13 01:08:46.119786 epoch: 3 step: 1500 cls_loss= 1.89202 (247 samples/sec)
2024-04-13 01:09:50.699573 epoch: 3 step: 2000 cls_loss= 1.65159 (247 samples/sec)
2024-04-13 01:10:55.243466 epoch: 3 step: 2500 cls_loss= 1.11277 (247 samples/sec)
2024-04-13 01:11:59.709510 epoch: 3 step: 3000 cls_loss= 1.66033 (248 samples/sec)
2024-04-13 01:15:01.464141------------------------------------------------------ Precision@1: 67.90%  Precision@1: 88.11%

top1: [67.734, 67.866, 67.9]
top5: [88.104, 87.992, 88.11]
=> creating model alexnet ...
 learning rate =  1e-05
SGD
2024-04-13 01:15:04.246094 epoch: 1 step: 0 cls_loss= 1.61606 (23816 samples/sec)
2024-04-13 01:15:59.405334 epoch: 1 step: 500 cls_loss= 2.11581 (290 samples/sec)
2024-04-13 01:16:57.193771 epoch: 1 step: 1000 cls_loss= 2.63878 (276 samples/sec)
2024-04-13 01:17:54.129769 epoch: 1 step: 1500 cls_loss= 2.86864 (281 samples/sec)
2024-04-13 01:18:51.121964 epoch: 1 step: 2000 cls_loss= 2.77602 (280 samples/sec)
2024-04-13 01:19:48.098615 epoch: 1 step: 2500 cls_loss= 2.08053 (280 samples/sec)
2024-04-13 01:20:45.557310 epoch: 1 step: 3000 cls_loss= 1.98614 (278 samples/sec)
2024-04-13 01:23:43.332553------------------------------------------------------ Precision@1: 56.02%  Precision@1: 78.67%

top1: [56.02]
top5: [78.674]
2024-04-13 01:23:43.503456 epoch: 2 step: 0 cls_loss= 2.05967 (94084 samples/sec)
2024-04-13 01:24:40.198324 epoch: 2 step: 500 cls_loss= 2.34871 (282 samples/sec)
2024-04-13 01:25:36.212967 epoch: 2 step: 1000 cls_loss= 2.29379 (285 samples/sec)
2024-04-13 01:26:32.449737 epoch: 2 step: 1500 cls_loss= 3.10653 (284 samples/sec)
2024-04-13 01:27:27.982428 epoch: 2 step: 2000 cls_loss= 2.47631 (288 samples/sec)
2024-04-13 01:28:24.301726 epoch: 2 step: 2500 cls_loss= 2.51480 (284 samples/sec)
2024-04-13 01:29:19.930512 epoch: 2 step: 3000 cls_loss= 3.52795 (287 samples/sec)
2024-04-13 01:32:16.851747------------------------------------------------------ Precision@1: 56.01%  Precision@1: 78.73%

top1: [56.02, 56.008]
top5: [78.674, 78.726]
2024-04-13 01:32:17.037998 epoch: 3 step: 0 cls_loss= 2.26885 (86304 samples/sec)
2024-04-13 01:33:13.078111 epoch: 3 step: 500 cls_loss= 1.69123 (285 samples/sec)
2024-04-13 01:34:08.631199 epoch: 3 step: 1000 cls_loss= 1.93550 (288 samples/sec)
2024-04-13 01:35:03.847693 epoch: 3 step: 1500 cls_loss= 2.44005 (289 samples/sec)
2024-04-13 01:36:00.269845 epoch: 3 step: 2000 cls_loss= 2.39452 (283 samples/sec)
2024-04-13 01:36:56.685807 epoch: 3 step: 2500 cls_loss= 2.35583 (283 samples/sec)
2024-04-13 01:37:52.477688 epoch: 3 step: 3000 cls_loss= 2.07485 (286 samples/sec)
2024-04-13 01:40:48.852959------------------------------------------------------ Precision@1: 55.97%  Precision@1: 78.61%

top1: [56.02, 56.008, 55.97]
top5: [78.674, 78.726, 78.612]
=> creating model alexnet ...
 learning rate =  1e-05
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 01:40:51.375395 epoch: 1 step: 0 cls_loss= 2.21292 (23850 samples/sec)
2024-04-13 01:41:47.573439 epoch: 1 step: 500 cls_loss= 2.70378 (284 samples/sec)
2024-04-13 01:42:44.532975 epoch: 1 step: 1000 cls_loss= 2.71684 (280 samples/sec)
2024-04-13 01:43:41.899011 epoch: 1 step: 1500 cls_loss= 2.46628 (278 samples/sec)
2024-04-13 01:44:38.567781 epoch: 1 step: 2000 cls_loss= 1.91556 (282 samples/sec)
2024-04-13 01:45:35.522989 epoch: 1 step: 2500 cls_loss= 2.84296 (280 samples/sec)
2024-04-13 01:46:33.286944 epoch: 1 step: 3000 cls_loss= 2.28453 (276 samples/sec)
2024-04-13 01:49:34.182153------------------------------------------------------ Precision@1: 55.83%  Precision@1: 78.63%

top1: [55.826]
top5: [78.634]
2024-04-13 01:49:34.390714 epoch: 2 step: 0 cls_loss= 2.19212 (77030 samples/sec)
2024-04-13 01:50:31.486937 epoch: 2 step: 500 cls_loss= 2.87732 (280 samples/sec)
2024-04-13 01:51:28.066222 epoch: 2 step: 1000 cls_loss= 1.71054 (282 samples/sec)
2024-04-13 01:52:25.335457 epoch: 2 step: 1500 cls_loss= 2.63770 (279 samples/sec)
2024-04-13 01:53:21.391684 epoch: 2 step: 2000 cls_loss= 2.53820 (285 samples/sec)
2024-04-13 01:54:18.006086 epoch: 2 step: 2500 cls_loss= 1.81110 (282 samples/sec)
2024-04-13 01:55:14.686129 epoch: 2 step: 3000 cls_loss= 2.17661 (282 samples/sec)
2024-04-13 01:58:15.161967------------------------------------------------------ Precision@1: 55.96%  Precision@1: 78.72%

top1: [55.826, 55.958]
top5: [78.634, 78.718]
2024-04-13 01:58:15.373271 epoch: 3 step: 0 cls_loss= 2.08969 (76049 samples/sec)
2024-04-13 01:59:11.658792 epoch: 3 step: 500 cls_loss= 2.66059 (284 samples/sec)
2024-04-13 02:00:08.733044 epoch: 3 step: 1000 cls_loss= 2.41515 (280 samples/sec)
2024-04-13 02:01:05.177730 epoch: 3 step: 1500 cls_loss= 2.71981 (283 samples/sec)
2024-04-13 02:02:01.652671 epoch: 3 step: 2000 cls_loss= 1.31488 (283 samples/sec)
2024-04-13 02:02:58.392670 epoch: 3 step: 2500 cls_loss= 3.11005 (281 samples/sec)
2024-04-13 02:03:55.178176 epoch: 3 step: 3000 cls_loss= 2.14590 (281 samples/sec)
2024-04-13 02:06:52.234464------------------------------------------------------ Precision@1: 55.88%  Precision@1: 78.48%

top1: [55.826, 55.958, 55.88]
top5: [78.634, 78.718, 78.484]
=> creating model alexnet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 02:06:54.740635 epoch: 1 step: 0 cls_loss= 2.33184 (24230 samples/sec)
2024-04-13 02:07:50.973262 epoch: 1 step: 500 cls_loss= 1.79488 (284 samples/sec)
2024-04-13 02:08:47.900781 epoch: 1 step: 1000 cls_loss= 2.55727 (281 samples/sec)
2024-04-13 02:09:45.628166 epoch: 1 step: 1500 cls_loss= 2.78251 (277 samples/sec)
2024-04-13 02:10:42.554745 epoch: 1 step: 2000 cls_loss= 2.69175 (281 samples/sec)
2024-04-13 02:11:39.643688 epoch: 1 step: 2500 cls_loss= 2.31089 (280 samples/sec)
2024-04-13 02:12:36.833581 epoch: 1 step: 3000 cls_loss= 1.79776 (279 samples/sec)
2024-04-13 02:15:34.314527------------------------------------------------------ Precision@1: 55.83%  Precision@1: 78.53%

top1: [55.832]
top5: [78.526]
2024-04-13 02:15:34.527354 epoch: 2 step: 0 cls_loss= 2.06000 (75495 samples/sec)
2024-04-13 02:16:31.141911 epoch: 2 step: 500 cls_loss= 2.58293 (282 samples/sec)
2024-04-13 02:17:27.096960 epoch: 2 step: 1000 cls_loss= 2.78213 (285 samples/sec)
2024-04-13 02:18:23.535309 epoch: 2 step: 1500 cls_loss= 2.38434 (283 samples/sec)
2024-04-13 02:19:19.981917 epoch: 2 step: 2000 cls_loss= 2.01863 (283 samples/sec)
2024-04-13 02:20:17.460479 epoch: 2 step: 2500 cls_loss= 2.60427 (278 samples/sec)
2024-04-13 02:21:14.162111 epoch: 2 step: 3000 cls_loss= 2.11401 (282 samples/sec)
2024-04-13 02:24:13.775609------------------------------------------------------ Precision@1: 55.82%  Precision@1: 78.56%

top1: [55.832, 55.822]
top5: [78.526, 78.558]
2024-04-13 02:24:13.989593 epoch: 3 step: 0 cls_loss= 2.43997 (75099 samples/sec)
2024-04-13 02:25:10.346798 epoch: 3 step: 500 cls_loss= 2.08725 (283 samples/sec)
2024-04-13 02:26:08.263205 epoch: 3 step: 1000 cls_loss= 3.25466 (276 samples/sec)
2024-04-13 02:27:06.276764 epoch: 3 step: 1500 cls_loss= 2.62430 (275 samples/sec)
2024-04-13 02:28:03.525929 epoch: 3 step: 2000 cls_loss= 2.03500 (279 samples/sec)
2024-04-13 02:29:01.009235 epoch: 3 step: 2500 cls_loss= 1.46560 (278 samples/sec)
2024-04-13 02:29:58.270459 epoch: 3 step: 3000 cls_loss= 2.68884 (279 samples/sec)
2024-04-13 02:32:56.874680------------------------------------------------------ Precision@1: 55.76%  Precision@1: 78.58%

top1: [55.832, 55.822, 55.76]
top5: [78.526, 78.558, 78.57600000000001]
=> creating model alexnet ...
 learning rate =  1e-05
SGD
2024-04-13 02:32:59.350781 epoch: 1 step: 0 cls_loss= 1.82008 (25994 samples/sec)
2024-04-13 02:33:56.213097 epoch: 1 step: 500 cls_loss= 1.90203 (281 samples/sec)
2024-04-13 02:34:52.664348 epoch: 1 step: 1000 cls_loss= 2.65564 (283 samples/sec)
2024-04-13 02:35:49.242068 epoch: 1 step: 1500 cls_loss= 3.25662 (282 samples/sec)
2024-04-13 02:36:45.198656 epoch: 1 step: 2000 cls_loss= 2.59726 (285 samples/sec)
2024-04-13 02:37:42.078413 epoch: 1 step: 2500 cls_loss= 2.51107 (281 samples/sec)
2024-04-13 02:38:37.707178 epoch: 1 step: 3000 cls_loss= 2.22728 (287 samples/sec)
2024-04-13 02:41:35.336764------------------------------------------------------ Precision@1: 56.01%  Precision@1: 78.74%

top1: [56.01]
top5: [78.74]
2024-04-13 02:41:35.503161 epoch: 2 step: 0 cls_loss= 1.91831 (96646 samples/sec)
2024-04-13 02:42:32.543969 epoch: 2 step: 500 cls_loss= 2.32389 (280 samples/sec)
2024-04-13 02:43:28.739213 epoch: 2 step: 1000 cls_loss= 2.26952 (284 samples/sec)
2024-04-13 02:44:25.234330 epoch: 2 step: 1500 cls_loss= 2.62255 (283 samples/sec)
2024-04-13 02:45:22.758480 epoch: 2 step: 2000 cls_loss= 2.46063 (278 samples/sec)
2024-04-13 02:46:19.300423 epoch: 2 step: 2500 cls_loss= 2.01823 (283 samples/sec)
2024-04-13 02:47:15.693475 epoch: 2 step: 3000 cls_loss= 2.31844 (283 samples/sec)
2024-04-13 02:50:12.636928------------------------------------------------------ Precision@1: 56.09%  Precision@1: 78.76%

top1: [56.01, 56.088]
top5: [78.74, 78.764]
2024-04-13 02:50:12.805939 epoch: 3 step: 0 cls_loss= 2.79533 (95169 samples/sec)
2024-04-13 02:51:09.279391 epoch: 3 step: 500 cls_loss= 2.53588 (283 samples/sec)
2024-04-13 02:52:05.550406 epoch: 3 step: 1000 cls_loss= 2.92668 (284 samples/sec)
2024-04-13 02:53:01.749092 epoch: 3 step: 1500 cls_loss= 1.78750 (284 samples/sec)
2024-04-13 02:53:58.816720 epoch: 3 step: 2000 cls_loss= 2.21838 (280 samples/sec)
2024-04-13 02:54:55.115517 epoch: 3 step: 2500 cls_loss= 1.93457 (284 samples/sec)
2024-04-13 02:55:51.006358 epoch: 3 step: 3000 cls_loss= 2.00742 (286 samples/sec)
2024-04-13 02:58:49.422886------------------------------------------------------ Precision@1: 56.11%  Precision@1: 78.78%

top1: [56.01, 56.088, 56.108000000000004]
top5: [78.74, 78.764, 78.776]
=> creating model alexnet ...
 learning rate =  1e-05
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 02:58:51.960852 epoch: 1 step: 0 cls_loss= 3.22672 (22949 samples/sec)
2024-04-13 02:59:47.807559 epoch: 1 step: 500 cls_loss= 2.12493 (286 samples/sec)
2024-04-13 03:00:44.396603 epoch: 1 step: 1000 cls_loss= 3.01631 (282 samples/sec)
2024-04-13 03:01:41.090226 epoch: 1 step: 1500 cls_loss= 2.60966 (282 samples/sec)
2024-04-13 03:02:37.381403 epoch: 1 step: 2000 cls_loss= 2.38654 (284 samples/sec)
2024-04-13 03:03:33.261424 epoch: 1 step: 2500 cls_loss= 2.09113 (286 samples/sec)
2024-04-13 03:04:29.444319 epoch: 1 step: 3000 cls_loss= 2.26347 (284 samples/sec)
2024-04-13 03:07:28.522815------------------------------------------------------ Precision@1: 55.99%  Precision@1: 78.70%

top1: [55.992000000000004]
top5: [78.70400000000001]
2024-04-13 03:07:28.749301 epoch: 2 step: 0 cls_loss= 2.36556 (70917 samples/sec)
2024-04-13 03:08:25.627756 epoch: 2 step: 500 cls_loss= 2.38472 (281 samples/sec)
2024-04-13 03:09:22.894131 epoch: 2 step: 1000 cls_loss= 2.77485 (279 samples/sec)
2024-04-13 03:10:19.852131 epoch: 2 step: 1500 cls_loss= 1.79414 (280 samples/sec)
2024-04-13 03:11:16.704654 epoch: 2 step: 2000 cls_loss= 2.42769 (281 samples/sec)
2024-04-13 03:12:13.909698 epoch: 2 step: 2500 cls_loss= 2.16327 (279 samples/sec)
2024-04-13 03:13:11.575118 epoch: 2 step: 3000 cls_loss= 2.27228 (277 samples/sec)
2024-04-13 03:16:10.944185------------------------------------------------------ Precision@1: 56.09%  Precision@1: 78.71%

top1: [55.992000000000004, 56.086]
top5: [78.70400000000001, 78.71000000000001]
2024-04-13 03:16:11.161061 epoch: 3 step: 0 cls_loss= 2.47330 (74099 samples/sec)
2024-04-13 03:17:06.984811 epoch: 3 step: 500 cls_loss= 2.25804 (286 samples/sec)
2024-04-13 03:18:02.982862 epoch: 3 step: 1000 cls_loss= 2.19912 (285 samples/sec)
2024-04-13 03:18:58.997459 epoch: 3 step: 1500 cls_loss= 1.60730 (285 samples/sec)
2024-04-13 03:19:55.346807 epoch: 3 step: 2000 cls_loss= 2.36888 (283 samples/sec)
2024-04-13 03:20:51.804912 epoch: 3 step: 2500 cls_loss= 2.43178 (283 samples/sec)
2024-04-13 03:21:48.743091 epoch: 3 step: 3000 cls_loss= 2.00247 (281 samples/sec)
2024-04-13 03:24:48.107456------------------------------------------------------ Precision@1: 56.00%  Precision@1: 78.70%

top1: [55.992000000000004, 56.086, 56.0]
top5: [78.70400000000001, 78.71000000000001, 78.69800000000001]
=> creating model alexnet ...
 learning rate =  1e-05
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 03:24:50.655565 epoch: 1 step: 0 cls_loss= 2.24552 (23251 samples/sec)
2024-04-13 03:25:46.937531 epoch: 1 step: 500 cls_loss= 2.26062 (284 samples/sec)
2024-04-13 03:26:43.621652 epoch: 1 step: 1000 cls_loss= 1.99108 (282 samples/sec)
2024-04-13 03:27:40.441755 epoch: 1 step: 1500 cls_loss= 2.33121 (281 samples/sec)
2024-04-13 03:28:37.313234 epoch: 1 step: 2000 cls_loss= 1.90431 (281 samples/sec)
2024-04-13 03:29:34.198635 epoch: 1 step: 2500 cls_loss= 1.89212 (281 samples/sec)
2024-04-13 03:30:30.840442 epoch: 1 step: 3000 cls_loss= 2.58883 (282 samples/sec)
2024-04-13 03:33:28.576759------------------------------------------------------ Precision@1: 55.88%  Precision@1: 78.45%

top1: [55.88]
top5: [78.452]
2024-04-13 03:33:28.787493 epoch: 2 step: 0 cls_loss= 1.96393 (76192 samples/sec)
2024-04-13 03:34:25.628440 epoch: 2 step: 500 cls_loss= 2.13332 (281 samples/sec)
2024-04-13 03:35:22.230113 epoch: 2 step: 1000 cls_loss= 2.51713 (282 samples/sec)
2024-04-13 03:36:19.177969 epoch: 2 step: 1500 cls_loss= 2.70908 (280 samples/sec)
2024-04-13 03:37:16.014602 epoch: 2 step: 2000 cls_loss= 2.23418 (281 samples/sec)
2024-04-13 03:38:12.878049 epoch: 2 step: 2500 cls_loss= 1.80261 (281 samples/sec)
2024-04-13 03:39:09.338592 epoch: 2 step: 3000 cls_loss= 2.08699 (283 samples/sec)
2024-04-13 03:42:08.883917------------------------------------------------------ Precision@1: 55.87%  Precision@1: 78.49%

top1: [55.88, 55.874]
top5: [78.452, 78.486]
2024-04-13 03:42:09.120697 epoch: 3 step: 0 cls_loss= 2.40819 (67800 samples/sec)
2024-04-13 03:43:05.593601 epoch: 3 step: 500 cls_loss= 2.46430 (283 samples/sec)
2024-04-13 03:44:01.850598 epoch: 3 step: 1000 cls_loss= 1.98952 (284 samples/sec)
2024-04-13 03:44:58.049020 epoch: 3 step: 1500 cls_loss= 2.46404 (284 samples/sec)
2024-04-13 03:45:54.576812 epoch: 3 step: 2000 cls_loss= 2.70666 (283 samples/sec)
2024-04-13 03:46:51.712824 epoch: 3 step: 2500 cls_loss= 2.80259 (280 samples/sec)
2024-04-13 03:47:48.632749 epoch: 3 step: 3000 cls_loss= 1.92268 (281 samples/sec)
2024-04-13 03:50:46.857809------------------------------------------------------ Precision@1: 55.89%  Precision@1: 78.67%

top1: [55.88, 55.874, 55.888]
top5: [78.452, 78.486, 78.67]
]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ 
[K]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ 
[K]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
[K]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model mobilenet ...
 learning rate =  0.0001
SGD
2024-04-13 10:52:20.812200 epoch: 1 step: 0 cls_loss= 1.66925 (19876 samples/sec)
2024-04-13 10:53:16.847077 epoch: 1 step: 500 cls_loss= 1.98165 (285 samples/sec)
2024-04-13 10:54:12.892351 epoch: 1 step: 1000 cls_loss= 1.79539 (285 samples/sec)
2024-04-13 10:55:08.777147 epoch: 1 step: 1500 cls_loss= 1.54438 (286 samples/sec)
2024-04-13 10:56:05.705986 epoch: 1 step: 2000 cls_loss= 1.90585 (281 samples/sec)
2024-04-13 10:57:02.837647 epoch: 1 step: 2500 cls_loss= 1.78030 (280 samples/sec)
2024-04-13 10:58:00.266691 epoch: 1 step: 3000 cls_loss= 1.78190 (278 samples/sec)
2024-04-13 11:00:59.972439------------------------------------------------------ Precision@1: 66.83%  Precision@1: 87.36%

top1: [66.834]
top5: [87.36]
2024-04-13 11:01:00.171964 epoch: 2 step: 0 cls_loss= 1.50414 (80691 samples/sec)
2024-04-13 11:01:56.890970 epoch: 2 step: 500 cls_loss= 1.76300 (282 samples/sec)
2024-04-13 11:02:54.101945 epoch: 2 step: 1000 cls_loss= 2.16396 (279 samples/sec)
2024-04-13 11:03:51.023244 epoch: 2 step: 1500 cls_loss= 1.70652 (281 samples/sec)
2024-04-13 11:04:48.365017 epoch: 2 step: 2000 cls_loss= 2.30401 (279 samples/sec)
2024-04-13 11:05:45.738760 epoch: 2 step: 2500 cls_loss= 2.38198 (278 samples/sec)
2024-04-13 11:06:42.608051 epoch: 2 step: 3000 cls_loss= 2.49589 (281 samples/sec)
2024-04-13 11:09:43.434023------------------------------------------------------ Precision@1: 66.92%  Precision@1: 87.61%

top1: [66.834, 66.916]
top5: [87.36, 87.614]
2024-04-13 11:09:43.631081 epoch: 3 step: 0 cls_loss= 1.42722 (81644 samples/sec)
2024-04-13 11:10:41.752706 epoch: 3 step: 500 cls_loss= 1.28975 (275 samples/sec)
2024-04-13 11:11:39.459335 epoch: 3 step: 1000 cls_loss= 1.65351 (277 samples/sec)
2024-04-13 11:12:37.356851 epoch: 3 step: 1500 cls_loss= 1.70984 (276 samples/sec)
2024-04-13 11:13:35.855897 epoch: 3 step: 2000 cls_loss= 1.50642 (273 samples/sec)
2024-04-13 11:14:33.899431 epoch: 3 step: 2500 cls_loss= 2.08934 (275 samples/sec)
2024-04-13 11:15:31.278806 epoch: 3 step: 3000 cls_loss= 2.25054 (278 samples/sec)
2024-04-13 11:18:31.962003------------------------------------------------------ Precision@1: 67.07%  Precision@1: 87.44%

top1: [66.834, 66.916, 67.066]
top5: [87.36, 87.614, 87.436]
=> creating model mobilenet ...
 learning rate =  0.0001
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 11:18:34.289535 epoch: 1 step: 0 cls_loss= 2.55087 (18086 samples/sec)
2024-04-13 11:19:35.528925 epoch: 1 step: 500 cls_loss= 1.54596 (261 samples/sec)
2024-04-13 11:20:36.442939 epoch: 1 step: 1000 cls_loss= 1.26565 (262 samples/sec)
2024-04-13 11:21:37.269983 epoch: 1 step: 1500 cls_loss= 1.93300 (263 samples/sec)
2024-04-13 11:22:38.271114 epoch: 1 step: 2000 cls_loss= 2.18541 (262 samples/sec)
2024-04-13 11:23:39.020476 epoch: 1 step: 2500 cls_loss= 1.98319 (263 samples/sec)
2024-04-13 11:24:39.982156 epoch: 1 step: 3000 cls_loss= 2.05388 (262 samples/sec)
2024-04-13 11:27:39.671908------------------------------------------------------ Precision@1: 65.63%  Precision@1: 86.55%

top1: [65.628]
top5: [86.552]
2024-04-13 11:27:39.930867 epoch: 2 step: 0 cls_loss= 1.80409 (62065 samples/sec)
2024-04-13 11:28:41.079512 epoch: 2 step: 500 cls_loss= 1.79117 (261 samples/sec)
2024-04-13 11:29:41.930201 epoch: 2 step: 1000 cls_loss= 2.81894 (262 samples/sec)
2024-04-13 11:30:43.142441 epoch: 2 step: 1500 cls_loss= 1.38125 (261 samples/sec)
2024-04-13 11:31:44.473960 epoch: 2 step: 2000 cls_loss= 1.95328 (260 samples/sec)
2024-04-13 11:32:45.670235 epoch: 2 step: 2500 cls_loss= 2.57151 (261 samples/sec)
2024-04-13 11:33:46.804214 epoch: 2 step: 3000 cls_loss= 1.85739 (261 samples/sec)
2024-04-13 11:36:47.485272------------------------------------------------------ Precision@1: 65.78%  Precision@1: 86.77%

top1: [65.628, 65.782]
top5: [86.552, 86.774]
2024-04-13 11:36:47.744270 epoch: 3 step: 0 cls_loss= 2.20958 (62089 samples/sec)
2024-04-13 11:37:48.771062 epoch: 3 step: 500 cls_loss= 2.17922 (262 samples/sec)
2024-04-13 11:38:50.068385 epoch: 3 step: 1000 cls_loss= 1.93058 (261 samples/sec)
2024-04-13 11:39:51.423318 epoch: 3 step: 1500 cls_loss= 2.05158 (260 samples/sec)
2024-04-13 11:40:52.843876 epoch: 3 step: 2000 cls_loss= 1.79504 (260 samples/sec)
2024-04-13 11:41:54.309966 epoch: 3 step: 2500 cls_loss= 2.13022 (260 samples/sec)
2024-04-13 11:42:55.774625 epoch: 3 step: 3000 cls_loss= 2.44518 (260 samples/sec)
2024-04-13 11:46:00.982672------------------------------------------------------ Precision@1: 65.72%  Precision@1: 86.64%

top1: [65.628, 65.782, 65.724]
top5: [86.552, 86.774, 86.644]
=> creating model mobilenet ...
 learning rate =  0.0001
SGD
2024-04-13 11:46:03.281426 epoch: 1 step: 0 cls_loss= 2.34415 (18585 samples/sec)
2024-04-13 11:47:00.914942 epoch: 1 step: 500 cls_loss= 1.91635 (277 samples/sec)
2024-04-13 11:47:58.198109 epoch: 1 step: 1000 cls_loss= 1.31253 (279 samples/sec)
2024-04-13 11:48:55.327529 epoch: 1 step: 1500 cls_loss= 1.45028 (280 samples/sec)
2024-04-13 11:49:52.674865 epoch: 1 step: 2000 cls_loss= 1.47242 (279 samples/sec)
2024-04-13 11:50:50.207409 epoch: 1 step: 2500 cls_loss= 1.76772 (278 samples/sec)
2024-04-13 11:51:47.573229 epoch: 1 step: 3000 cls_loss= 1.30080 (278 samples/sec)
2024-04-13 11:54:46.157809------------------------------------------------------ Precision@1: 67.60%  Precision@1: 88.00%

top1: [67.596]
top5: [88.004]
2024-04-13 11:54:46.360377 epoch: 2 step: 0 cls_loss= 1.50969 (79425 samples/sec)
2024-04-13 11:55:42.797678 epoch: 2 step: 500 cls_loss= 2.42773 (283 samples/sec)
2024-04-13 11:56:39.831362 epoch: 2 step: 1000 cls_loss= 1.33098 (280 samples/sec)
2024-04-13 11:57:37.510588 epoch: 2 step: 1500 cls_loss= 2.02502 (277 samples/sec)
2024-04-13 11:58:35.185701 epoch: 2 step: 2000 cls_loss= 1.61980 (277 samples/sec)
2024-04-13 11:59:32.961141 epoch: 2 step: 2500 cls_loss= 1.70475 (277 samples/sec)
2024-04-13 12:00:30.210421 epoch: 2 step: 3000 cls_loss= 1.40265 (279 samples/sec)
2024-04-13 12:03:29.226870------------------------------------------------------ Precision@1: 67.51%  Precision@1: 87.84%

top1: [67.596, 67.508]
top5: [88.004, 87.84400000000001]
2024-04-13 12:03:29.428324 epoch: 3 step: 0 cls_loss= 2.19579 (79889 samples/sec)
2024-04-13 12:04:26.705750 epoch: 3 step: 500 cls_loss= 1.41522 (279 samples/sec)
2024-04-13 12:05:23.617998 epoch: 3 step: 1000 cls_loss= 1.81641 (281 samples/sec)
^CTraceback (most recent call last):
  File "./imgnet_train_eval.py", line 346, in <module>
    main()
  File "./imgnet_train_eval.py", line 339, in main
    train(epoch)
  File "./imgnet_train_eval.py", line 175, in train
    output = model(inputs.cuda())
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspaces/pytorch-dev/SLFP_CNNs/nets_imgnet/mobilenetv1.py", line 81, in forward
    x = self.model(x)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1480, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
KeyboardInterrupt

]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model mobilenet ...
 learning rate =  5e-06
SGD
2024-04-13 12:07:33.871856 epoch: 1 step: 0 cls_loss= 2.81100 (18203 samples/sec)
2024-04-13 12:08:30.060284 epoch: 1 step: 500 cls_loss= 1.44812 (284 samples/sec)
2024-04-13 12:09:26.834778 epoch: 1 step: 1000 cls_loss= 2.30126 (281 samples/sec)
2024-04-13 12:10:23.782038 epoch: 1 step: 1500 cls_loss= 1.75199 (281 samples/sec)
2024-04-13 12:11:20.417170 epoch: 1 step: 2000 cls_loss= 2.00903 (282 samples/sec)
2024-04-13 12:12:18.223217 epoch: 1 step: 2500 cls_loss= 1.60773 (276 samples/sec)
2024-04-13 12:13:17.659308 epoch: 1 step: 3000 cls_loss= 1.52402 (269 samples/sec)
2024-04-13 12:17:15.704289------------------------------------------------------ Precision@1: 66.26%  Precision@1: 86.86%

top1: [66.262]
top5: [86.858]
2024-04-13 12:17:16.324181 epoch: 2 step: 0 cls_loss= 1.13450 (25916 samples/sec)
2024-04-13 12:20:09.060558 epoch: 2 step: 500 cls_loss= 1.96705 (92 samples/sec)
2024-04-13 12:23:05.894760 epoch: 2 step: 1000 cls_loss= 2.12040 (90 samples/sec)
2024-04-13 12:26:19.763364 epoch: 2 step: 1500 cls_loss= 1.63514 (82 samples/sec)
2024-04-13 12:30:11.794601 epoch: 2 step: 2000 cls_loss= 1.52664 (68 samples/sec)
2024-04-13 12:34:14.382867 epoch: 2 step: 2500 cls_loss= 2.18885 (65 samples/sec)
2024-04-13 12:38:18.874610 epoch: 2 step: 3000 cls_loss= 2.45241 (65 samples/sec)
2024-04-13 12:45:16.091838------------------------------------------------------ Precision@1: 66.90%  Precision@1: 87.30%

top1: [66.262, 66.904]
top5: [86.858, 87.304]
2024-04-13 12:45:16.470210 epoch: 3 step: 0 cls_loss= 2.33577 (42511 samples/sec)
2024-04-13 12:47:54.470245 epoch: 3 step: 500 cls_loss= 1.91660 (101 samples/sec)
2024-04-13 12:50:49.841526 epoch: 3 step: 1000 cls_loss= 2.67110 (91 samples/sec)
2024-04-13 12:53:49.482895 epoch: 3 step: 1500 cls_loss= 2.28758 (89 samples/sec)
2024-04-13 12:56:50.470233 epoch: 3 step: 2000 cls_loss= 2.00257 (88 samples/sec)
2024-04-13 12:59:48.847557 epoch: 3 step: 2500 cls_loss= 2.23545 (89 samples/sec)
2024-04-13 13:02:47.788849 epoch: 3 step: 3000 cls_loss= 2.17100 (89 samples/sec)
2024-04-13 13:09:57.096525------------------------------------------------------ Precision@1: 67.01%  Precision@1: 87.47%

top1: [66.262, 66.904, 67.008]
top5: [86.858, 87.304, 87.468]
=> creating model mobilenet ...
 learning rate =  5e-06
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 13:10:01.490458 epoch: 1 step: 0 cls_loss= 1.88673 (11881 samples/sec)
2024-04-13 13:13:10.857081 epoch: 1 step: 500 cls_loss= 2.15809 (84 samples/sec)
2024-04-13 13:16:24.215549 epoch: 1 step: 1000 cls_loss= 2.39684 (82 samples/sec)
2024-04-13 13:19:37.847384 epoch: 1 step: 1500 cls_loss= 1.31511 (82 samples/sec)
2024-04-13 13:23:01.681588 epoch: 1 step: 2000 cls_loss= 1.81713 (78 samples/sec)
2024-04-13 13:26:25.190820 epoch: 1 step: 2500 cls_loss= 2.08095 (78 samples/sec)
2024-04-13 13:29:51.364857 epoch: 1 step: 3000 cls_loss= 1.60926 (77 samples/sec)
2024-04-13 13:36:28.465146------------------------------------------------------ Precision@1: 66.68%  Precision@1: 87.23%

top1: [66.684]
top5: [87.232]
2024-04-13 13:36:29.009902 epoch: 2 step: 0 cls_loss= 1.80626 (29464 samples/sec)
2024-04-13 13:39:22.332659 epoch: 2 step: 500 cls_loss= 2.27850 (92 samples/sec)
2024-04-13 13:42:36.382084 epoch: 2 step: 1000 cls_loss= 1.16024 (82 samples/sec)
2024-04-13 13:46:15.207424 epoch: 2 step: 1500 cls_loss= 2.33426 (73 samples/sec)
2024-04-13 13:50:11.118414 epoch: 2 step: 2000 cls_loss= 1.91860 (67 samples/sec)
2024-04-13 13:54:12.385317 epoch: 2 step: 2500 cls_loss= 1.72055 (66 samples/sec)
2024-04-13 13:58:31.317755 epoch: 2 step: 3000 cls_loss= 2.07807 (61 samples/sec)
2024-04-13 14:05:41.304345------------------------------------------------------ Precision@1: 67.13%  Precision@1: 87.48%

top1: [66.684, 67.128]
top5: [87.232, 87.48]
2024-04-13 14:05:41.870917 epoch: 3 step: 0 cls_loss= 1.34986 (28301 samples/sec)
2024-04-13 14:08:16.383135 epoch: 3 step: 500 cls_loss= 1.48354 (103 samples/sec)
2024-04-13 14:11:05.887502 epoch: 3 step: 1000 cls_loss= 1.30138 (94 samples/sec)
2024-04-13 14:14:58.616942 epoch: 3 step: 1500 cls_loss= 1.90173 (68 samples/sec)
2024-04-13 14:19:11.202282 epoch: 3 step: 2000 cls_loss= 2.12932 (63 samples/sec)
2024-04-13 14:23:26.138003 epoch: 3 step: 2500 cls_loss= 1.93782 (62 samples/sec)
2024-04-13 14:28:23.653240 epoch: 3 step: 3000 cls_loss= 2.24586 (53 samples/sec)
2024-04-13 14:35:38.578559------------------------------------------------------ Precision@1: 67.22%  Precision@1: 87.69%

top1: [66.684, 67.128, 67.22]
top5: [87.232, 87.48, 87.694]
=> creating model mobilenet ...
 learning rate =  5e-06
SGD
2024-04-13 14:35:44.163519 epoch: 1 step: 0 cls_loss= 1.50981 (9694 samples/sec)
2024-04-13 14:39:11.730092 epoch: 1 step: 500 cls_loss= 2.29840 (77 samples/sec)
2024-04-13 14:43:04.620283 epoch: 1 step: 1000 cls_loss= 2.45833 (68 samples/sec)
2024-04-13 14:47:24.887496 epoch: 1 step: 1500 cls_loss= 1.83262 (61 samples/sec)
2024-04-13 14:51:46.515676 epoch: 1 step: 2000 cls_loss= 1.31754 (61 samples/sec)
2024-04-13 14:56:07.855376 epoch: 1 step: 2500 cls_loss= 1.93125 (61 samples/sec)
2024-04-13 15:00:38.368550 epoch: 1 step: 3000 cls_loss= 1.50580 (59 samples/sec)
2024-04-13 15:07:40.409532------------------------------------------------------ Precision@1: 67.67%  Precision@1: 87.99%

top1: [67.674]
top5: [87.986]
2024-04-13 15:07:40.820299 epoch: 2 step: 0 cls_loss= 1.36984 (39075 samples/sec)
2024-04-13 15:10:52.177678 epoch: 2 step: 500 cls_loss= 1.65748 (83 samples/sec)
2024-04-13 15:14:27.547716 epoch: 2 step: 1000 cls_loss= 2.12890 (74 samples/sec)
2024-04-13 15:18:47.840022 epoch: 2 step: 1500 cls_loss= 1.82444 (61 samples/sec)
2024-04-13 15:23:40.064118 epoch: 2 step: 2000 cls_loss= 1.84407 (54 samples/sec)
2024-04-13 15:28:52.156344 epoch: 2 step: 2500 cls_loss= 1.84980 (51 samples/sec)
2024-04-13 15:33:58.361304 epoch: 2 step: 3000 cls_loss= 1.46714 (52 samples/sec)
2024-04-13 15:41:19.550034------------------------------------------------------ Precision@1: 67.70%  Precision@1: 88.00%

top1: [67.674, 67.7]
top5: [87.986, 87.996]
2024-04-13 15:41:20.100637 epoch: 3 step: 0 cls_loss= 2.03147 (29160 samples/sec)
2024-04-13 15:44:52.974265 epoch: 3 step: 500 cls_loss= 1.38544 (75 samples/sec)
2024-04-13 15:48:55.844620 epoch: 3 step: 1000 cls_loss= 1.72040 (65 samples/sec)
2024-04-13 15:53:27.816605 epoch: 3 step: 1500 cls_loss= 1.57558 (58 samples/sec)
2024-04-13 15:58:09.171472 epoch: 3 step: 2000 cls_loss= 1.51369 (56 samples/sec)
2024-04-13 16:02:51.512968 epoch: 3 step: 2500 cls_loss= 1.47412 (56 samples/sec)
2024-04-13 16:07:32.664791 epoch: 3 step: 3000 cls_loss= 1.61861 (56 samples/sec)
2024-04-13 16:12:40.182603------------------------------------------------------ Precision@1: 67.78%  Precision@1: 87.96%

top1: [67.674, 67.7, 67.78]
top5: [87.986, 87.996, 87.962]
=> creating model mobilenet ...
 learning rate =  5e-06
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 16:12:44.426660 epoch: 1 step: 0 cls_loss= 1.69117 (14297 samples/sec)
2024-04-13 16:13:50.337263 epoch: 1 step: 500 cls_loss= 1.65565 (242 samples/sec)
2024-04-13 16:14:56.232419 epoch: 1 step: 1000 cls_loss= 1.97116 (242 samples/sec)
2024-04-13 16:16:01.959842 epoch: 1 step: 1500 cls_loss= 1.61422 (243 samples/sec)
2024-04-13 16:17:08.581770 epoch: 1 step: 2000 cls_loss= 1.94806 (240 samples/sec)
2024-04-13 16:18:16.406856 epoch: 1 step: 2500 cls_loss= 1.48479 (235 samples/sec)
2024-04-13 16:19:23.173238 epoch: 1 step: 3000 cls_loss= 2.16351 (239 samples/sec)
2024-04-13 16:22:26.425022------------------------------------------------------ Precision@1: 67.68%  Precision@1: 88.18%

top1: [67.678]
top5: [88.178]
2024-04-13 16:22:26.702591 epoch: 2 step: 0 cls_loss= 1.69336 (57879 samples/sec)
2024-04-13 16:23:31.053244 epoch: 2 step: 500 cls_loss= 1.75516 (248 samples/sec)
2024-04-13 16:24:35.630818 epoch: 2 step: 1000 cls_loss= 1.76680 (247 samples/sec)
2024-04-13 16:25:40.104876 epoch: 2 step: 1500 cls_loss= 1.69686 (248 samples/sec)
2024-04-13 16:26:44.440442 epoch: 2 step: 2000 cls_loss= 2.37986 (248 samples/sec)
2024-04-13 16:27:48.757365 epoch: 2 step: 2500 cls_loss= 1.59489 (248 samples/sec)
2024-04-13 16:28:53.031804 epoch: 2 step: 3000 cls_loss= 1.79775 (248 samples/sec)
2024-04-13 16:31:55.803441------------------------------------------------------ Precision@1: 67.71%  Precision@1: 88.16%

top1: [67.678, 67.708]
top5: [88.178, 88.158]
2024-04-13 16:31:56.093792 epoch: 3 step: 0 cls_loss= 1.42092 (55326 samples/sec)
2024-04-13 16:33:00.317801 epoch: 3 step: 500 cls_loss= 2.02182 (249 samples/sec)
2024-04-13 16:34:04.640513 epoch: 3 step: 1000 cls_loss= 2.19578 (248 samples/sec)
2024-04-13 16:35:08.977004 epoch: 3 step: 1500 cls_loss= 1.27083 (248 samples/sec)
2024-04-13 16:36:13.118779 epoch: 3 step: 2000 cls_loss= 1.34905 (249 samples/sec)
2024-04-13 16:37:17.321711 epoch: 3 step: 2500 cls_loss= 1.56731 (249 samples/sec)
2024-04-13 16:38:21.557414 epoch: 3 step: 3000 cls_loss= 1.20803 (249 samples/sec)
2024-04-13 16:41:23.139813------------------------------------------------------ Precision@1: 68.00%  Precision@1: 88.01%

top1: [67.678, 67.708, 67.998]
top5: [88.178, 88.158, 88.014]
=> creating model alexnet ...
 learning rate =  1e-07
SGD
2024-04-13 16:41:26.061636 epoch: 1 step: 0 cls_loss= 2.69472 (24316 samples/sec)
2024-04-13 16:42:22.850613 epoch: 1 step: 500 cls_loss= 2.23511 (281 samples/sec)
2024-04-13 16:43:20.370645 epoch: 1 step: 1000 cls_loss= 2.97555 (278 samples/sec)
2024-04-13 16:44:17.714750 epoch: 1 step: 1500 cls_loss= 3.07135 (279 samples/sec)
2024-04-13 16:45:14.228454 epoch: 1 step: 2000 cls_loss= 2.15883 (283 samples/sec)
2024-04-13 16:46:11.003427 epoch: 1 step: 2500 cls_loss= 2.32232 (281 samples/sec)
2024-04-13 16:47:07.931847 epoch: 1 step: 3000 cls_loss= 2.90306 (281 samples/sec)
2024-04-13 16:50:04.378276------------------------------------------------------ Precision@1: 56.02%  Precision@1: 78.87%

top1: [56.018]
top5: [78.866]
2024-04-13 16:50:04.546144 epoch: 2 step: 0 cls_loss= 2.42382 (95800 samples/sec)
2024-04-13 16:51:01.053140 epoch: 2 step: 500 cls_loss= 3.04879 (283 samples/sec)
2024-04-13 16:51:57.775306 epoch: 2 step: 1000 cls_loss= 2.14809 (282 samples/sec)
2024-04-13 16:52:53.858606 epoch: 2 step: 1500 cls_loss= 2.20884 (285 samples/sec)
2024-04-13 16:53:50.836159 epoch: 2 step: 2000 cls_loss= 2.82489 (280 samples/sec)
2024-04-13 16:54:47.589622 epoch: 2 step: 2500 cls_loss= 2.62537 (281 samples/sec)
2024-04-13 16:55:44.929261 epoch: 2 step: 3000 cls_loss= 2.61221 (279 samples/sec)
2024-04-13 16:58:42.586013------------------------------------------------------ Precision@1: 55.95%  Precision@1: 78.76%

top1: [56.018, 55.948]
top5: [78.866, 78.764]
2024-04-13 16:58:42.753658 epoch: 3 step: 0 cls_loss= 2.31188 (95916 samples/sec)
2024-04-13 16:59:39.160009 epoch: 3 step: 500 cls_loss= 3.04235 (283 samples/sec)
2024-04-13 17:00:35.009321 epoch: 3 step: 1000 cls_loss= 2.31138 (286 samples/sec)
2024-04-13 17:01:30.850212 epoch: 3 step: 1500 cls_loss= 3.80333 (286 samples/sec)
2024-04-13 17:02:27.248624 epoch: 3 step: 2000 cls_loss= 3.08909 (283 samples/sec)
2024-04-13 17:03:23.439135 epoch: 3 step: 2500 cls_loss= 3.04043 (284 samples/sec)
2024-04-13 17:04:19.947570 epoch: 3 step: 3000 cls_loss= 3.10613 (283 samples/sec)
2024-04-13 17:07:16.923459------------------------------------------------------ Precision@1: 56.01%  Precision@1: 78.84%

top1: [56.018, 55.948, 56.014]
top5: [78.866, 78.764, 78.84]
=> creating model alexnet ...
 learning rate =  1e-07
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 17:07:19.473806 epoch: 1 step: 0 cls_loss= 2.46662 (23756 samples/sec)
2024-04-13 17:08:15.882520 epoch: 1 step: 500 cls_loss= 2.42383 (283 samples/sec)
2024-04-13 17:09:12.638848 epoch: 1 step: 1000 cls_loss= 2.19374 (281 samples/sec)
2024-04-13 17:10:09.765947 epoch: 1 step: 1500 cls_loss= 2.44563 (280 samples/sec)
2024-04-13 17:11:08.128479 epoch: 1 step: 2000 cls_loss= 2.48387 (274 samples/sec)
2024-04-13 17:12:05.674424 epoch: 1 step: 2500 cls_loss= 2.85032 (278 samples/sec)
2024-04-13 17:13:03.650705 epoch: 1 step: 3000 cls_loss= 2.22338 (275 samples/sec)
2024-04-13 17:16:03.362321------------------------------------------------------ Precision@1: 56.00%  Precision@1: 78.79%

top1: [55.998000000000005]
top5: [78.788]
2024-04-13 17:16:03.575711 epoch: 2 step: 0 cls_loss= 3.52060 (75247 samples/sec)
2024-04-13 17:17:00.794187 epoch: 2 step: 500 cls_loss= 1.85144 (279 samples/sec)
2024-04-13 17:17:57.671488 epoch: 2 step: 1000 cls_loss= 2.20754 (281 samples/sec)
2024-04-13 17:18:53.833082 epoch: 2 step: 1500 cls_loss= 2.24091 (284 samples/sec)
2024-04-13 17:19:50.702512 epoch: 2 step: 2000 cls_loss= 3.00919 (281 samples/sec)
2024-04-13 17:20:47.833269 epoch: 2 step: 2500 cls_loss= 2.18219 (280 samples/sec)
2024-04-13 17:21:45.864242 epoch: 2 step: 3000 cls_loss= 2.07086 (275 samples/sec)
2024-04-13 17:24:45.160348------------------------------------------------------ Precision@1: 55.95%  Precision@1: 78.79%

top1: [55.998000000000005, 55.954]
top5: [78.788, 78.79]
2024-04-13 17:24:45.379130 epoch: 3 step: 0 cls_loss= 2.23018 (73447 samples/sec)
2024-04-13 17:25:42.906479 epoch: 3 step: 500 cls_loss= 2.19933 (278 samples/sec)
2024-04-13 17:26:39.618290 epoch: 3 step: 1000 cls_loss= 2.78002 (282 samples/sec)
2024-04-13 17:27:36.404362 epoch: 3 step: 1500 cls_loss= 2.76033 (281 samples/sec)
2024-04-13 17:28:32.892259 epoch: 3 step: 2000 cls_loss= 3.04344 (283 samples/sec)
2024-04-13 17:29:29.997354 epoch: 3 step: 2500 cls_loss= 3.32949 (280 samples/sec)
2024-04-13 17:30:28.854404 epoch: 3 step: 3000 cls_loss= 2.25982 (271 samples/sec)
2024-04-13 17:33:29.406526------------------------------------------------------ Precision@1: 56.04%  Precision@1: 78.74%

top1: [55.998000000000005, 55.954, 56.042]
top5: [78.788, 78.79, 78.744]
=> creating model alexnet ...
 learning rate =  1e-07
SGD
2024-04-13 17:33:31.887611 epoch: 1 step: 0 cls_loss= 2.86644 (25353 samples/sec)
2024-04-13 17:34:27.619321 epoch: 1 step: 500 cls_loss= 1.93309 (287 samples/sec)
2024-04-13 17:35:24.435946 epoch: 1 step: 1000 cls_loss= 2.32908 (281 samples/sec)
2024-04-13 17:36:22.002330 epoch: 1 step: 1500 cls_loss= 2.01718 (277 samples/sec)
2024-04-13 17:37:19.476124 epoch: 1 step: 2000 cls_loss= 2.47669 (278 samples/sec)
2024-04-13 17:38:17.145415 epoch: 1 step: 2500 cls_loss= 2.49492 (277 samples/sec)
2024-04-13 17:39:15.067354 epoch: 1 step: 3000 cls_loss= 1.80578 (276 samples/sec)
2024-04-13 17:42:14.908476------------------------------------------------------ Precision@1: 56.07%  Precision@1: 78.82%

top1: [56.07]
top5: [78.816]
2024-04-13 17:42:15.075333 epoch: 2 step: 0 cls_loss= 2.51747 (96415 samples/sec)
2024-04-13 17:43:12.276934 epoch: 2 step: 500 cls_loss= 2.39278 (279 samples/sec)
2024-04-13 17:44:09.016571 epoch: 2 step: 1000 cls_loss= 2.44740 (282 samples/sec)
2024-04-13 17:45:05.907925 epoch: 2 step: 1500 cls_loss= 2.40617 (281 samples/sec)
2024-04-13 17:46:02.288779 epoch: 2 step: 2000 cls_loss= 2.62527 (283 samples/sec)
2024-04-13 17:46:58.219816 epoch: 2 step: 2500 cls_loss= 3.78013 (286 samples/sec)
2024-04-13 17:47:54.025706 epoch: 2 step: 3000 cls_loss= 2.89494 (286 samples/sec)
2024-04-13 17:50:51.393968------------------------------------------------------ Precision@1: 56.14%  Precision@1: 78.85%

top1: [56.07, 56.136]
top5: [78.816, 78.854]
2024-04-13 17:50:51.558114 epoch: 3 step: 0 cls_loss= 2.25811 (97957 samples/sec)
2024-04-13 17:51:48.390535 epoch: 3 step: 500 cls_loss= 2.39022 (281 samples/sec)
2024-04-13 17:52:45.115526 epoch: 3 step: 1000 cls_loss= 2.17435 (282 samples/sec)
2024-04-13 17:53:41.792868 epoch: 3 step: 1500 cls_loss= 2.45024 (282 samples/sec)
2024-04-13 17:54:38.280525 epoch: 3 step: 2000 cls_loss= 2.31146 (283 samples/sec)
2024-04-13 17:55:35.095502 epoch: 3 step: 2500 cls_loss= 2.62940 (281 samples/sec)
2024-04-13 17:56:31.412350 epoch: 3 step: 3000 cls_loss= 2.12759 (284 samples/sec)
2024-04-13 17:59:29.308644------------------------------------------------------ Precision@1: 56.08%  Precision@1: 78.89%

top1: [56.07, 56.136, 56.084]
top5: [78.816, 78.854, 78.89]
=> creating model alexnet ...
 learning rate =  1e-07
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 17:59:31.848085 epoch: 1 step: 0 cls_loss= 2.00658 (23455 samples/sec)
2024-04-13 18:00:28.173450 epoch: 1 step: 500 cls_loss= 3.21431 (284 samples/sec)
2024-04-13 18:01:23.755906 epoch: 1 step: 1000 cls_loss= 2.93179 (287 samples/sec)
2024-04-13 18:02:20.249289 epoch: 1 step: 1500 cls_loss= 2.01301 (283 samples/sec)
2024-04-13 18:03:17.190562 epoch: 1 step: 2000 cls_loss= 2.09411 (280 samples/sec)
2024-04-13 18:04:13.960123 epoch: 1 step: 2500 cls_loss= 2.05985 (281 samples/sec)
2024-04-13 18:05:11.285054 epoch: 1 step: 3000 cls_loss= 2.53726 (279 samples/sec)
2024-04-13 18:08:13.670700------------------------------------------------------ Precision@1: 56.10%  Precision@1: 78.89%

top1: [56.096000000000004]
top5: [78.894]
2024-04-13 18:08:13.895424 epoch: 2 step: 0 cls_loss= 1.69466 (71482 samples/sec)
2024-04-13 18:09:10.565888 epoch: 2 step: 500 cls_loss= 2.91925 (282 samples/sec)
2024-04-13 18:10:07.048897 epoch: 2 step: 1000 cls_loss= 3.34275 (283 samples/sec)
2024-04-13 18:11:03.921752 epoch: 2 step: 1500 cls_loss= 3.20280 (281 samples/sec)
2024-04-13 18:12:00.012972 epoch: 2 step: 2000 cls_loss= 2.34226 (285 samples/sec)
2024-04-13 18:12:56.736745 epoch: 2 step: 2500 cls_loss= 2.51702 (282 samples/sec)
2024-04-13 18:13:54.157709 epoch: 2 step: 3000 cls_loss= 3.26089 (278 samples/sec)
2024-04-13 18:16:53.245743------------------------------------------------------ Precision@1: 56.10%  Precision@1: 78.88%

top1: [56.096000000000004, 56.102000000000004]
top5: [78.894, 78.88]
2024-04-13 18:16:53.474695 epoch: 3 step: 0 cls_loss= 1.69935 (70182 samples/sec)
2024-04-13 18:17:49.811171 epoch: 3 step: 500 cls_loss= 2.49120 (284 samples/sec)
2024-04-13 18:18:46.107141 epoch: 3 step: 1000 cls_loss= 2.16841 (284 samples/sec)
2024-04-13 18:19:42.518233 epoch: 3 step: 1500 cls_loss= 2.52247 (283 samples/sec)
2024-04-13 18:20:39.057879 epoch: 3 step: 2000 cls_loss= 1.90837 (282 samples/sec)
2024-04-13 18:21:36.557431 epoch: 3 step: 2500 cls_loss= 3.46141 (278 samples/sec)
2024-04-13 18:22:34.390306 epoch: 3 step: 3000 cls_loss= 2.29743 (276 samples/sec)
2024-04-13 18:25:34.166094------------------------------------------------------ Precision@1: 56.08%  Precision@1: 78.86%

top1: [56.096000000000004, 56.102000000000004, 56.082]
top5: [78.894, 78.88, 78.86]
]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model alexnet ...
 learning rate =  5e-08
 precision =  7 bits
SGD
2024-04-13 22:16:25.716854 epoch: 1 step: 0 cls_loss= 2.68654 (12796 samples/sec)
2024-04-13 22:18:59.096751 epoch: 1 step: 500 cls_loss= 2.04754 (104 samples/sec)
2024-04-13 22:21:38.314925 epoch: 1 step: 1000 cls_loss= 2.40127 (100 samples/sec)
2024-04-13 22:24:20.127979 epoch: 1 step: 1500 cls_loss= 2.96782 (98 samples/sec)
2024-04-13 22:27:00.808839 epoch: 1 step: 2000 cls_loss= 2.17449 (99 samples/sec)
2024-04-13 22:29:41.553917 epoch: 1 step: 2500 cls_loss= 2.55257 (99 samples/sec)
2024-04-13 22:32:23.975087 epoch: 1 step: 3000 cls_loss= 1.78289 (98 samples/sec)
2024-04-13 22:38:28.280805------------------------------------------------------ Precision@1: 55.92%  Precision@1: 78.78%

top1: [55.922000000000004]
top5: [78.78]
2024-04-13 22:38:28.529131 epoch: 2 step: 0 cls_loss= 2.64042 (64724 samples/sec)
2024-04-13 22:40:14.820309 epoch: 2 step: 500 cls_loss= 2.65619 (150 samples/sec)
2024-04-13 22:42:04.179316 epoch: 2 step: 1000 cls_loss= 2.45828 (146 samples/sec)
2024-04-13 22:43:57.169528 epoch: 2 step: 1500 cls_loss= 1.90440 (141 samples/sec)
2024-04-13 22:46:13.969082 epoch: 2 step: 2000 cls_loss= 2.76055 (116 samples/sec)
2024-04-13 22:48:32.037555 epoch: 2 step: 2500 cls_loss= 1.94897 (115 samples/sec)
2024-04-13 22:50:48.567333 epoch: 2 step: 3000 cls_loss= 2.37827 (117 samples/sec)
2024-04-13 22:54:38.434529------------------------------------------------------ Precision@1: 55.99%  Precision@1: 78.81%

top1: [55.922000000000004, 55.988]
top5: [78.78, 78.81]
2024-04-13 22:54:38.647393 epoch: 3 step: 0 cls_loss= 2.88798 (75491 samples/sec)
2024-04-13 22:55:35.516014 epoch: 3 step: 500 cls_loss= 2.86142 (281 samples/sec)
2024-04-13 22:56:32.197745 epoch: 3 step: 1000 cls_loss= 3.35615 (282 samples/sec)
2024-04-13 22:57:28.859118 epoch: 3 step: 1500 cls_loss= 2.32136 (282 samples/sec)
2024-04-13 22:58:25.433598 epoch: 3 step: 2000 cls_loss= 2.32528 (282 samples/sec)
2024-04-13 22:59:21.671000 epoch: 3 step: 2500 cls_loss= 2.89866 (284 samples/sec)
2024-04-13 23:00:17.801483 epoch: 3 step: 3000 cls_loss= 2.38007 (285 samples/sec)
2024-04-13 23:03:16.382634------------------------------------------------------ Precision@1: 56.07%  Precision@1: 78.81%

top1: [55.922000000000004, 55.988, 56.07]
top5: [78.78, 78.81, 78.81]
=> creating model alexnet ...
 learning rate =  5e-08
 precision =  7 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 23:03:18.991700 epoch: 1 step: 0 cls_loss= 2.96236 (23010 samples/sec)
2024-04-13 23:04:15.426349 epoch: 1 step: 500 cls_loss= 2.07119 (283 samples/sec)
2024-04-13 23:05:12.330587 epoch: 1 step: 1000 cls_loss= 3.02645 (281 samples/sec)
2024-04-13 23:06:09.566979 epoch: 1 step: 1500 cls_loss= 2.22835 (279 samples/sec)
2024-04-13 23:07:06.606100 epoch: 1 step: 2000 cls_loss= 2.76041 (280 samples/sec)
2024-04-13 23:08:03.687424 epoch: 1 step: 2500 cls_loss= 1.83654 (280 samples/sec)
2024-04-13 23:09:00.617516 epoch: 1 step: 3000 cls_loss= 2.30801 (281 samples/sec)
2024-04-13 23:11:58.915276------------------------------------------------------ Precision@1: 56.02%  Precision@1: 78.85%

top1: [56.022]
top5: [78.852]
2024-04-13 23:11:59.133887 epoch: 2 step: 0 cls_loss= 2.82518 (73462 samples/sec)
2024-04-13 23:12:55.546154 epoch: 2 step: 500 cls_loss= 2.50336 (283 samples/sec)
2024-04-13 23:13:51.369808 epoch: 2 step: 1000 cls_loss= 1.74566 (286 samples/sec)
2024-04-13 23:14:48.202458 epoch: 2 step: 1500 cls_loss= 2.95653 (281 samples/sec)
2024-04-13 23:15:45.417053 epoch: 2 step: 2000 cls_loss= 1.86887 (279 samples/sec)
2024-04-13 23:16:41.992098 epoch: 2 step: 2500 cls_loss= 2.84165 (282 samples/sec)
2024-04-13 23:17:38.431376 epoch: 2 step: 3000 cls_loss= 1.93489 (283 samples/sec)
2024-04-13 23:20:35.014038------------------------------------------------------ Precision@1: 56.03%  Precision@1: 78.83%

top1: [56.022, 56.028]
top5: [78.852, 78.82600000000001]
2024-04-13 23:20:35.219219 epoch: 3 step: 0 cls_loss= 2.11688 (78305 samples/sec)
2024-04-13 23:21:31.325413 epoch: 3 step: 500 cls_loss= 1.68671 (285 samples/sec)
2024-04-13 23:22:27.738438 epoch: 3 step: 1000 cls_loss= 1.87246 (283 samples/sec)
2024-04-13 23:23:24.010465 epoch: 3 step: 1500 cls_loss= 2.49451 (284 samples/sec)
2024-04-13 23:24:20.352725 epoch: 3 step: 2000 cls_loss= 2.35810 (283 samples/sec)
2024-04-13 23:25:17.207687 epoch: 3 step: 2500 cls_loss= 3.59165 (281 samples/sec)
2024-04-13 23:26:13.492227 epoch: 3 step: 3000 cls_loss= 2.53353 (284 samples/sec)
2024-04-13 23:29:10.831673------------------------------------------------------ Precision@1: 55.98%  Precision@1: 78.83%

top1: [56.022, 56.028, 55.978]
top5: [78.852, 78.82600000000001, 78.83]
=> creating model alexnet ...
 learning rate =  5e-08
 precision =  8 bits
SGD
2024-04-13 23:29:13.340718 epoch: 1 step: 0 cls_loss= 1.92361 (24152 samples/sec)
2024-04-13 23:30:10.094980 epoch: 1 step: 500 cls_loss= 2.66637 (281 samples/sec)
2024-04-13 23:31:06.640729 epoch: 1 step: 1000 cls_loss= 2.51015 (282 samples/sec)
2024-04-13 23:32:03.125972 epoch: 1 step: 1500 cls_loss= 1.79044 (283 samples/sec)
2024-04-13 23:33:00.196397 epoch: 1 step: 2000 cls_loss= 2.34969 (280 samples/sec)
2024-04-13 23:33:57.021860 epoch: 1 step: 2500 cls_loss= 2.48013 (281 samples/sec)
2024-04-13 23:34:53.540098 epoch: 1 step: 3000 cls_loss= 2.58717 (283 samples/sec)
2024-04-13 23:37:51.641119------------------------------------------------------ Precision@1: 56.03%  Precision@1: 78.83%

top1: [56.026]
top5: [78.834]
2024-04-13 23:37:51.823132 epoch: 2 step: 0 cls_loss= 2.73213 (88361 samples/sec)
2024-04-13 23:38:48.305780 epoch: 2 step: 500 cls_loss= 3.34123 (283 samples/sec)
2024-04-13 23:39:44.241519 epoch: 2 step: 1000 cls_loss= 2.27961 (286 samples/sec)
2024-04-13 23:40:39.850662 epoch: 2 step: 1500 cls_loss= 1.43840 (287 samples/sec)
2024-04-13 23:41:36.273019 epoch: 2 step: 2000 cls_loss= 2.83930 (283 samples/sec)
2024-04-13 23:42:32.359918 epoch: 2 step: 2500 cls_loss= 2.37691 (285 samples/sec)
2024-04-13 23:43:28.807028 epoch: 2 step: 3000 cls_loss= 1.93043 (283 samples/sec)
2024-04-13 23:46:23.952968------------------------------------------------------ Precision@1: 56.06%  Precision@1: 78.86%

top1: [56.026, 56.058]
top5: [78.834, 78.864]
2024-04-13 23:46:24.114444 epoch: 3 step: 0 cls_loss= 2.24479 (99620 samples/sec)
2024-04-13 23:47:19.700833 epoch: 3 step: 500 cls_loss= 2.70870 (287 samples/sec)
2024-04-13 23:48:16.264082 epoch: 3 step: 1000 cls_loss= 2.47401 (282 samples/sec)
2024-04-13 23:49:12.539852 epoch: 3 step: 1500 cls_loss= 1.98568 (284 samples/sec)
2024-04-13 23:50:09.023617 epoch: 3 step: 2000 cls_loss= 2.84357 (283 samples/sec)
2024-04-13 23:51:05.662133 epoch: 3 step: 2500 cls_loss= 1.90572 (282 samples/sec)
2024-04-13 23:52:01.776685 epoch: 3 step: 3000 cls_loss= 1.98202 (285 samples/sec)
2024-04-13 23:54:58.538721------------------------------------------------------ Precision@1: 56.11%  Precision@1: 78.84%

top1: [56.026, 56.058, 56.112]
top5: [78.834, 78.864, 78.83800000000001]
=> creating model alexnet ...
 learning rate =  5e-08
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-13 23:55:01.058915 epoch: 1 step: 0 cls_loss= 2.89688 (24044 samples/sec)
2024-04-13 23:55:57.502266 epoch: 1 step: 500 cls_loss= 3.45955 (283 samples/sec)
2024-04-13 23:56:53.897143 epoch: 1 step: 1000 cls_loss= 2.36389 (283 samples/sec)
2024-04-13 23:57:50.419777 epoch: 1 step: 1500 cls_loss= 2.45975 (283 samples/sec)
2024-04-13 23:58:47.784135 epoch: 1 step: 2000 cls_loss= 1.81046 (278 samples/sec)
2024-04-13 23:59:44.919065 epoch: 1 step: 2500 cls_loss= 2.10050 (280 samples/sec)
2024-04-14 00:00:41.842622 epoch: 1 step: 3000 cls_loss= 2.41064 (281 samples/sec)
2024-04-14 00:03:39.254831------------------------------------------------------ Precision@1: 56.13%  Precision@1: 78.80%

top1: [56.13]
top5: [78.804]
2024-04-14 00:03:39.476038 epoch: 2 step: 0 cls_loss= 2.76933 (72642 samples/sec)
2024-04-14 00:04:36.334509 epoch: 2 step: 500 cls_loss= 2.03490 (281 samples/sec)
2024-04-14 00:05:32.332821 epoch: 2 step: 1000 cls_loss= 1.96219 (285 samples/sec)
2024-04-14 00:06:28.423275 epoch: 2 step: 1500 cls_loss= 3.25135 (285 samples/sec)
2024-04-14 00:07:24.670529 epoch: 2 step: 2000 cls_loss= 2.45575 (284 samples/sec)
2024-04-14 00:08:21.509879 epoch: 2 step: 2500 cls_loss= 2.37664 (281 samples/sec)
2024-04-14 00:09:18.219876 epoch: 2 step: 3000 cls_loss= 2.39174 (282 samples/sec)
2024-04-14 00:12:16.879355------------------------------------------------------ Precision@1: 56.08%  Precision@1: 78.86%

top1: [56.13, 56.076]
top5: [78.804, 78.864]
2024-04-14 00:12:17.098795 epoch: 3 step: 0 cls_loss= 2.18754 (73158 samples/sec)
2024-04-14 00:13:13.496016 epoch: 3 step: 500 cls_loss= 2.47358 (283 samples/sec)
2024-04-14 00:14:10.799214 epoch: 3 step: 1000 cls_loss= 2.44041 (279 samples/sec)
2024-04-14 00:15:07.829888 epoch: 3 step: 1500 cls_loss= 2.16068 (280 samples/sec)
2024-04-14 00:16:04.152940 epoch: 3 step: 2000 cls_loss= 2.89789 (284 samples/sec)
2024-04-14 00:17:00.849263 epoch: 3 step: 2500 cls_loss= 3.12478 (282 samples/sec)
2024-04-14 00:17:57.373957 epoch: 3 step: 3000 cls_loss= 2.52823 (283 samples/sec)
2024-04-14 00:20:54.486248------------------------------------------------------ Precision@1: 56.09%  Precision@1: 78.84%

top1: [56.13, 56.076, 56.09]
top5: [78.804, 78.864, 78.836]
=> creating model mobilenet ...
 learning rate =  8e-06
 precision =  7 bits
SGD
2024-04-14 00:20:56.835570 epoch: 1 step: 0 cls_loss= 2.11142 (18259 samples/sec)
2024-04-14 00:21:53.560803 epoch: 1 step: 500 cls_loss= 2.10484 (282 samples/sec)
2024-04-14 00:22:50.449108 epoch: 1 step: 1000 cls_loss= 2.25284 (281 samples/sec)
2024-04-14 00:23:47.332287 epoch: 1 step: 1500 cls_loss= 1.54778 (281 samples/sec)
2024-04-14 00:24:44.254280 epoch: 1 step: 2000 cls_loss= 1.77810 (281 samples/sec)
2024-04-14 00:25:40.990385 epoch: 1 step: 2500 cls_loss= 1.60123 (282 samples/sec)
2024-04-14 00:26:37.793951 epoch: 1 step: 3000 cls_loss= 1.85157 (281 samples/sec)
2024-04-14 00:29:37.344618------------------------------------------------------ Precision@1: 66.66%  Precision@1: 87.23%

top1: [66.658]
top5: [87.23400000000001]
2024-04-14 00:29:37.545226 epoch: 2 step: 0 cls_loss= 2.64935 (80188 samples/sec)
2024-04-14 00:30:34.121877 epoch: 2 step: 500 cls_loss= 1.61110 (282 samples/sec)
2024-04-14 00:31:31.563677 epoch: 2 step: 1000 cls_loss= 2.12090 (278 samples/sec)
2024-04-14 00:32:28.093612 epoch: 2 step: 1500 cls_loss= 1.76882 (283 samples/sec)
2024-04-14 00:33:24.501427 epoch: 2 step: 2000 cls_loss= 2.48377 (283 samples/sec)
2024-04-14 00:34:21.338418 epoch: 2 step: 2500 cls_loss= 1.64338 (281 samples/sec)
2024-04-14 00:35:17.868389 epoch: 2 step: 3000 cls_loss= 2.26604 (283 samples/sec)
2024-04-14 00:38:15.953310------------------------------------------------------ Precision@1: 67.03%  Precision@1: 87.47%

top1: [66.658, 67.026]
top5: [87.23400000000001, 87.468]
2024-04-14 00:38:16.157659 epoch: 3 step: 0 cls_loss= 2.87784 (78781 samples/sec)
2024-04-14 00:39:13.176399 epoch: 3 step: 500 cls_loss= 2.22130 (280 samples/sec)
2024-04-14 00:40:10.022097 epoch: 3 step: 1000 cls_loss= 1.81667 (281 samples/sec)
2024-04-14 00:41:06.273092 epoch: 3 step: 1500 cls_loss= 2.32603 (284 samples/sec)
2024-04-14 00:42:03.961439 epoch: 3 step: 2000 cls_loss= 2.01445 (277 samples/sec)
2024-04-14 00:43:01.848647 epoch: 3 step: 2500 cls_loss= 1.72932 (276 samples/sec)
2024-04-14 00:43:58.896956 epoch: 3 step: 3000 cls_loss= 1.51774 (280 samples/sec)
2024-04-14 00:46:57.793812------------------------------------------------------ Precision@1: 67.07%  Precision@1: 87.51%

top1: [66.658, 67.026, 67.068]
top5: [87.23400000000001, 87.468, 87.506]
=> creating model mobilenet ...
 learning rate =  8e-06
 precision =  7 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 00:47:00.103374 epoch: 1 step: 0 cls_loss= 1.81101 (18274 samples/sec)
2024-04-14 00:48:00.974155 epoch: 1 step: 500 cls_loss= 1.43880 (262 samples/sec)
2024-04-14 00:49:01.750147 epoch: 1 step: 1000 cls_loss= 1.59615 (263 samples/sec)
2024-04-14 00:50:02.595121 epoch: 1 step: 1500 cls_loss= 2.08731 (262 samples/sec)
2024-04-14 00:51:03.422227 epoch: 1 step: 2000 cls_loss= 1.17033 (263 samples/sec)
2024-04-14 00:52:04.148288 epoch: 1 step: 2500 cls_loss= 2.20395 (263 samples/sec)
2024-04-14 00:53:04.965830 epoch: 1 step: 3000 cls_loss= 1.53600 (263 samples/sec)
2024-04-14 00:56:04.922351------------------------------------------------------ Precision@1: 66.93%  Precision@1: 87.48%

top1: [66.93]
top5: [87.47800000000001]
2024-04-14 00:56:05.186885 epoch: 2 step: 0 cls_loss= 1.72919 (60732 samples/sec)
2024-04-14 00:57:05.584694 epoch: 2 step: 500 cls_loss= 1.32310 (264 samples/sec)
2024-04-14 00:58:05.976610 epoch: 2 step: 1000 cls_loss= 1.79244 (264 samples/sec)
2024-04-14 00:59:06.442575 epoch: 2 step: 1500 cls_loss= 1.68114 (264 samples/sec)
2024-04-14 01:00:06.814629 epoch: 2 step: 2000 cls_loss= 1.55699 (265 samples/sec)
2024-04-14 01:01:07.214459 epoch: 2 step: 2500 cls_loss= 1.27106 (264 samples/sec)
2024-04-14 01:02:07.757734 epoch: 2 step: 3000 cls_loss= 1.76870 (264 samples/sec)
2024-04-14 01:05:07.024184------------------------------------------------------ Precision@1: 67.26%  Precision@1: 87.73%

top1: [66.93, 67.264]
top5: [87.47800000000001, 87.732]
2024-04-14 01:05:07.292058 epoch: 3 step: 0 cls_loss= 1.67717 (60003 samples/sec)
2024-04-14 01:06:07.807558 epoch: 3 step: 500 cls_loss= 1.14883 (264 samples/sec)
2024-04-14 01:07:08.147976 epoch: 3 step: 1000 cls_loss= 1.46185 (265 samples/sec)
2024-04-14 01:08:08.431146 epoch: 3 step: 1500 cls_loss= 1.51312 (265 samples/sec)
2024-04-14 01:09:08.649127 epoch: 3 step: 2000 cls_loss= 1.82972 (265 samples/sec)
2024-04-14 01:10:08.952403 epoch: 3 step: 2500 cls_loss= 2.03985 (265 samples/sec)
2024-04-14 01:11:09.193255 epoch: 3 step: 3000 cls_loss= 1.64950 (265 samples/sec)
2024-04-14 01:14:10.045233------------------------------------------------------ Precision@1: 67.21%  Precision@1: 87.76%

top1: [66.93, 67.264, 67.208]
top5: [87.47800000000001, 87.732, 87.756]
=> creating model mobilenet ...
 learning rate =  8e-06
 precision =  8 bits
SGD
2024-04-14 01:14:12.336030 epoch: 1 step: 0 cls_loss= 2.21192 (18444 samples/sec)
2024-04-14 01:15:08.715005 epoch: 1 step: 500 cls_loss= 1.16632 (283 samples/sec)
2024-04-14 01:16:05.701507 epoch: 1 step: 1000 cls_loss= 1.68782 (280 samples/sec)
2024-04-14 01:17:02.903120 epoch: 1 step: 1500 cls_loss= 1.84364 (279 samples/sec)
2024-04-14 01:17:59.744702 epoch: 1 step: 2000 cls_loss= 1.78807 (281 samples/sec)
2024-04-14 01:18:56.586011 epoch: 1 step: 2500 cls_loss= 1.59441 (281 samples/sec)
2024-04-14 01:19:53.787183 epoch: 1 step: 3000 cls_loss= 1.52038 (279 samples/sec)
2024-04-14 01:22:53.448326------------------------------------------------------ Precision@1: 67.63%  Precision@1: 88.03%

top1: [67.632]
top5: [88.028]
2024-04-14 01:22:53.653928 epoch: 2 step: 0 cls_loss= 1.86370 (78220 samples/sec)
2024-04-14 01:23:51.189751 epoch: 2 step: 500 cls_loss= 1.60620 (278 samples/sec)
2024-04-14 01:24:49.050056 epoch: 2 step: 1000 cls_loss= 1.39107 (276 samples/sec)
2024-04-14 01:25:45.693774 epoch: 2 step: 1500 cls_loss= 2.51683 (282 samples/sec)
2024-04-14 01:26:42.720043 epoch: 2 step: 2000 cls_loss= 2.03912 (280 samples/sec)
2024-04-14 01:27:38.603989 epoch: 2 step: 2500 cls_loss= 1.86769 (286 samples/sec)
2024-04-14 01:28:34.810725 epoch: 2 step: 3000 cls_loss= 2.10085 (284 samples/sec)
2024-04-14 01:31:34.641170------------------------------------------------------ Precision@1: 67.82%  Precision@1: 88.07%

top1: [67.632, 67.82000000000001]
top5: [88.028, 88.07000000000001]
2024-04-14 01:31:34.861181 epoch: 3 step: 0 cls_loss= 1.51495 (73077 samples/sec)
2024-04-14 01:32:32.476517 epoch: 3 step: 500 cls_loss= 1.37012 (277 samples/sec)
2024-04-14 01:33:29.750997 epoch: 3 step: 1000 cls_loss= 1.71492 (279 samples/sec)
2024-04-14 01:34:27.041144 epoch: 3 step: 1500 cls_loss= 1.96522 (279 samples/sec)
2024-04-14 01:35:23.747856 epoch: 3 step: 2000 cls_loss= 1.33642 (282 samples/sec)
2024-04-14 01:36:20.333322 epoch: 3 step: 2500 cls_loss= 2.14094 (282 samples/sec)
2024-04-14 01:37:16.483526 epoch: 3 step: 3000 cls_loss= 1.68068 (285 samples/sec)
2024-04-14 01:40:17.014192------------------------------------------------------ Precision@1: 67.77%  Precision@1: 88.16%

top1: [67.632, 67.82000000000001, 67.77]
top5: [88.028, 88.07000000000001, 88.162]
=> creating model mobilenet ...
 learning rate =  8e-06
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 01:40:19.397405 epoch: 1 step: 0 cls_loss= 1.90597 (17620 samples/sec)
2024-04-14 01:41:23.877164 epoch: 1 step: 500 cls_loss= 1.55620 (248 samples/sec)
2024-04-14 01:42:28.253103 epoch: 1 step: 1000 cls_loss= 1.75786 (248 samples/sec)
2024-04-14 01:43:32.436523 epoch: 1 step: 1500 cls_loss= 1.80601 (249 samples/sec)
2024-04-14 01:44:36.670393 epoch: 1 step: 2000 cls_loss= 2.08257 (249 samples/sec)
2024-04-14 01:45:40.885077 epoch: 1 step: 2500 cls_loss= 1.42746 (249 samples/sec)
2024-04-14 01:46:45.091852 epoch: 1 step: 3000 cls_loss= 1.43718 (249 samples/sec)
2024-04-14 01:49:48.024673------------------------------------------------------ Precision@1: 67.80%  Precision@1: 88.11%

top1: [67.798]
top5: [88.11]
2024-04-14 01:49:48.297880 epoch: 2 step: 0 cls_loss= 1.91348 (58736 samples/sec)
2024-04-14 01:50:52.407321 epoch: 2 step: 500 cls_loss= 2.95933 (249 samples/sec)
2024-04-14 01:51:56.548760 epoch: 2 step: 1000 cls_loss= 1.64560 (249 samples/sec)
2024-04-14 01:53:00.720115 epoch: 2 step: 1500 cls_loss= 1.70274 (249 samples/sec)
2024-04-14 01:54:04.986199 epoch: 2 step: 2000 cls_loss= 1.55744 (248 samples/sec)
2024-04-14 01:55:09.327773 epoch: 2 step: 2500 cls_loss= 2.01736 (248 samples/sec)
2024-04-14 01:56:13.567322 epoch: 2 step: 3000 cls_loss= 1.95588 (249 samples/sec)
2024-04-14 01:59:16.092508------------------------------------------------------ Precision@1: 67.82%  Precision@1: 88.09%

top1: [67.798, 67.82000000000001]
top5: [88.11, 88.08800000000001]
2024-04-14 01:59:16.355907 epoch: 3 step: 0 cls_loss= 1.52806 (61019 samples/sec)
2024-04-14 02:00:20.773147 epoch: 3 step: 500 cls_loss= 1.59522 (248 samples/sec)
2024-04-14 02:01:25.121945 epoch: 3 step: 1000 cls_loss= 1.40787 (248 samples/sec)
2024-04-14 02:02:29.321707 epoch: 3 step: 1500 cls_loss= 1.67291 (249 samples/sec)
2024-04-14 02:03:33.406295 epoch: 3 step: 2000 cls_loss= 1.69756 (249 samples/sec)
2024-04-14 02:04:37.549650 epoch: 3 step: 2500 cls_loss= 1.75971 (249 samples/sec)
2024-04-14 02:05:41.881583 epoch: 3 step: 3000 cls_loss= 1.27623 (248 samples/sec)
2024-04-14 02:08:43.621621------------------------------------------------------ Precision@1: 67.84%  Precision@1: 88.02%

top1: [67.798, 67.82000000000001, 67.83800000000001]
top5: [88.11, 88.08800000000001, 88.018]
]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ 
[K]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNsbash bash_train.sh 
=> creating model mobilenet ...
 learning rate =  1e-05
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 11:01:16.879705 epoch: 1 step: 0 cls_loss= 1.31420 (18001 samples/sec)
2024-04-14 11:02:20.960497 epoch: 1 step: 500 cls_loss= 1.65829 (249 samples/sec)
2024-04-14 11:03:25.105384 epoch: 1 step: 1000 cls_loss= 1.91772 (249 samples/sec)
2024-04-14 11:04:29.478856 epoch: 1 step: 1500 cls_loss= 1.81662 (248 samples/sec)
2024-04-14 11:05:34.082431 epoch: 1 step: 2000 cls_loss= 2.12941 (247 samples/sec)
2024-04-14 11:06:38.553980 epoch: 1 step: 2500 cls_loss= 2.20889 (248 samples/sec)
2024-04-14 11:07:43.182911 epoch: 1 step: 3000 cls_loss= 1.71263 (247 samples/sec)
2024-04-14 11:11:10.037651------------------------------------------------------ Precision@1: 67.79%  Precision@1: 88.09%

top1: [67.788]
top5: [88.086]
2024-04-14 11:11:10.628189 epoch: 2 step: 0 cls_loss= 2.13666 (27174 samples/sec)
2024-04-14 11:13:45.063832 epoch: 2 step: 500 cls_loss= 2.08959 (103 samples/sec)
2024-04-14 11:16:30.787136 epoch: 2 step: 1000 cls_loss= 2.16736 (96 samples/sec)
2024-04-14 11:19:40.318399 epoch: 2 step: 1500 cls_loss= 1.73366 (84 samples/sec)
2024-04-14 11:23:13.668775 epoch: 2 step: 2000 cls_loss= 1.63449 (74 samples/sec)
2024-04-14 11:26:58.128468 epoch: 2 step: 2500 cls_loss= 1.72561 (71 samples/sec)
2024-04-14 11:30:47.134279 epoch: 2 step: 3000 cls_loss= 2.33359 (69 samples/sec)
2024-04-14 11:36:28.955728------------------------------------------------------ Precision@1: 67.71%  Precision@1: 87.97%

top1: [67.788, 67.714]
top5: [88.086, 87.97]
2024-04-14 11:36:29.382141 epoch: 3 step: 0 cls_loss= 0.83676 (37652 samples/sec)
2024-04-14 11:38:29.508721 epoch: 3 step: 500 cls_loss= 1.90557 (133 samples/sec)
2024-04-14 11:40:37.308013 epoch: 3 step: 1000 cls_loss= 2.02818 (125 samples/sec)
2024-04-14 11:42:55.992421 epoch: 3 step: 1500 cls_loss= 0.89511 (115 samples/sec)
2024-04-14 11:45:36.110742 epoch: 3 step: 2000 cls_loss= 2.39644 (99 samples/sec)
2024-04-14 11:48:54.965150 epoch: 3 step: 2500 cls_loss= 2.31295 (80 samples/sec)
2024-04-14 11:52:34.839576 epoch: 3 step: 3000 cls_loss= 1.54017 (72 samples/sec)
2024-04-14 11:57:53.617391------------------------------------------------------ Precision@1: 67.85%  Precision@1: 88.06%

top1: [67.788, 67.714, 67.85]
top5: [88.086, 87.97, 88.056]
=> creating model mobilenet ...
 learning rate =  2e-05
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 11:57:57.250868 epoch: 1 step: 0 cls_loss= 1.59651 (13523 samples/sec)
2024-04-14 11:59:38.427054 epoch: 1 step: 500 cls_loss= 2.16629 (158 samples/sec)
2024-04-14 12:01:20.019488 epoch: 1 step: 1000 cls_loss= 1.54689 (157 samples/sec)
2024-04-14 12:03:09.014461 epoch: 1 step: 1500 cls_loss= 1.83855 (146 samples/sec)
2024-04-14 12:05:10.691821 epoch: 1 step: 2000 cls_loss= 2.08702 (131 samples/sec)
2024-04-14 12:07:25.326102 epoch: 1 step: 2500 cls_loss= 1.61410 (118 samples/sec)
2024-04-14 12:10:16.332829 epoch: 1 step: 3000 cls_loss= 1.45789 (93 samples/sec)
2024-04-14 12:15:19.654455------------------------------------------------------ Precision@1: 67.69%  Precision@1: 87.86%

top1: [67.694]
top5: [87.85600000000001]
2024-04-14 12:15:19.979339 epoch: 2 step: 0 cls_loss= 1.28589 (49527 samples/sec)
2024-04-14 12:16:42.124865 epoch: 2 step: 500 cls_loss= 1.71444 (194 samples/sec)
2024-04-14 12:18:06.568360 epoch: 2 step: 1000 cls_loss= 1.53890 (189 samples/sec)
2024-04-14 12:19:28.882795 epoch: 2 step: 1500 cls_loss= 1.87512 (194 samples/sec)
2024-04-14 12:20:53.010914 epoch: 2 step: 2000 cls_loss= 1.60128 (190 samples/sec)
2024-04-14 12:22:20.091110 epoch: 2 step: 2500 cls_loss= 1.34086 (183 samples/sec)
2024-04-14 12:23:55.445964 epoch: 2 step: 3000 cls_loss= 1.38248 (167 samples/sec)
2024-04-14 12:28:17.254924------------------------------------------------------ Precision@1: 67.67%  Precision@1: 88.04%

top1: [67.694, 67.672]
top5: [87.85600000000001, 88.042]
2024-04-14 12:28:17.604350 epoch: 3 step: 0 cls_loss= 1.90629 (45973 samples/sec)
2024-04-14 12:29:33.565234 epoch: 3 step: 500 cls_loss= 1.94821 (210 samples/sec)
2024-04-14 12:30:50.457127 epoch: 3 step: 1000 cls_loss= 1.76771 (208 samples/sec)
2024-04-14 12:32:10.080622 epoch: 3 step: 1500 cls_loss= 1.96136 (200 samples/sec)
2024-04-14 12:33:26.119895 epoch: 3 step: 2000 cls_loss= 1.24790 (210 samples/sec)
2024-04-14 12:34:44.680389 epoch: 3 step: 2500 cls_loss= 1.72186 (203 samples/sec)
2024-04-14 12:36:15.585439 epoch: 3 step: 3000 cls_loss= 1.82238 (176 samples/sec)
2024-04-14 12:40:23.526056------------------------------------------------------ Precision@1: 67.66%  Precision@1: 87.95%

top1: [67.694, 67.672, 67.656]
top5: [87.85600000000001, 88.042, 87.95]
=> creating model mobilenet ...
 learning rate =  5e-05
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 12:40:27.544217 epoch: 1 step: 0 cls_loss= 1.90879 (14226 samples/sec)
2024-04-14 12:41:42.181422 epoch: 1 step: 500 cls_loss= 1.84487 (214 samples/sec)
2024-04-14 12:42:58.780965 epoch: 1 step: 1000 cls_loss= 2.17252 (208 samples/sec)
2024-04-14 12:44:16.041664 epoch: 1 step: 1500 cls_loss= 1.27245 (207 samples/sec)
2024-04-14 12:45:32.335224 epoch: 1 step: 2000 cls_loss= 2.75665 (209 samples/sec)
2024-04-14 12:46:47.571584 epoch: 1 step: 2500 cls_loss= 1.72762 (212 samples/sec)
2024-04-14 12:48:04.058113 epoch: 1 step: 3000 cls_loss= 1.87499 (209 samples/sec)
2024-04-14 12:51:56.395189------------------------------------------------------ Precision@1: 67.24%  Precision@1: 87.80%

top1: [67.242]
top5: [87.802]
2024-04-14 12:51:56.723132 epoch: 2 step: 0 cls_loss= 1.87651 (49055 samples/sec)
2024-04-14 12:53:12.031279 epoch: 2 step: 500 cls_loss= 1.70680 (212 samples/sec)
2024-04-14 12:54:28.023486 epoch: 2 step: 1000 cls_loss= 1.59588 (210 samples/sec)
2024-04-14 12:55:45.143039 epoch: 2 step: 1500 cls_loss= 1.41194 (207 samples/sec)
2024-04-14 12:56:59.693169 epoch: 2 step: 2000 cls_loss= 1.93706 (214 samples/sec)
2024-04-14 12:58:14.521485 epoch: 2 step: 2500 cls_loss= 1.20291 (213 samples/sec)
2024-04-14 12:59:29.666488 epoch: 2 step: 3000 cls_loss= 1.55072 (212 samples/sec)
2024-04-14 13:03:34.751827------------------------------------------------------ Precision@1: 67.05%  Precision@1: 87.56%

top1: [67.242, 67.048]
top5: [87.802, 87.558]
2024-04-14 13:03:35.109934 epoch: 3 step: 0 cls_loss= 1.51055 (44913 samples/sec)
2024-04-14 13:04:52.007548 epoch: 3 step: 500 cls_loss= 2.44368 (208 samples/sec)
2024-04-14 13:06:12.108620 epoch: 3 step: 1000 cls_loss= 1.73000 (199 samples/sec)
2024-04-14 13:07:28.983828 epoch: 3 step: 1500 cls_loss= 1.55610 (208 samples/sec)
2024-04-14 13:08:48.147636 epoch: 3 step: 2000 cls_loss= 1.57886 (202 samples/sec)
2024-04-14 13:10:06.374322 epoch: 3 step: 2500 cls_loss= 2.00641 (204 samples/sec)
2024-04-14 13:11:20.699966 epoch: 3 step: 3000 cls_loss= 1.75692 (215 samples/sec)
2024-04-14 13:15:17.778398------------------------------------------------------ Precision@1: 67.34%  Precision@1: 87.67%

top1: [67.242, 67.048, 67.342]
top5: [87.802, 87.558, 87.674]
=> creating model mobilenet ...
 learning rate =  1e-05
 precision =  7 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 13:15:21.018905 epoch: 1 step: 0 cls_loss= 2.31561 (14243 samples/sec)
2024-04-14 13:16:38.077309 epoch: 1 step: 500 cls_loss= 1.54111 (207 samples/sec)
2024-04-14 13:17:53.930266 epoch: 1 step: 1000 cls_loss= 1.69347 (210 samples/sec)
2024-04-14 13:19:09.618405 epoch: 1 step: 1500 cls_loss= 2.07464 (211 samples/sec)
2024-04-14 13:20:27.979166 epoch: 1 step: 2000 cls_loss= 2.36562 (204 samples/sec)
2024-04-14 13:21:45.975119 epoch: 1 step: 2500 cls_loss= 2.31562 (205 samples/sec)
2024-04-14 13:23:02.351130 epoch: 1 step: 3000 cls_loss= 2.73057 (209 samples/sec)
2024-04-14 13:27:10.013438------------------------------------------------------ Precision@1: 67.13%  Precision@1: 87.43%

top1: [67.13]
top5: [87.434]
2024-04-14 13:27:10.335413 epoch: 2 step: 0 cls_loss= 1.91394 (49980 samples/sec)
2024-04-14 13:28:27.224548 epoch: 2 step: 500 cls_loss= 1.38705 (208 samples/sec)
2024-04-14 13:29:45.087648 epoch: 2 step: 1000 cls_loss= 2.75485 (205 samples/sec)
2024-04-14 13:31:03.203004 epoch: 2 step: 1500 cls_loss= 1.76979 (204 samples/sec)
2024-04-14 13:32:19.017643 epoch: 2 step: 2000 cls_loss= 1.84400 (211 samples/sec)
2024-04-14 13:33:37.254486 epoch: 2 step: 2500 cls_loss= 1.44066 (204 samples/sec)
2024-04-14 13:34:54.830986 epoch: 2 step: 3000 cls_loss= 1.70582 (206 samples/sec)
2024-04-14 13:39:05.179172------------------------------------------------------ Precision@1: 67.19%  Precision@1: 87.68%

top1: [67.13, 67.188]
top5: [87.434, 87.68]
2024-04-14 13:39:05.545674 epoch: 3 step: 0 cls_loss= 1.52085 (43965 samples/sec)
2024-04-14 13:40:22.025649 epoch: 3 step: 500 cls_loss= 1.51217 (209 samples/sec)
2024-04-14 13:41:37.996919 epoch: 3 step: 1000 cls_loss= 1.35124 (210 samples/sec)
2024-04-14 13:42:52.589985 epoch: 3 step: 1500 cls_loss= 2.26145 (214 samples/sec)
2024-04-14 13:44:08.160924 epoch: 3 step: 2000 cls_loss= 2.42338 (211 samples/sec)
2024-04-14 13:45:23.286706 epoch: 3 step: 2500 cls_loss= 2.10157 (212 samples/sec)
2024-04-14 13:46:38.445137 epoch: 3 step: 3000 cls_loss= 2.23617 (212 samples/sec)
2024-04-14 13:50:43.611314------------------------------------------------------ Precision@1: 67.25%  Precision@1: 87.79%

top1: [67.13, 67.188, 67.246]
top5: [87.434, 87.68, 87.786]
=> creating model mobilenet ...
 learning rate =  2e-05
 precision =  7 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 13:50:46.973956 epoch: 1 step: 0 cls_loss= 1.82890 (14035 samples/sec)
2024-04-14 13:52:03.447621 epoch: 1 step: 500 cls_loss= 2.00111 (209 samples/sec)
2024-04-14 13:53:19.490815 epoch: 1 step: 1000 cls_loss= 1.43429 (210 samples/sec)
2024-04-14 13:54:33.485917 epoch: 1 step: 1500 cls_loss= 1.82611 (216 samples/sec)
2024-04-14 13:55:45.691689 epoch: 1 step: 2000 cls_loss= 1.84411 (221 samples/sec)
2024-04-14 13:57:00.452731 epoch: 1 step: 2500 cls_loss= 1.91799 (214 samples/sec)
2024-04-14 13:58:15.030308 epoch: 1 step: 3000 cls_loss= 2.05193 (214 samples/sec)
2024-04-14 14:02:18.276897------------------------------------------------------ Precision@1: 66.98%  Precision@1: 87.56%

top1: [66.978]
top5: [87.56]
2024-04-14 14:02:18.641778 epoch: 2 step: 0 cls_loss= 1.92532 (44039 samples/sec)
2024-04-14 14:03:34.398783 epoch: 2 step: 500 cls_loss= 1.92782 (211 samples/sec)
2024-04-14 14:04:49.728135 epoch: 2 step: 1000 cls_loss= 2.22299 (212 samples/sec)
2024-04-14 14:06:04.769729 epoch: 2 step: 1500 cls_loss= 1.78851 (213 samples/sec)
2024-04-14 14:07:19.965955 epoch: 2 step: 2000 cls_loss= 2.27003 (212 samples/sec)
2024-04-14 14:08:35.106700 epoch: 2 step: 2500 cls_loss= 2.86797 (212 samples/sec)
2024-04-14 14:09:50.765124 epoch: 2 step: 3000 cls_loss= 1.42373 (211 samples/sec)
2024-04-14 14:13:47.987554------------------------------------------------------ Precision@1: 66.95%  Precision@1: 87.54%

top1: [66.978, 66.95400000000001]
top5: [87.56, 87.54]
2024-04-14 14:13:48.321095 epoch: 3 step: 0 cls_loss= 1.53246 (48209 samples/sec)
2024-04-14 14:15:04.140009 epoch: 3 step: 500 cls_loss= 2.50552 (211 samples/sec)
2024-04-14 14:16:19.309996 epoch: 3 step: 1000 cls_loss= 1.78157 (212 samples/sec)
2024-04-14 14:17:36.265426 epoch: 3 step: 1500 cls_loss= 2.22862 (207 samples/sec)
2024-04-14 14:18:52.109502 epoch: 3 step: 2000 cls_loss= 1.14112 (210 samples/sec)
2024-04-14 14:20:07.407102 epoch: 3 step: 2500 cls_loss= 1.96255 (212 samples/sec)
2024-04-14 14:21:22.500993 epoch: 3 step: 3000 cls_loss= 1.35047 (213 samples/sec)
2024-04-14 14:25:28.233542------------------------------------------------------ Precision@1: 66.86%  Precision@1: 87.33%

top1: [66.978, 66.95400000000001, 66.86]
top5: [87.56, 87.54, 87.328]
=> creating model mobilenet ...
 learning rate =  5e-05
 precision =  7 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 14:25:31.484404 epoch: 1 step: 0 cls_loss= 2.24061 (14325 samples/sec)
2024-04-14 14:26:45.854169 epoch: 1 step: 500 cls_loss= 2.68403 (215 samples/sec)
2024-04-14 14:28:03.297248 epoch: 1 step: 1000 cls_loss= 1.57448 (206 samples/sec)
2024-04-14 14:29:17.643619 epoch: 1 step: 1500 cls_loss= 2.31412 (215 samples/sec)
2024-04-14 14:30:34.594066 epoch: 1 step: 2000 cls_loss= 1.81563 (207 samples/sec)
2024-04-14 14:31:49.757925 epoch: 1 step: 2500 cls_loss= 2.12155 (212 samples/sec)
2024-04-14 14:33:05.727669 epoch: 1 step: 3000 cls_loss= 2.18831 (210 samples/sec)
2024-04-14 14:37:06.713301------------------------------------------------------ Precision@1: 66.35%  Precision@1: 87.08%

top1: [66.352]
top5: [87.08]
2024-04-14 14:37:07.094820 epoch: 2 step: 0 cls_loss= 1.44445 (42188 samples/sec)
2024-04-14 14:38:24.503995 epoch: 2 step: 500 cls_loss= 1.52180 (206 samples/sec)
2024-04-14 14:39:41.801480 epoch: 2 step: 1000 cls_loss= 1.66315 (206 samples/sec)
2024-04-14 14:40:57.147671 epoch: 2 step: 1500 cls_loss= 2.02171 (212 samples/sec)
2024-04-14 14:42:11.614532 epoch: 2 step: 2000 cls_loss= 1.88112 (214 samples/sec)
2024-04-14 14:43:27.218513 epoch: 2 step: 2500 cls_loss= 1.59014 (211 samples/sec)
2024-04-14 14:44:42.653171 epoch: 2 step: 3000 cls_loss= 2.29318 (212 samples/sec)
2024-04-14 14:49:04.319432------------------------------------------------------ Precision@1: 66.87%  Precision@1: 87.43%

top1: [66.352, 66.872]
top5: [87.08, 87.426]
2024-04-14 14:49:04.755473 epoch: 3 step: 0 cls_loss= 1.46685 (36850 samples/sec)
2024-04-14 14:50:49.905066 epoch: 3 step: 500 cls_loss= 1.79767 (152 samples/sec)
2024-04-14 14:52:39.677490 epoch: 3 step: 1000 cls_loss= 1.78789 (145 samples/sec)
2024-04-14 14:54:39.617729 epoch: 3 step: 1500 cls_loss= 1.70841 (133 samples/sec)
2024-04-14 14:56:51.441631 epoch: 3 step: 2000 cls_loss= 1.61467 (121 samples/sec)
2024-04-14 14:59:32.112531 epoch: 3 step: 2500 cls_loss= 2.10381 (99 samples/sec)
2024-04-14 15:02:15.721166 epoch: 3 step: 3000 cls_loss= 1.44243 (97 samples/sec)
2024-04-14 15:06:12.105990------------------------------------------------------ Precision@1: 66.68%  Precision@1: 87.29%

top1: [66.352, 66.872, 66.684]
top5: [87.08, 87.426, 87.29]
]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ bash bash_train.sh 
=> creating model mobilenet ...
 learning rate =  5e-06
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 16:47:10.120586 epoch: 1 step: 0 cls_loss= 1.51236 (12272 samples/sec)
2024-04-14 16:49:10.405637 epoch: 1 step: 500 cls_loss= 1.88300 (133 samples/sec)
2024-04-14 16:51:10.038309 epoch: 1 step: 1000 cls_loss= 2.51942 (133 samples/sec)
2024-04-14 16:53:06.922724 epoch: 1 step: 1500 cls_loss= 2.17022 (136 samples/sec)
2024-04-14 16:55:06.565956 epoch: 1 step: 2000 cls_loss= 1.92220 (133 samples/sec)
2024-04-14 16:57:04.619802 epoch: 1 step: 2500 cls_loss= 1.87021 (135 samples/sec)
2024-04-14 16:59:04.776312 epoch: 1 step: 3000 cls_loss= 2.36804 (133 samples/sec)
2024-04-14 17:03:25.193017------------------------------------------------------ Precision@1: 67.80%  Precision@1: 88.05%

top1: [67.8]
top5: [88.054]
2024-04-14 17:03:25.554091 epoch: 2 step: 0 cls_loss= 1.34562 (44517 samples/sec)
2024-04-14 17:04:40.120401 epoch: 2 step: 500 cls_loss= 2.23667 (214 samples/sec)
2024-04-14 17:05:56.367286 epoch: 2 step: 1000 cls_loss= 1.94074 (209 samples/sec)
2024-04-14 17:07:12.561141 epoch: 2 step: 1500 cls_loss= 2.39769 (209 samples/sec)
2024-04-14 17:08:31.131894 epoch: 2 step: 2000 cls_loss= 1.49671 (203 samples/sec)
2024-04-14 17:09:47.274329 epoch: 2 step: 2500 cls_loss= 1.85613 (210 samples/sec)
2024-04-14 17:11:02.463355 epoch: 2 step: 3000 cls_loss= 1.99297 (212 samples/sec)
2024-04-14 17:15:03.067477------------------------------------------------------ Precision@1: 67.86%  Precision@1: 88.11%

top1: [67.8, 67.862]
top5: [88.054, 88.11]
2024-04-14 17:15:03.422698 epoch: 3 step: 0 cls_loss= 1.74308 (45314 samples/sec)
2024-04-14 17:16:19.728017 epoch: 3 step: 500 cls_loss= 1.85111 (209 samples/sec)
2024-04-14 17:17:36.295432 epoch: 3 step: 1000 cls_loss= 1.65831 (208 samples/sec)
2024-04-14 17:18:53.694251 epoch: 3 step: 1500 cls_loss= 1.50822 (206 samples/sec)
2024-04-14 17:20:08.489647 epoch: 3 step: 2000 cls_loss= 1.68248 (213 samples/sec)
2024-04-14 17:21:25.054362 epoch: 3 step: 2500 cls_loss= 1.67828 (208 samples/sec)
2024-04-14 17:22:38.723142 epoch: 3 step: 3000 cls_loss= 1.71122 (217 samples/sec)
2024-04-14 17:26:44.891335------------------------------------------------------ Precision@1: 67.78%  Precision@1: 88.04%

top1: [67.8, 67.862, 67.782]
top5: [88.054, 88.11, 88.044]
=> creating model mobilenet ...
 learning rate =  5e-06
 precision =  8 bits
DSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:46: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 17:26:48.242524 epoch: 1 step: 0 cls_loss= 2.05639 (14294 samples/sec)
2024-04-14 17:28:04.478144 epoch: 1 step: 500 cls_loss= 1.96479 (209 samples/sec)
2024-04-14 17:29:22.775207 epoch: 1 step: 1000 cls_loss= 2.13125 (204 samples/sec)
2024-04-14 17:30:38.009429 epoch: 1 step: 1500 cls_loss= 2.31193 (212 samples/sec)
2024-04-14 17:31:57.205610 epoch: 1 step: 2000 cls_loss= 1.42090 (202 samples/sec)
2024-04-14 17:33:15.659278 epoch: 1 step: 2500 cls_loss= 2.08228 (203 samples/sec)
2024-04-14 17:34:31.945213 epoch: 1 step: 3000 cls_loss= 1.10466 (209 samples/sec)
2024-04-14 17:38:38.473863------------------------------------------------------ Precision@1: 67.82%  Precision@1: 88.05%

top1: [67.82000000000001]
top5: [88.054]
2024-04-14 17:38:38.835838 epoch: 2 step: 0 cls_loss= 1.18028 (44437 samples/sec)
2024-04-14 17:39:57.739776 epoch: 2 step: 500 cls_loss= 1.93378 (202 samples/sec)
2024-04-14 17:41:14.463488 epoch: 2 step: 1000 cls_loss= 2.07415 (208 samples/sec)
2024-04-14 17:42:33.545363 epoch: 2 step: 1500 cls_loss= 2.13134 (202 samples/sec)
2024-04-14 17:43:51.350069 epoch: 2 step: 2000 cls_loss= 1.81207 (205 samples/sec)
2024-04-14 17:45:08.835755 epoch: 2 step: 2500 cls_loss= 1.33515 (206 samples/sec)
2024-04-14 17:46:26.888008 epoch: 2 step: 3000 cls_loss= 1.69082 (204 samples/sec)
2024-04-14 17:50:30.662350------------------------------------------------------ Precision@1: 67.89%  Precision@1: 88.11%

top1: [67.82000000000001, 67.892]
top5: [88.054, 88.108]
2024-04-14 17:50:31.030098 epoch: 3 step: 0 cls_loss= 1.48883 (43686 samples/sec)
2024-04-14 17:51:48.804537 epoch: 3 step: 500 cls_loss= 1.69787 (205 samples/sec)
2024-04-14 17:53:03.253335 epoch: 3 step: 1000 cls_loss= 1.97336 (214 samples/sec)
2024-04-14 17:54:23.184078 epoch: 3 step: 1500 cls_loss= 1.66509 (200 samples/sec)
2024-04-14 17:55:40.589748 epoch: 3 step: 2000 cls_loss= 1.59098 (206 samples/sec)
2024-04-14 17:56:57.175332 epoch: 3 step: 2500 cls_loss= 2.07900 (208 samples/sec)
2024-04-14 17:58:14.000147 epoch: 3 step: 3000 cls_loss= 1.60180 (208 samples/sec)
2024-04-14 18:02:10.176934------------------------------------------------------ Precision@1: 67.97%  Precision@1: 88.09%

top1: [67.82000000000001, 67.892, 67.968]
top5: [88.054, 88.108, 88.09400000000001]
=> creating model mobilenet ...
 learning rate =  5e-06
 precision =  8 bits
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 18:02:13.656462 epoch: 1 step: 0 cls_loss= 2.20008 (13503 samples/sec)
2024-04-14 18:03:30.291739 epoch: 1 step: 500 cls_loss= 1.71495 (208 samples/sec)
2024-04-14 18:04:49.379494 epoch: 1 step: 1000 cls_loss= 2.10530 (202 samples/sec)
2024-04-14 18:06:04.679148 epoch: 1 step: 1500 cls_loss= 2.40957 (212 samples/sec)
2024-04-14 18:07:20.886285 epoch: 1 step: 2000 cls_loss= 2.03329 (209 samples/sec)
2024-04-14 18:08:37.299830 epoch: 1 step: 2500 cls_loss= 1.57990 (209 samples/sec)
2024-04-14 18:09:53.715297 epoch: 1 step: 3000 cls_loss= 2.06755 (209 samples/sec)
2024-04-14 18:14:05.663978------------------------------------------------------ Precision@1: 67.90%  Precision@1: 88.15%

top1: [67.896]
top5: [88.148]
2024-04-14 18:14:06.018969 epoch: 2 step: 0 cls_loss= 1.26775 (45295 samples/sec)
2024-04-14 18:15:23.934371 epoch: 2 step: 500 cls_loss= 2.13902 (205 samples/sec)
2024-04-14 18:16:41.800690 epoch: 2 step: 1000 cls_loss= 1.66186 (205 samples/sec)
2024-04-14 18:18:01.926355 epoch: 2 step: 1500 cls_loss= 1.88671 (199 samples/sec)
2024-04-14 18:19:18.351007 epoch: 2 step: 2000 cls_loss= 2.12967 (209 samples/sec)
2024-04-14 18:20:36.721643 epoch: 2 step: 2500 cls_loss= 1.16127 (204 samples/sec)
2024-04-14 18:21:54.475516 epoch: 2 step: 3000 cls_loss= 2.04934 (205 samples/sec)
2024-04-14 18:26:04.031110------------------------------------------------------ Precision@1: 67.75%  Precision@1: 88.03%

top1: [67.896, 67.752]
top5: [88.148, 88.026]
2024-04-14 18:26:04.371362 epoch: 3 step: 0 cls_loss= 1.05270 (47195 samples/sec)
2024-04-14 18:27:24.153805 epoch: 3 step: 500 cls_loss= 1.76694 (200 samples/sec)
2024-04-14 18:28:40.085551 epoch: 3 step: 1000 cls_loss= 1.96245 (210 samples/sec)
2024-04-14 18:29:57.730433 epoch: 3 step: 1500 cls_loss= 1.99708 (206 samples/sec)
2024-04-14 18:31:15.845523 epoch: 3 step: 2000 cls_loss= 1.55419 (204 samples/sec)
2024-04-14 18:32:34.710607 epoch: 3 step: 2500 cls_loss= 1.54048 (202 samples/sec)
2024-04-14 18:33:53.155747 epoch: 3 step: 3000 cls_loss= 1.00778 (203 samples/sec)
2024-04-14 18:38:01.847033------------------------------------------------------ Precision@1: 67.64%  Precision@1: 87.99%

top1: [67.896, 67.752, 67.636]
top5: [88.148, 88.026, 87.986]
=> creating model mobilenet ...
 learning rate =  5e-06
 precision =  8 bits
SSGD
/workspaces/pytorch-dev/SLFP_CNNs/utils/optimizer.py:114: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1488.)
  d_p.add_(weight_decay, p.data)
2024-04-14 18:38:05.382383 epoch: 1 step: 0 cls_loss= 1.72925 (13005 samples/sec)
2024-04-14 18:39:21.837847 epoch: 1 step: 500 cls_loss= 1.70045 (209 samples/sec)
2024-04-14 18:40:40.021494 epoch: 1 step: 1000 cls_loss= 1.40687 (204 samples/sec)
2024-04-14 18:41:57.711065 epoch: 1 step: 1500 cls_loss= 1.55724 (205 samples/sec)
2024-04-14 18:43:16.461421 epoch: 1 step: 2000 cls_loss= 2.16049 (203 samples/sec)
2024-04-14 18:44:33.130909 epoch: 1 step: 2500 cls_loss= 2.21084 (208 samples/sec)
2024-04-14 18:45:52.090075 epoch: 1 step: 3000 cls_loss= 2.24544 (202 samples/sec)
2024-04-14 18:49:59.154332------------------------------------------------------ Precision@1: 67.67%  Precision@1: 88.03%

top1: [67.672]
top5: [88.028]
2024-04-14 18:49:59.502871 epoch: 2 step: 0 cls_loss= 1.63472 (46195 samples/sec)
2024-04-14 18:51:15.840255 epoch: 2 step: 500 cls_loss= 1.70913 (209 samples/sec)
2024-04-14 18:52:33.848942 epoch: 2 step: 1000 cls_loss= 1.14357 (205 samples/sec)
2024-04-14 18:53:52.349898 epoch: 2 step: 1500 cls_loss= 1.46837 (203 samples/sec)
2024-04-14 18:55:08.325166 epoch: 2 step: 2000 cls_loss= 1.41897 (210 samples/sec)
2024-04-14 18:56:24.057035 epoch: 2 step: 2500 cls_loss= 1.56113 (211 samples/sec)
2024-04-14 18:57:40.014003 epoch: 2 step: 3000 cls_loss= 1.89395 (210 samples/sec)
2024-04-14 19:01:35.307592------------------------------------------------------ Precision@1: 67.78%  Precision@1: 88.08%

top1: [67.672, 67.784]
top5: [88.028, 88.08]
2024-04-14 19:01:36.471647 epoch: 3 step: 0 cls_loss= 2.26061 (13771 samples/sec)
2024-04-14 19:02:53.611783 epoch: 3 step: 500 cls_loss= 2.36907 (207 samples/sec)
2024-04-14 19:04:10.520651 epoch: 3 step: 1000 cls_loss= 1.74955 (208 samples/sec)
2024-04-14 19:05:27.800757 epoch: 3 step: 1500 cls_loss= 2.03183 (207 samples/sec)
2024-04-14 19:06:46.113206 epoch: 3 step: 2000 cls_loss= 1.77556 (204 samples/sec)
2024-04-14 19:08:04.213201 epoch: 3 step: 2500 cls_loss= 1.49921 (204 samples/sec)
2024-04-14 19:09:20.327402 epoch: 3 step: 3000 cls_loss= 1.60476 (210 samples/sec)
2024-04-14 19:13:15.288240------------------------------------------------------ Precision@1: 67.84%  Precision@1: 88.02%

top1: [67.672, 67.784, 67.83800000000001]
top5: [88.028, 88.08, 88.02]
]0;vscode@pytorch: /workspaces/pytorch-dev/SLFP_CNNs[01;32mvscode@pytorch[00m:[01;34m/workspaces/pytorch-dev/SLFP_CNNs[00m$ exit

Script done on 2024-04-15 10:30:03+08:00 [COMMAND_EXIT_CODE="0"]
